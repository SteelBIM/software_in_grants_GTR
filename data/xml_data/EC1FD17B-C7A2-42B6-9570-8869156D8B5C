<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/C0805014-A6FD-41C1-81BE-B94AE4139F25"><gtr:id>C0805014-A6FD-41C1-81BE-B94AE4139F25</gtr:id><gtr:name>Max Planck Society</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/E135C6B6-8F1E-4403-A0C4-5F0A3F729B93"><gtr:id>E135C6B6-8F1E-4403-A0C4-5F0A3F729B93</gtr:id><gtr:name>Koc University</gtr:name><gtr:address><gtr:line1>Rumelifeneri Yolu</gtr:line1><gtr:line2>34450 Sariyer</gtr:line2><gtr:region>Unknown</gtr:region></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/081FAFFC-0576-4A79-ABCE-FAE0692E1B0D"><gtr:id>081FAFFC-0576-4A79-ABCE-FAE0692E1B0D</gtr:id><gtr:name>Max Planck Institute for Empirical Aesthetics</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:department>Sch of Philosophy Psychology &amp; Language</gtr:department><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/2DB7ED73-8E89-457A-A395-FAC12F929C1A"><gtr:id>2DB7ED73-8E89-457A-A395-FAC12F929C1A</gtr:id><gtr:name>University of Edinburgh</gtr:name><gtr:address><gtr:line1>Old College</gtr:line1><gtr:line2>South Bridge</gtr:line2><gtr:line3>Mayfield Road</gtr:line3><gtr:line4>Edinburgh</gtr:line4><gtr:postCode>EH8 9YL</gtr:postCode><gtr:region>Scotland</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/C0805014-A6FD-41C1-81BE-B94AE4139F25"><gtr:id>C0805014-A6FD-41C1-81BE-B94AE4139F25</gtr:id><gtr:name>Max Planck Society</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/E135C6B6-8F1E-4403-A0C4-5F0A3F729B93"><gtr:id>E135C6B6-8F1E-4403-A0C4-5F0A3F729B93</gtr:id><gtr:name>Koc University</gtr:name><gtr:address><gtr:line1>Rumelifeneri Yolu</gtr:line1><gtr:line2>34450 Sariyer</gtr:line2><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/081FAFFC-0576-4A79-ABCE-FAE0692E1B0D"><gtr:id>081FAFFC-0576-4A79-ABCE-FAE0692E1B0D</gtr:id><gtr:name>Max Planck Institute for Empirical Aesthetics</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/A5DC9BF7-7867-4D98-937B-7610C6B0CEF1"><gtr:id>A5DC9BF7-7867-4D98-937B-7610C6B0CEF1</gtr:id><gtr:firstName>Andrea Eyleen</gtr:firstName><gtr:surname>Martin-Nieuwland</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=ES%2FK009095%2F1"><gtr:id>EC1FD17B-C7A2-42B6-9570-8869156D8B5C</gtr:id><gtr:title>Brain-to-brain coupling during dialogue: What sentence fragments can reveal about 'joint' mental representations</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/K009095/1</gtr:grantReference><gtr:abstractText>Talking to one another is one of the cornerstones and joys of human experience. Imagine how difficult our lives would be if we couldn't use language to communicate, have a conversation, ask questions or easily say what we mean. But actually, we might not even have to say or pronounce all the things that are meant or understood in a conversation (full meanings shown for the reader in brackets):
A: Someone called for you. B: [Did someone] Really [call for me]? 
A: Yes, [someone] really [called for you]. B: Who [called for me]? 
A: John [called for you]. B: About what [did John call]?
Everyday interaction would be completely different if we had to repeat all the information we mean and understand, word for word, during dialogue - it would sure take a lot longer to get anywhere. Although we are not aware of it, most conversation is reduced or simplified into sentence fragments that &amp;quot;stand in&amp;quot; for full formal linguistic structure. Nonetheless, without being pronounced, complex structure is easily understood by both people. This fact clashes with a defining property of human language - a formal correspondence between sound and meaning, and seems to challenge the rules we use to combine linguistic units into larger ones. These seemingly innocuous sentence fragments may be why dialogue is such an easy, effective form of communication. Fragments naturally tap into information exchange during dialogue because they require speakers and listeners to refer to and access a shared memory of what has been said. 
But how do we form and update this shared memory? Speakers must formulate utterances with the mental states of addressees in mind. The reduced fragments people end up producing and hearing operate as a natural &amp;quot;compression algorithm&amp;quot;, making conversation easy and productive most of the time. But how can dialogue be so fragmented without people losing the plot more often? It may well be that aspects of linguistic structures and human memory allow people to 'jointly' activate information, or align their dialogue. In current theory, people align via priming, or passive activation of mental representations between speakers - which is why people often repeat each other's words and phrases. What is rarely noted is how, in order to converse, speaker and listener have to tacitly 'agree on' material that is not overtly expressed, as in the brackets above.
A series of experiments investigates how fragments are represented and transmitted between speakers, and whether the brain treats externally-sourced representations the same as internally-generated ones during dialogue. A second line of research develops an innovative new method that can index the 'flow' of information between speakers' brains during spontaneous, unscripted dialogue. Humans are fundamentally interactive - a fact only recently impacting theories of human cognition, highlighting the necessity of understanding classic cognitive questions in terms of an interaction between two actors in an environment. The basic notion is that real-time interaction, such as dialogue, is made possible by brain-to-brain coupling; where one brain's perceptual system is coupled to another brain's motor or speech output, deriving from a related ability of brains to bind to exogenous environmental signals. These signals, including those emanating from other brains, e.g., speech, are converted into internal signals the brain uses to infer, in turn, about its environment. A brain-to-brain coupling approach for dialogue requires methodological innovation in language research: we need to observe brain activity from two people interacting in real time. My research combines methods and theories from distinct domains of psychology and cognitive neuroscience to develop a novel paradigm for studying real-time interactive dialogue. This funding, if awarded, would allow me to develop my skill set to a degree that I would otherwise not be able to, adding value to my academic training and growth.</gtr:abstractText><gtr:potentialImpactText>Who will benefit from this research?
Because talking to each other and making conversation is such a big part of human life, research on language and dialogue is a natural jumping-off point for increasing public engagement in science. I believe the proposed research, especially the study of language and the brain during interactive dialogue, could have substantial impact outside academia and engage people of all walks of life to learn more about psychology and the science of the human mind. The simple fact that dialogue is a powerful tool for the exchange of information and knowledge transfer, enabling us to transmit information about events that are temporally and spatially remote, highlights an amazing ability in the natural world. 
The key stakeholders (besides the Academic Beneficiaries listed separately) are the general public, the media, and science teachers. Specifically, the end goal for impact would be to make the science of the human mind resonate better with science teachers, children, and young people. This resonance would happen by using everyday daily activities, like having a conversation or asking a question, and unpacking the complex and fascinating human cognition underlying them. Dialogue is a clear input for highlighting the centrality of language and the human mind in everyday life, especially for audiences for whom conversation often happens via texting or online chatting.

How will they benefit?
Seeing 'everyday' things differently. The potential benefits to the key stakeholders from increasing public engagement with language research and the science of the mind come primarily from seeing everyday behaviours, events, and human interactions in a new, compelling and vibrant light. Linking scientific research to tangible, accessible, human behaviours, such as having a conversation or asking and answering questions, will promote the science of mind. I believe this can be accomplished by communicating how human language is unique, and demonstrating how a complex computational system underlies simple human moments. The main benefit would be that people have a deeper understanding of our place in the natural world.

Specifically, I envision three main avenues for promoting the public engagement with the science of the mind and language research: 
(1) Presenting research on language and dialogue at science festivals. 
(2) Generating press releases and lay articles
(3) Building creative partnerships with schools and science museums to feature research on language and the human mind by creating simple interactive presentations and activities.
 Please see the Pathways to Impact statement for my specific goals for increasing public understanding of language and mind research, and my plans on how to achieve them.

Impact outcomes. An outcome of impact would be increasing public interest in the human mind and language, via the understanding of: (1) the uniqueness of human language among naturally occurring communication systems and computations and (2) how our cognitive abilities pervade and enable everyday activities, such having a conversation or asking a question, in ways we never stop to realise. These outcomes could be assessed via science festival attendance numbers, website visits and download numbers for online articles, school activity use and museum installation attendance. Please see the Pathways to Impact statement for more details.</gtr:potentialImpactText><gtr:fund><gtr:end>2017-09-30</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2013-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>253696</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Edinburgh</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Department of Psychology</gtr:department><gtr:description>Abstraction in time: Finding hierarchical linguistic structure in a model of relational processing</gtr:description><gtr:id>9C140B94-58C7-438B-B7DD-0AC9CF0EBD34</gtr:id><gtr:impact>We have published this conference paper and have another paper under revision. Doumas, L. A. A., &amp;amp; Martin, A. E. (2016). Abstraction in time: Finding hierarchical linguistic structure in a model of relational processing. In Proceedings of the 38th Annual Conference of the Cognitive Science Society. Austin, TX: Cognitive Science Society.</gtr:impact><gtr:partnerContribution>Expertise in computational modelling.</gtr:partnerContribution><gtr:piContribution>My theoretical process model is being tested and implemented using both brain data and computational modelling.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Max Planck Society</gtr:collaboratingOrganisation><gtr:country>Germany, Federal Republic of</gtr:country><gtr:department>Max Planck Institute for Psycholinguistics</gtr:department><gtr:description>Decoding cortical linguistic representations</gtr:description><gtr:id>6EDE402D-5177-4948-8B07-8452DCE8A4CF</gtr:id><gtr:impact>Alday, P. &amp;amp; Martin, A. E. (2017) Decoding linguistic representations in the time-frequency domain. Presentation to be given at the Annual Meeting of the Cognitive Neuroscience Society in March 2017.</gtr:impact><gtr:partnerContribution>My collaborator implemented the data processing stream</gtr:partnerContribution><gtr:piContribution>I conceived of the theoretical question and conceptual design of the methods</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Edinburgh</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:department>Department of Psychology</gtr:department><gtr:description>Prospective memory in parsing</gtr:description><gtr:id>23D4B988-A579-4458-A949-43AAB42B73CD</gtr:id><gtr:impact>Grant submitted to Leverhulme is through to the 2nd round. We presented this poster:
Sturt P., &amp;amp; Martin, A. E. (2016). Using grammatical features to forecast incoming structure: The processing of Across-the-board extraction. The 29th annual CUNY. Gainesville, FL, USA.</gtr:impact><gtr:partnerContribution>My partner wrote stimuli, help design the studies, collected the data and analysed it.</gtr:partnerContribution><gtr:piContribution>I helped design experiments and interpret results. I also wrote half of the stimuli.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Koc University</gtr:collaboratingOrganisation><gtr:country>Turkey, Republic of</gtr:country><gtr:description>Hierarchy in cognition and brain function through the lenses of memory and language</gtr:description><gtr:id>D4326821-C7E2-4881-A836-FFFE5F771B10</gtr:id><gtr:impact>We have applied for a Newton Advanced fellowship from the Royal Society but we were not successful.</gtr:impact><gtr:partnerContribution>My collaborator will train me in machine learning approaches to fMRI data analysis and will collect data and give me access to data.</gtr:partnerContribution><gtr:piContribution>My process model will be tested via a series of fMRI experiments we are designing. I will make the stimuli, and help write the papers.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Max Planck Institute for Empirical Aesthetics</gtr:collaboratingOrganisation><gtr:country>Germany, Federal Republic of</gtr:country><gtr:description>Oscillations and sentence processing</gtr:description><gtr:id>14AA3BEB-3F10-4D2F-9A6D-8975B4CDF8BD</gtr:id><gtr:impact>There are no outputs or outcomes yet.</gtr:impact><gtr:partnerContribution>The expertise of the Director of the Neuroscience department has informed my thinking and theorising. I will have access to MEG data from his lab.</gtr:partnerContribution><gtr:piContribution>Collaborative magentoencephalography (MEG) experiments are being planned which will be conducted at the MPI for Empirical Aesthetics in Frankfurt. I am developing and planning the experiments and will present them to collaborators early in May 2017 at a workshop. I will also analyse, model and write up data for the experiments.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Neurobiology of Language Conference (Amsterdam)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>9EB08A36-925D-40CC-9B4C-DE3AAFFFD64C</gtr:id><gtr:impact>I presented 3 posters at the Society for the Neurobiology of Language Conference in Amsterdam in 2014.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited talk and collaboration visit MPI AE Frankfurt</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>F90A7E21-9FC2-442C-B0B3-EA0586C6E52D</gtr:id><gtr:impact>Gave a lecture and met with MSc and PhD students</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Language and Attention Conference (Mainz, Germany)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>CF978D8A-04C9-42DB-A993-A7130EF24AD1</gtr:id><gtr:impact>50 people attended an invited talk I gave at a conference on Language and Attention.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Sentence Processing Conference &quot;Architectures and Mechanisms for Language Processing&quot; (AMLaP, Edinburgh and Malta)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>C89BBF83-6344-4A33-8D1A-8403B26D8A87</gtr:id><gtr:impact>About 350 people attended a talk I gave at the Edinburgh AMLaP in 2014, I also presented a poster there that had about 40 attendees. I presented a poster that had about 30 attendees at the Malta AMLaP conference in 2014.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2014,2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Sentence Processing Conference of the City University of New York (CUNY, Los Angeles, CA; Gainesville, FL)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>9E53F35F-206F-45FF-AE8D-F103185DB30A</gtr:id><gtr:impact>I presented a talk and poster at the CUNY sentence processing conference in Los Angeles in 2015, and I will present a poster at the CUNY conference in Gainesville, FL in March 2016.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited talk MPI Frankfurt</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>AF5D5BCE-D352-43C2-B9FA-D8EDE67BE61A</gtr:id><gtr:impact>I given two invited talks at the MPI for Empirical Aesthetics in Frankfurt in 2015 and 2016 leading to ongoing collaboration.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2015,2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>EEG Open day</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>B7F90057-CD62-4766-90BD-ACB62929C7CD</gtr:id><gtr:impact>Around 50 students and research participants attended an open day to visit the research facility, we gave a demo on EEG using headsets, this sparked questions and discussion and many people enjoyed using the headsets. We had a spike in student projects/inquiries following the demo.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs><gtr:researchMaterialOutput><gtr:description>I and my collaborator Phillip Alday have developed a new way to analyze EEG and relate it to language representations, including during dialogue.</gtr:description><gtr:id>CC142E08-A9BA-478B-94C9-FDA1DD628A2B</gtr:id><gtr:impact>We are presenting an example of this method at conferences in March and April 2017 and are at work at writing a paper.</gtr:impact><gtr:providedToOthers>false</gtr:providedToOthers><gtr:title>Time-frequency decoding data pipeline</gtr:title><gtr:type>Improvements to research infrastructure</gtr:type></gtr:researchMaterialOutput></gtr:researchMaterialOutputs><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/7DA1115B-4CF0-422D-94F5-A454DA4BE4EF"><gtr:id>7DA1115B-4CF0-422D-94F5-A454DA4BE4EF</gtr:id><gtr:title>How robust are prediction effects in language comprehension? Failure to replicate article-elicited N400 effects</gtr:title><gtr:parentPublicationTitle>Language, Cognition and Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/328c69408dfe296d6822d1749305ba4f"><gtr:id>328c69408dfe296d6822d1749305ba4f</gtr:id><gtr:otherNames>Ito A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/7863DFDE-C281-4CEA-8B9B-664889B6BD9F"><gtr:id>7863DFDE-C281-4CEA-8B9B-664889B6BD9F</gtr:id><gtr:title>Predicting form and meaning: Evidence from brain potentials</gtr:title><gtr:parentPublicationTitle>Journal of Memory and Language</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/328c69408dfe296d6822d1749305ba4f"><gtr:id>328c69408dfe296d6822d1749305ba4f</gtr:id><gtr:otherNames>Ito A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/5296E199-9986-4926-BDA2-1BD29459704B"><gtr:id>5296E199-9986-4926-BDA2-1BD29459704B</gtr:id><gtr:title>Agreement attraction during comprehension of grammatical sentences: ERP evidence from ellipsis.</gtr:title><gtr:parentPublicationTitle>Brain and language</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d47967305a5025e58920395d9d2e59ec"><gtr:id>d47967305a5025e58920395d9d2e59ec</gtr:id><gtr:otherNames>Martin AE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0093-934X</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/8A416E00-7DB6-4CB5-8D59-CDFF7EC15F00"><gtr:id>8A416E00-7DB6-4CB5-8D59-CDFF7EC15F00</gtr:id><gtr:title>Language Processing as Cue Integration: Grounding the Psychology of Language in Perception and Neurophysiology.</gtr:title><gtr:parentPublicationTitle>Frontiers in psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d47967305a5025e58920395d9d2e59ec"><gtr:id>d47967305a5025e58920395d9d2e59ec</gtr:id><gtr:otherNames>Martin AE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1664-1078</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/566D0DAE-FB52-4AF9-84CD-44A1A4127300"><gtr:id>566D0DAE-FB52-4AF9-84CD-44A1A4127300</gtr:id><gtr:title>Prediction of Agreement and Phonetic Overlap Shape Sublexical Identification</gtr:title><gtr:parentPublicationTitle>Language and Speech</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/2c872ff41113538ab773e310298450ec"><gtr:id>2c872ff41113538ab773e310298450ec</gtr:id><gtr:otherNames>Martin A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/3F023486-9225-4F12-B727-4ECE599BAB3A"><gtr:id>3F023486-9225-4F12-B727-4ECE599BAB3A</gtr:id><gtr:title>Neural Oscillations and a Nascent Corticohippocampal Theory of Reference</gtr:title><gtr:parentPublicationTitle>Journal of Cognitive Neuorscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/cabcfbdfc99df9d0eb39fa4079523815"><gtr:id>cabcfbdfc99df9d0eb39fa4079523815</gtr:id><gtr:otherNames>Nieuwland MS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/5DFEEF86-1DB6-4672-B41D-89E90F3058E7"><gtr:id>5DFEEF86-1DB6-4672-B41D-89E90F3058E7</gtr:id><gtr:title>Abstraction in time: Finding hierarchical linguistic structure in a model of relational processing</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/0b1d12e6e48dd3df39b440174452c3ba"><gtr:id>0b1d12e6e48dd3df39b440174452c3ba</gtr:id><gtr:otherNames>Doumas LAA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/4D847232-1AE3-4EAD-A157-3C283B222C2C"><gtr:id>4D847232-1AE3-4EAD-A157-3C283B222C2C</gtr:id><gtr:title>Predicting form and meaning: Evidence from ERPs.</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/328c69408dfe296d6822d1749305ba4f"><gtr:id>328c69408dfe296d6822d1749305ba4f</gtr:id><gtr:otherNames>Ito A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/2A81CEE4-E230-4ADD-A285-BD83A43829CB"><gtr:id>2A81CEE4-E230-4ADD-A285-BD83A43829CB</gtr:id><gtr:title>A neural oscillatory signature of reference</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/cabcfbdfc99df9d0eb39fa4079523815"><gtr:id>cabcfbdfc99df9d0eb39fa4079523815</gtr:id><gtr:otherNames>Nieuwland MS</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/F791B7DC-2831-48EA-A637-4A700EA5BB53"><gtr:id>F791B7DC-2831-48EA-A637-4A700EA5BB53</gtr:id><gtr:title>A mechanism for the cortical computation of hierarchical linguistic structure</gtr:title><gtr:parentPublicationTitle>PLoS Biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d47967305a5025e58920395d9d2e59ec"><gtr:id>d47967305a5025e58920395d9d2e59ec</gtr:id><gtr:otherNames>Martin AE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/K009095/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>B94A2498-60DA-4055-A957-686B6CB42654</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Linguistics</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>E457FFDE-A4C1-4907-AE12-A394D95A3AE5</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Cognitive Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>699D8438-2A43-4BCF-B1A4-6240ED82CEEE</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Human Communication in ICT</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>7B8CEF0E-4DA8-4D0E-812A-5B92663E5EB9</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psycholinguistics</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>