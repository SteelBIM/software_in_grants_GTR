<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/44160F04-5CBF-4E8E-A6C6-C0EF61A5865C"><gtr:id>44160F04-5CBF-4E8E-A6C6-C0EF61A5865C</gtr:id><gtr:name>Lancaster University</gtr:name><gtr:department>Computing &amp; Communications</gtr:department><gtr:address><gtr:line1>University House</gtr:line1><gtr:line4>Lancaster</gtr:line4><gtr:line5>Lancashire</gtr:line5><gtr:postCode>LA1 4YW</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/44160F04-5CBF-4E8E-A6C6-C0EF61A5865C"><gtr:id>44160F04-5CBF-4E8E-A6C6-C0EF61A5865C</gtr:id><gtr:name>Lancaster University</gtr:name><gtr:address><gtr:line1>University House</gtr:line1><gtr:line4>Lancaster</gtr:line4><gtr:line5>Lancashire</gtr:line5><gtr:postCode>LA1 4YW</gtr:postCode><gtr:region>North West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/A5C9D5E0-181F-4A32-98C2-8F213015A36C"><gtr:id>A5C9D5E0-181F-4A32-98C2-8F213015A36C</gtr:id><gtr:name>SR Research Ltd</gtr:name><gtr:address><gtr:line1>SR Research Ltd</gtr:line1><gtr:line2>5516 Main Street</gtr:line2><gtr:line4>Osgoode</gtr:line4><gtr:line5>ON</gtr:line5><gtr:postCode>K0A 2W0</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>Canada</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/024053CA-92D2-4676-B8EC-29BF8FE07C4F"><gtr:id>024053CA-92D2-4676-B8EC-29BF8FE07C4F</gtr:id><gtr:name>NIHR CRN: North West Coast</gtr:name><gtr:address><gtr:line1>Liverpool Science Park</gtr:line1><gtr:line2>Innovation Centre 1</gtr:line2><gtr:line3>131 Mount Pleasant</gtr:line3><gtr:postCode>L3 5TF</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/74F12374-E00A-4831-904A-B9F3D3E5C2E8"><gtr:id>74F12374-E00A-4831-904A-B9F3D3E5C2E8</gtr:id><gtr:name>Lancashire Care NHS Foundation Trust</gtr:name><gtr:address><gtr:line1>Queens Park Hospital</gtr:line1><gtr:line2>Haslingden Road</gtr:line2><gtr:postCode>BB2 3HH</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/2404B774-64FF-4466-84B9-7C440C465071"><gtr:id>2404B774-64FF-4466-84B9-7C440C465071</gtr:id><gtr:firstName>Pete</gtr:firstName><gtr:surname>Sawyer</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/4DD9C43A-345B-4FDF-8F92-8B0C746A27A1"><gtr:id>4DD9C43A-345B-4FDF-8F92-8B0C746A27A1</gtr:id><gtr:firstName>Rebecca</gtr:firstName><gtr:surname>Killick</gtr:surname><gtr:orcidId>0000-0003-0583-3960</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/AFBAE0F9-0019-4E90-BAA9-46BE25FAB6E1"><gtr:id>AFBAE0F9-0019-4E90-BAA9-46BE25FAB6E1</gtr:id><gtr:firstName>Iracema</gtr:firstName><gtr:surname>Leroi</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/2C64963C-FAB7-4BED-B01E-B003E6AC2696"><gtr:id>2C64963C-FAB7-4BED-B01E-B003E6AC2696</gtr:id><gtr:firstName>Trevor</gtr:firstName><gtr:surname>Crawford</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/1039F264-C039-470E-8406-6BEC2796FDE1"><gtr:id>1039F264-C039-470E-8406-6BEC2796FDE1</gtr:id><gtr:firstName>Kwang In</gtr:firstName><gtr:surname>Kim</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/9CCD79AA-7EB2-4DC0-9C7F-BB94BF0FF609"><gtr:id>9CCD79AA-7EB2-4DC0-9C7F-BB94BF0FF609</gtr:id><gtr:firstName>Hans</gtr:firstName><gtr:surname>Gellersen</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FM006255%2F1"><gtr:id>3818D17A-B855-4FCD-BF3A-3A72DE2441E1</gtr:id><gtr:title>MODEM - Monitoring Of Dementia using Eye Movements</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M006255/1</gtr:grantReference><gtr:abstractText>There is mounting evidence that deficits in saccadic and smooth pursuit eye movements are characteristic of dementia. These deficits can be detected in a lab or clinical setting using specialised eye-tracking equipment but this is inconvenient for the patient, costly for the NHS and introduces the risk of sampling bias because clinic visits are inevitably intermittent. The aim of the Monitoring Of Dementia using Eye Movements (MODEM) project is to enable the longitudinal collection of data at low cost and with minimal inconvenience, to provide a novel platform for prognosis and diagnosis of dementia. 

We propose to tackle monitoring of disease progression with in-home eye tracking and computational analysis of eye movement embedded with patients' everyday activity. This is an entirely novel approach, and hence high risk. However, it has the potential to lead to major breakthroughs, for three reasons: (i) Eye movement and cognitive health are closely linked, including initial evidence of markers for dementia diagnosis. (ii) Eye trackers are on the verge of a step change from lab instrument to widely deployed sensor, and their adoption for contact-less health monitoring is becoming a realistic proposition. (iii) People/patients use their eyes in daily routines that are visually engaging, and that present rich contexts for collection of information about how their eye movement changes over time, as a function of disease progression.

Our vision is that rather than patients having to attend a clinic or laboratory, eye movement data can be collected in settings where the technology is ambient and peoples' behaviour is relaxed and natural. The target settings are peoples' own homes and care homes. Eye trackers can be placed strategically to observe eye movement in the context of everyday tasks. For example they can be used to track hand-eye coordination in routine tasks such as tea-making for possible signs of change; these might signal cognitive decline long before routines become more obviously affected. Eye trackers can also be deployed interactively. People spend significant amounts of their daily lives as consumers of visual media, especially through TV, which affords interactive stimulation of eye movement. For example, content (e.g. TV programmes) can be designed to elicit behaviours of interest for diagnosis. People can also be provided with active gaze controls for interaction, for instance as alternative to remote control functions of a TV. Use of gaze for control stimulates specific eye movements which can be used for testing. Though beyond the scope project, this could also lead to therapeutic application of the technology. Moreover, as eye trackers are based on cameras and computer vision, this opens up avenues for integration with other vision-based approaches such as analysis of facial expressions, for multimodal cognitive health analysis.</gtr:abstractText><gtr:potentialImpactText>Beneficiaries include 

The NHS will benefit because 
- the means for continuous tracking of the progression of dementia in domestic settings has the potential to yield cost savings associated with people periodically attending memory clinics.
- MODEM technology will yield continuous rather than fragmentary data, providing data sets of a size that should improve the fidelity of insights into the progression of dementia in an individual, and when aggregated across the population, provide significant insights into how the condition progresses.

Government and wider society will benefit because MODEM will contribute to the G8 Dementia Challenge's priorities and lead to cost savings and quality of life improvements for dementia sufferers and their carers, allowing (e.g.) mitigating interventions at thepoint where behavioural changes are probable. 

Industry has the potential to benefit, particularly:
- The UK video games industry is already set to benefit from on-going advances in eye-tracking technology, but MODEM is likely to lead to unique developments in the integration of gaze and interaction. Using this as the means for intervention in eye-tracking for dementia will have potential analogues that are exploitable for games design.
- TV manufacturers may also benefit from MODEM's integration of camera and display technology, not only using eye-tracking to (e.g.) infer the locus of peoples' attention, but also more generally to e.g. infer who is watching and tailor the display to their favoured volume, brightness, etc. This generalises to other display manufacturers and content providers.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-03-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2015-03-31</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>950403</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Poster at Alzheimer's Research UK (March 2016): MoDEM: Monitoring of dementia using eye movements</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>29B060C5-AA09-48E3-A871-2A4AE6008286</gtr:id><gtr:impact>The poster presentation gave MoDEM a presence at the Alzheimer's Research UK's annual conference in 2016. Many attendees representing various stakeholder types expressed in terse in MoDEM.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>https://alzres.biomedcentral.com/articles/10.1186/s13195-016-0203-0</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>UBISS summer school</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>7F6EFA84-85A8-409D-8951-75D5F74C6B5A</gtr:id><gtr:impact>13 Postgraduate students from around the world attended a week-long workshop on eye tracking and eye movement analysis, influencing postgraduate research internationally.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Introduction to human eye-tracking - Invited talk at SynaNET, Lancaster, given by Dr Thom Wilcockson</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>EBAE9985-2650-4C7F-9401-44236EDAA7DE</gtr:id><gtr:impact>The workshop covered current research and topics in the use of behavioural approaches to study brain function, in health and in disease, in model organisms and in humans. The workshop consisted of both lectures and practical sessions, giving both theoretic and practical insight into the application of these approaches. These sessions were delivered by both SynaNET members and other international experts in the field. Participants developed a greater knowledge of the behavioural paradigms used in both model organisms and in humans.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:url>http://www.synanet2020.com/activities/workshops/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Eye movements and Neuropsychology - an Invited talk to H2020 SynaNET project given by Dr Trevor Crawford</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>0E43C65E-15E2-4F83-AD3C-0B97670C49B3</gtr:id><gtr:impact>The workshop covered current research and topics in the use of behavioural approaches to study brain function, in health and in disease, in model organisms and in humans. The workshop consisted of both lectures and practical sessions, giving both theoretic and practical insight into the application of these approaches. These sessions were delivered by both SynaNET members and other international experts in the field. Participants developed a greater knowledge of the behavioural paradigms used in both model organisms and in humans.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:url>http://www.synanet2020.com/activities/workshops/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Dr Trevor Crawford &amp; Dr Thom Wilcockson were Interviewed for the Joint Dementia Research website</gtr:description><gtr:form>Engagement focused website, blog or social media channel</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>DDA5D4BC-19D0-4A3C-A258-9775BE475EB5</gtr:id><gtr:impact>JDR is an NHS NIHR website designed to publicise dementia research and help recruit trial participants. Our interview led to a summary article about MoDEM on the JDR site. It has helped us recruit participants for our eye-tracking experiments which are generating large volumes of data that are beginning to translate in to new discoveries.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Study participants or study members</gtr:primaryAudience><gtr:url>http://news.joindementiaresearch.nihr.ac.uk/can-dementia-diagnosed-eye-movement/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Participation in EPSRC Healthy Nation video</gtr:description><gtr:form>A broadcast e.g. TV/radio/film/podcast (other than news/press)</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>33BCB98B-7AB7-448F-9C3E-5E5BCEBEC4CA</gtr:id><gtr:impact>The video featured a brief section on MoDEM, it's aims and envisioned technologies.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>https://www.youtube.com/watch?v=EXPf9uau4Do</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The work (and that of EP/K015796/1) was presented at a Dementia Futures event in Lancaster Town Hall on 18th September 2015.

https://www.youtube.com/watch?v=UAD_aaUUAIk</gtr:description><gtr:firstYearOfImpact>2015</gtr:firstYearOfImpact><gtr:id>E8CAED73-856C-4455-B3C4-36437E25FD8A</gtr:id><gtr:impactTypes><gtr:impactType>Cultural,Societal</gtr:impactType></gtr:impactTypes><gtr:sector>Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>As an interim finding, it appears to be possible to use machine learning to classify subjects as healthy, suffering from mild cognitive impairment or alzheimer's disease from pro-saccadic oscillations of their eyes in laboratory experiments. 

This work is being written up for journal submissions, so is not in the public domain yet.</gtr:description><gtr:exploitationPathways>The results have two primary potential uses:

- as a clinical diagnostic tool, perhaps as part of a battery of cognitive tests.

- as a feature that might be built in to an ambient eye-monitoring system which itself might form part of a health monitoring system for older adults living alone.</gtr:exploitationPathways><gtr:id>4362B4C9-36EE-492D-882F-A798F5DEF30B</gtr:id><gtr:sectors><gtr:sector>Communities and Social Services/Policy,Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/AF1196EE-1712-480A-B9D9-BEEF3104B88D"><gtr:id>AF1196EE-1712-480A-B9D9-BEEF3104B88D</gtr:id><gtr:title>Distinguishing between impairments of working memory and inhibitory control in cases of early dementia.</gtr:title><gtr:parentPublicationTitle>Neuropsychologia</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/1724af6c91b7e4e53f5a77518f1a7376"><gtr:id>1724af6c91b7e4e53f5a77518f1a7376</gtr:id><gtr:otherNames>Crawford TJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0028-3932</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/831BE4EF-8EC4-4BE6-BED4-100673D9904B"><gtr:id>831BE4EF-8EC4-4BE6-BED4-100673D9904B</gtr:id><gtr:title>The disengagement of visual attention in Alzheimer's disease: a longitudinal eye-tracking study.</gtr:title><gtr:parentPublicationTitle>Frontiers in aging neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/1724af6c91b7e4e53f5a77518f1a7376"><gtr:id>1724af6c91b7e4e53f5a77518f1a7376</gtr:id><gtr:otherNames>Crawford TJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1663-4365</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/233491EE-D02B-4ED8-A30C-00423FCDD847"><gtr:id>233491EE-D02B-4ED8-A30C-00423FCDD847</gtr:id><gtr:title>Monitoring of Dementia using Eye Movements</gtr:title><gtr:parentPublicationTitle>Psychology of Older People: FPOP Bulletin</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/05c2342d6a895eb8fbdabce1f131d03a"><gtr:id>05c2342d6a895eb8fbdabce1f131d03a</gtr:id><gtr:otherNames>Wilcockson T</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/686C6CE2-2336-47B8-9BC5-CA0F767EE799"><gtr:id>686C6CE2-2336-47B8-9BC5-CA0F767EE799</gtr:id><gtr:title>Intelligent Decision Technologies 2016</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d895db59e431e55ec84105d0da4fab0d"><gtr:id>d895db59e431e55ec84105d0da4fab0d</gtr:id><gtr:otherNames>Zhang Y</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:isbn>978-3-319-39626-2</gtr:isbn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M006255/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6BF947B0-8E6E-48DB-AB68-7130938F2DF2</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Instrument. sensor &amp; detectors</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F78E4567-DD59-4364-9D1F-0A778996E941</gtr:id><gtr:percentage>50</gtr:percentage><gtr:text>Instrumentation Eng. &amp; Dev.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>