<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/8225A536-700C-446D-9242-29C77BC2E15E"><gtr:id>8225A536-700C-446D-9242-29C77BC2E15E</gtr:id><gtr:name>National Institute of Informatics, Tokyo</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/89E6D9CB-DAF8-40A2-A9EF-B330A5A7FC24"><gtr:id>89E6D9CB-DAF8-40A2-A9EF-B330A5A7FC24</gtr:id><gtr:name>Open University</gtr:name><gtr:department>Computing</gtr:department><gtr:address><gtr:line1>Walton Hall</gtr:line1><gtr:line2>Walton</gtr:line2><gtr:line4>Milton Keynes</gtr:line4><gtr:line5>Buckinghamshire</gtr:line5><gtr:postCode>MK7 6AA</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/89E6D9CB-DAF8-40A2-A9EF-B330A5A7FC24"><gtr:id>89E6D9CB-DAF8-40A2-A9EF-B330A5A7FC24</gtr:id><gtr:name>Open University</gtr:name><gtr:address><gtr:line1>Walton Hall</gtr:line1><gtr:line2>Walton</gtr:line2><gtr:line4>Milton Keynes</gtr:line4><gtr:line5>Buckinghamshire</gtr:line5><gtr:postCode>MK7 6AA</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/8225A536-700C-446D-9242-29C77BC2E15E"><gtr:id>8225A536-700C-446D-9242-29C77BC2E15E</gtr:id><gtr:name>National Institute of Informatics, Tokyo</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/D90735BD-8E6A-4116-AD9F-FA66BCD5FE36"><gtr:id>D90735BD-8E6A-4116-AD9F-FA66BCD5FE36</gtr:id><gtr:firstName>Paul</gtr:firstName><gtr:surname>Piwek</gtr:surname><gtr:orcidId>0000-0003-1621-6124</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FG020981%2F1"><gtr:id>E88115BA-12E2-4E80-8298-1F62AAB293FD</gtr:id><gtr:title>CODA: COherent Dialogue Automatically generated from text</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/G020981/1</gtr:grantReference><gtr:abstractText>The CODA (COherent Dialogue Automatically generated from text) project will make a contribution to realizing the UK Government's Council for Science and Technology's vision of `providing people with services and information when, where and how they need it [...] Interaction will be through next generation personal digital assistants [...] and doubtlessly a variety of other human-oriented methods as yet unforeseen'. CODA will help achieve this by developing the theory and technology for automatically creating dialogue content from text in monologue form. There is ample empirical evidence that presentation of information in the form of a dialogue can be more effective than monologue in certain settings (e.g., tutoring and persuasive communication). Since most information is, however, locked up in text (books, leaflets, webpages, etc.), text-to-dialogue generation technology can play an important role in making information available in a form that best meets people's needs for easily processible and engaging information. The effectiveness of dialogue is magnified by the fact that it is eminently suitable for new multimedia presentation styles - e.g., a dialogue can be performed by digital computer-animated characters. Thus, presentation of information in dialogue form promises to not only deliver effective information presentation, but also entertain and engage people, as evidenced by the widespread use of dialogue in conventional media, such as news bulletins, commercials, educational entertainment and games. The proposed research builds on a preliminary feasibility study that was undertaken in collaboration with Dr. Prendinger at the National Institute of Informatics (Tokyo). That research led to a first prototype that takes a patient information leaflet with text such as: You can use aspirin, if you have a headache. Though aspirin does have side effects: it can harm the circulation. , and automatically generates a dialogue between a virtual pharmacist and client: C: What if I have a headache? P: You can use aspirin. C: But does it have side effects? P: Yes, it can harm the circulation. . Dr. Prendinger is proposed as Visiting Researcher for the current project.The project will develop the aforementioned first prototype into a domain-independent system for the generation of dialogue from text such that the meaning of the input text is preserved and the resulting dialogue is both coherent and cohesive. It will also produce the, to our knowledge, first extensive collection of text spans paired with snippets of dialogue that are equivalent in meaning (a parallel text-dialogue corpus). This corpus will be used in the project to learn transformations from text to dialogue that the system will then implement. During the second half of the project, a thorough evaluation of the system will take place to determine the quality of the content and organization of the generated dialogues. It will be applied to input texts from a variety domains to put its robustness/domain-independence to the test. We anticipate that if successful, this project will lead to potentially commercially exploitable middle-ware for bridging the gap between content locked up in text and effective and engaging presentations of information through state-of-the-art multimedia presentation tools, with applications in education (presentation of textbook materials), E-health (presenting medical information in an engaging way), and serious/educational games (automatic generation of dialogue content for non-player characters).</gtr:abstractText><gtr:fund><gtr:end>2011-07-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2009-07-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>170692</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>National Institute of Informatics, Tokyo</gtr:collaboratingOrganisation><gtr:country>Japan</gtr:country><gtr:description>Ongoing collaboration with NII Tokyo</gtr:description><gtr:id>74AD92B9-57BC-454C-A3A7-3728B746BE84</gtr:id><gtr:impact>Conference paper at IVA 2012 conference.</gtr:impact><gtr:partnerContribution>Research collaboration and software development.</gtr:partnerContribution><gtr:piContribution>Publication of follow-up research at IVA conference. 

Research visit by Piwek February 16-25, 2015 to NII, funded by NII.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Papworth trust information: from leaflets to dialogue</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>C7EC3F67-1D16-479B-8FAA-604632937617</gtr:id><gtr:impact>The Papworth Trust commissioned two videos based on their information leaflets for service users. The content of the videos is prepared using the CODA Monologue-to-Dialogue technology. The videos are available on the Papworth Trust's YouTube Channel: User Involvement Promise (see http://www.youtube.com/watch?v=Tb-MkbwAneY) and Feedback (see http://www.youtube.com/watch?v=A2jLwvJ_kE8) and on the trust's Getting involved page.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Participants in your research and patient groups</gtr:primaryAudience><gtr:url>http://www.youtube.com/watch?v=A2jLwvJ_kE8</gtr:url><gtr:year>2011</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>12000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Studentship funding directly by employer (WDS/Xerox) of student</gtr:description><gtr:end>2021-06-02</gtr:end><gtr:fundingOrg>Xerox Europe</gtr:fundingOrg><gtr:fundingRef>N/A</gtr:fundingRef><gtr:id>2AA623E3-07D3-4982-9C7E-2BD41E218652</gtr:id><gtr:sector>Private</gtr:sector><gtr:start>2015-06-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The dialogue from text generation technology was used by the Papworth trust to create videos for two of their information leaflets. These videos were used on their website to inform service users. See http://computing.open.ac.uk/coda/publicity.html</gtr:description><gtr:firstYearOfImpact>2011</gtr:firstYearOfImpact><gtr:id>29C82E25-A5BD-4966-B728-FCBA58927A07</gtr:id><gtr:impactTypes><gtr:impactType>Societal</gtr:impactType></gtr:impactTypes><gtr:sector>Communities and Social Services/Policy,Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The main aim of the CODA project was to develop the theory and technology for automatically transforming text into coherent and cohesive expository -- i.e., information delivering -- dialogue, such that the transformation from text to dialogue preserves the informational content of the input text. This aim involved four equally important objectives: 1) Creation of the, to our knowledge, first parallel corpus of text-dialogue pairs; 2) Formulation of transformation rules based on the corpus which relate certain patterns in text in monologue form (in particular, underlying coherence relations) to patterns in dialogue (specific dialogue acts, moves or structures); 3) Implementation of the transformations in a system for text-to-dialogue generation; 4) Evaluation of content and organization of the dialogues that the system generates.</gtr:description><gtr:exploitationPathways>The Papworth Trust commissioned two videos based on their information leaflets for service users. The content of the videos was prepared using the CODA Monologue-to-Dialogue technology. The videos are available on the Papworth Trust's Homepage and their YouTube Channel: http://www.youtube.com/user/papworthtrust#p/u/0/Tb-MkbwAneY and http://www.youtube.com/user/papworthtrust#p/u/1/A2jLwvJ_kE8. Bored with reading the instructions? Watch and listen instead!



Information leaflets may soon be more than just a piece of paper. Research at The Open University has made significant steps towards changing the way information is conveyed by translating text into dialogue, while preserving clarity and meaning. The EPSRC-funded project, Coherent Dialogue Automatically Generated from Text (CODA), has developed the theory and technology for semi-automatic conversion of text to dialogue. It is specifically geared towards creating conversations between lay people and experts, for example, a patient and doctor.



Despite evidence supporting the fact that dialogue is more effective than monologue in tutoring and persuasive communication, most information is still locked up in text, including books, leaflets or web pages.



Text-to-dialogue generation technology can play an important role in making information available in a form that best meets people's needs when processing information. Dialogue is much more suitable for new multimedia presentation styles and can, for example, be performed by digital computer-animated characters.</gtr:exploitationPathways><gtr:id>94BC5553-21F6-46F8-B266-23D0592EAA43</gtr:id><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:sectors><gtr:url>http://computing.open.ac.uk/coda/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>CODA corpus Release 1.0 July 16, 2010. This release contains approximately 700 turns of human-authored expository dialogue (by Mark Twain and George Berkeley) which has been aligned with monologue that expresses the same information as the dialogue. The monologue side is annotated with Coherence Relations (RST), and the dialogue side with Dialogue Act tags.</gtr:description><gtr:id>EA94CE46-A89D-4623-972A-5E22BF3F134F</gtr:id><gtr:impact>The monologue-to-dialogue corpus has been released to the research community (100 downloads, including Carnegie Mellon and Xerox).</gtr:impact><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>CODA corpus</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://computing.open.ac.uk/coda/data.html</gtr:url><gtr:yearFirstProvided>2010</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>CODA Tools software Release 1.1 February 20, 2012. This release contains 1) software for converting text parsed with RST relations into dialogue and 2) an anotation tool for annotating dialogue and translating it into monologue (used for creating CODA corpus).</gtr:description><gtr:id>E95860C6-3B73-41C6-801B-CCA0D7C65B48</gtr:id><gtr:impact>Downloaded by researchers at several research establishments, including Takamura lab at Tokyo Institute of Technology, Hankuk University of Foreign Studies (South Korea), Cornell and Columbia Universities.</gtr:impact><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>CODA Tools</gtr:title><gtr:type>Computer model/algorithm</gtr:type><gtr:url>http://computing.open.ac.uk/coda/data.html</gtr:url><gtr:yearFirstProvided>2012</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput><gtr:researchDatabaseAndModelOutput><gtr:description>QGSTEC 2010 Generating Questions from Sentences Corpus December 21, 2010. A corpus of over 1000 questions (both human and machine generated). The automatically generated questions have been rated by several raters according to five criteria (relevance, question type, syntactic correctness and fluency, ambiguity, and variety).</gtr:description><gtr:id>9A950F35-997A-4F51-9EDC-B72670F3B620</gtr:id><gtr:impact>The QGSTEC development, evaluation and results data were made available to the research community (54 downloads so far from groups including IBM, MITRE, Univ. of Tuebingen, Michigan, and Pittsburgh).</gtr:impact><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>QG Corpus</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://computing.open.ac.uk/coda/data.html</gtr:url><gtr:yearFirstProvided>2010</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/D196AAC7-35F8-4582-9919-25358E696EE5"><gtr:id>D196AAC7-35F8-4582-9919-25358E696EE5</gtr:id><gtr:title>Intelligent Virtual Agents</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/f69b2aa438a6b03fdc2a6094698a0533"><gtr:id>f69b2aa438a6b03fdc2a6094698a0533</gtr:id><gtr:otherNames>Kuyten P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:isbn>978-3-642-33196-1</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/DAED0DEB-DFE2-48A6-9758-588C7505F085"><gtr:id>DAED0DEB-DFE2-48A6-9758-588C7505F085</gtr:id><gtr:title>The CODA System for Monologue-to-Dialogue Generation</gtr:title><gtr:parentPublicationTitle>Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/21a4ea04bef53c8308e96f3ab3454519"><gtr:id>21a4ea04bef53c8308e96f3ab3454519</gtr:id><gtr:otherNames>stoyanchev s</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/79750773-F956-49D2-A2CB-C62D38D4BAC2"><gtr:id>79750773-F956-49D2-A2CB-C62D38D4BAC2</gtr:id><gtr:title>Harvesting re-usable high-level rules for expository dialogue generation</gtr:title><gtr:parentPublicationTitle>6th International Natural Language Generation Conference (INLG 2010)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/21a4ea04bef53c8308e96f3ab3454519"><gtr:id>21a4ea04bef53c8308e96f3ab3454519</gtr:id><gtr:otherNames>stoyanchev s</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/2B9478BA-B7F2-4030-8E61-FD22C05880A9"><gtr:id>2B9478BA-B7F2-4030-8E61-FD22C05880A9</gtr:id><gtr:title>A Detailed Account of The First Question Generation Shared Task Evaluation Challenge</gtr:title><gtr:parentPublicationTitle>Dialogue &amp; Discourse</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/7b311e59f7c9ea75eb6fd5bda3882151"><gtr:id>7b311e59f7c9ea75eb6fd5bda3882151</gtr:id><gtr:otherNames>Rus V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/20B2DC5A-4BAD-463F-B79B-38B069D05598"><gtr:id>20B2DC5A-4BAD-463F-B79B-38B069D05598</gtr:id><gtr:title>Constructing the CODA Corpus: A Parallel Corpus of Monologues and Expository Dialogues</gtr:title><gtr:parentPublicationTitle>7th international conference on Language Resources and Evaluation (LREC) 2010</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/21a4ea04bef53c8308e96f3ab3454519"><gtr:id>21a4ea04bef53c8308e96f3ab3454519</gtr:id><gtr:otherNames>stoyanchev s</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/41DEEBAD-9484-478F-A9B0-098F4AE6B2A7"><gtr:id>41DEEBAD-9484-478F-A9B0-098F4AE6B2A7</gtr:id><gtr:title>Varieties of Question Generation: Introduction to this Special Issue</gtr:title><gtr:parentPublicationTitle>Dialogue &amp; Discourse</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/87ee933615ae9aa64daa119a5c06adfd"><gtr:id>87ee933615ae9aa64daa119a5c06adfd</gtr:id><gtr:otherNames>Piwek P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/98EE0A02-7C27-400F-9264-477B08634128"><gtr:id>98EE0A02-7C27-400F-9264-477B08634128</gtr:id><gtr:title>Generating Expository Dialogue from Monologue:Motivation, Corpus and Preliminary Rules</gtr:title><gtr:parentPublicationTitle>11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) 2010</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/58948b22684af7435bdad2dc1d95930d"><gtr:id>58948b22684af7435bdad2dc1d95930d</gtr:id><gtr:otherNames>piwek, p</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/F284303E-6995-4ACA-A283-63EFFC4944FA"><gtr:id>F284303E-6995-4ACA-A283-63EFFC4944FA</gtr:id><gtr:title>Data-oriented Monologue-to-Dialogue Generation</gtr:title><gtr:parentPublicationTitle>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: shortpapers</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/1857d073ef563ad39d46460acc9d7826"><gtr:id>1857d073ef563ad39d46460acc9d7826</gtr:id><gtr:otherNames> piwek p</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/B6A34AC8-92D3-418D-A21E-5A4E652515DA"><gtr:id>B6A34AC8-92D3-418D-A21E-5A4E652515DA</gtr:id><gtr:title>Dialogue across Media</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/87ee933615ae9aa64daa119a5c06adfd"><gtr:id>87ee933615ae9aa64daa119a5c06adfd</gtr:id><gtr:otherNames>Piwek P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:isbn>978 90 272 1045 6</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/66DB4925-69AD-4744-AE0B-33CE9A55A5CA"><gtr:id>66DB4925-69AD-4744-AE0B-33CE9A55A5CA</gtr:id><gtr:title>Intelligent Virtual Agents</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/a5ca48f46e97afd321603d40e381cf94"><gtr:id>a5ca48f46e97afd321603d40e381cf94</gtr:id><gtr:otherNames>Stoyanchev S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:isbn>978-3-642-23973-1</gtr:isbn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/G020981/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>B94A2498-60DA-4055-A957-686B6CB42654</gtr:id><gtr:percentage>75</gtr:percentage><gtr:text>Linguistics</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>15BC6F17-6453-42B4-836A-01286E6D8068</gtr:id><gtr:percentage>75</gtr:percentage><gtr:text>Comput./Corpus Linguistics</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>699D8438-2A43-4BCF-B1A4-6240ED82CEEE</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Human Communication in ICT</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>