<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/5E589D68-A73C-42BB-892C-BC508C7B60CA"><gtr:id>5E589D68-A73C-42BB-892C-BC508C7B60CA</gtr:id><gtr:name>University of Hertfordshire</gtr:name><gtr:department>School of Computer Science</gtr:department><gtr:address><gtr:line1>Hatfield Campus</gtr:line1><gtr:line2>College Lane</gtr:line2><gtr:line4>Hatfield</gtr:line4><gtr:line5>Hertfordshire</gtr:line5><gtr:postCode>AL10 9AB</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/5E589D68-A73C-42BB-892C-BC508C7B60CA"><gtr:id>5E589D68-A73C-42BB-892C-BC508C7B60CA</gtr:id><gtr:name>University of Hertfordshire</gtr:name><gtr:address><gtr:line1>Hatfield Campus</gtr:line1><gtr:line2>College Lane</gtr:line2><gtr:line4>Hatfield</gtr:line4><gtr:line5>Hertfordshire</gtr:line5><gtr:postCode>AL10 9AB</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/31CF8BE1-65D3-41D9-8BC7-339C0250BA30"><gtr:id>31CF8BE1-65D3-41D9-8BC7-339C0250BA30</gtr:id><gtr:firstName>Kerstin</gtr:firstName><gtr:surname>Dautenhahn</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/EB57CC12-67F0-4EBC-86D4-080FF84D22A3"><gtr:id>EB57CC12-67F0-4EBC-86D4-080FF84D22A3</gtr:id><gtr:firstName>Farshid</gtr:firstName><gtr:surname>Amirabdollahian</gtr:surname><gtr:orcidId>0000-0001-7007-2227</gtr:orcidId><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FK006509%2F1"><gtr:id>F1D42188-4E81-4952-8292-5A6603397C30</gtr:id><gtr:title>Trustworthy Robotic Assistants</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/K006509/1</gtr:grantReference><gtr:abstractText>The development of robotic assistants is being held back by the lack of a coherent and credible safety framework. Consequently, robotic assistant applications are confined either to research labs or, in practice, to scenarios where physical interaction with humans is purposely limited, e.g. surveillance, transport or entertainment (e.g. museums).

In the domestic/personal domain, however, interactions take place in an informal, unstructured, and typically highly complex way. Even in more constrained industrial settings, the need for reduced manufacturing costs is motivating the creation of robots capable of much greater flexibility and intelligence. These robots need to work near to, be taught by, and perhaps even interact physically with, human co-workers.

So, how can we enhance robots so that they can participate in sophisticated interactions with humans in a safe and trustworthy manner? This is a fundamental research question that must be addressed before the traditional physical safety barrier between the robot and the human can be removed, which is essential for close-proximity human-robot interactions. How, then, might we establish such safety arguments? Intrinsically safe robots must incorporate safety at all levels (mechanical; control; and human interaction). There has been some work on safety at lower, mechanical, levels to severely restrict movements near humans, without regard to whether the movements are &amp;quot;safe&amp;quot; or not. Crucially, no one has yet tackled the high-level behaviours of robotic assistants during interaction with humans, i.e. not only whether the robot makes safe moves, but whether it knowingly or deliberately makes unsafe moves. This is the focus of our project.

Formal verification exhaustively analyses all of the robot's possible choices, but uses a vastly simplified environmental model. Simulation-based testing of robot-human interactions can be carried out in a fast, directed way and involves a much more realistic environmental model, but is essentially selective and does not take into account true human interaction. Formative user evaluation provides exactly this validation, constructing a comprehensive analysis from the human participant's point of view.

It is the aim of our project to bring these three approaches together to tackle the holistic analysis of safety in human-robot interactions. This will require significant research in enhancing each of the, very distinct, approaches so they can work together and subsequently be applied in realistic human-robot scenarios. This has not previously been achieved. Developing strong links between the techniques, for example through formal assertions and interaction hypotheses, together with extension of the basic techniques to cope with practical robotics, is the core part of our research.

Though non-trivial to achieve, this combined approach will be very powerful. Not only will analysis from one technique stimulate new explorations for the others, but each distinct technique actually remedies some of the deficiencies of another. Thus, this combination provides a new, strong, comprehensive, end-to-end verification and validation method for assessing safety in human-robot interactions.</gtr:abstractText><gtr:fund><gtr:end>2016-09-30</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2013-04-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>375541</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Invited panelist for the Rustat Conference on Future of Work, 22nd November 2016, Jesus College, Cambridge.</gtr:description><gtr:form>A formal working group, expert panel or dialogue</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>DACA8501-02FD-499A-8B6D-65B37D2C1EB0</gtr:id><gtr:impact>The purpose of the meeting was to bring together senior decision makers from government, industry and the media to discuss vital issues of the
day with expert academics. The specific topic was the &amp;quot;Future of Work&amp;quot; and it brought together about 30 participants.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:url>https://www.jesus.cam.ac.uk/research/rustat-conferences/past-events-and-reports</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>keynote talk at conference</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>3C7A503D-2295-4677-88E5-11BAC6D76E1E</gtr:id><gtr:impact>Kerstin Dautenhahn was invited keynote speaker at IEEE ICDL-EPIROB, Brown University, 13-16 August 2015, USA. The title of the talk was &amp;quot;How can I help you? Challenges in Designing, Implementing and Evaluating Companion Robots&amp;quot;. The conference was attended by an interdisciplinary audience, including psychologists etc. The audience was very interested in the project results on trust and trustworthiness of home companion robots.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other audiences</gtr:primaryAudience><gtr:url>http://www.tech.plym.ac.uk/SoCCE/CRNS/icdl-epirob/2015/index.html</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited presentation and panel member</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>0EB03E35-154C-41EB-ADCE-9592CEC0D3FE</gtr:id><gtr:impact>Kerstin Dautenhahn participated in two events at The Times Cheltenham Science Festival in 2016. She gave an invited talk and was a member of a panel discussion on 8th June 2016, The talk was part of the KS4 Science day: 'Science: Creating Your Future'. On the same day I'm also part of a panel of experts discussing the topic of &amp;quot;Robots: Emotional Companions?&amp;quot; Subsequently I have been invited to several other events as speaker/panelist, including the 2017 Science Festival.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>http://www.cheltenhamfestivals.com/science</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>578051</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>EPSRC Strategic Equipment</gtr:description><gtr:end>2019-02-02</gtr:end><gtr:fundingOrg>EPSRC and CRUK</gtr:fundingOrg><gtr:fundingRef>Grant Ref: EP/P020577/1 Robot House 2.0 - Infrastructure for the Study of Smart Home and Autonomous Robotic Systems</gtr:fundingRef><gtr:id>B2B8A43E-2D7B-480F-B916-5C70DAEB21BE</gtr:id><gtr:sector>Private</gtr:sector><gtr:start>2017-03-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The research led on to subsequent EPSRC proposals. 

 Work in this project has helped inform BSI Robot Safety and Robot Ethics standards.

 Testing techniques developed are being taken up by industry.

 Findings led to several new PhD student projects that will further illuminate issues of safety, reliability, trust, and trustworthiness for robots 
 operating in human-inhabited environments.

 New collaborations with industry through three CASE studentships have been initiated.</gtr:description><gtr:id>E0A425AF-AC03-45C4-9CF3-DA748108529C</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:sector>Digital/Communication/Information Technologies (including Software)</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Reliability and Safety. We conducted formal verification of an autonomous personal care robot, Care-o-bot, deployed within the
 University of Hertfordshire's Robot House test facility. We modelled the Care-o-bot's behaviour formally using Brahms, a high-level agent
 programming language. Using a software tool developed in-house, they were able to translate Brahms into Promela, the input language to the
 model checker Spin. Safety- and mission-critical requirements were translated into formal properties expressed in LTL and were then formally verified using Spin. This
 provided a higher level of confidence in the abiity of Care-o-bot to take care of a person in the Robot House. In subsequent work an
 expanded set of properties was used to formalise a wider range of requirements, further increasing the confidence in Care-o-bot and
 further demonstrating the effectiveness of formal verification for human-robot interaction scenarios.

 We demonstrated the benefits of using coverage-driven verification to automate a large part of simulation-based testing of code used to control
 robots that directly interact with humans on the example of a human-robot collaborative manufacturing task. We then focused on the problem of
 efficiently generating effective tests. We developed a very effective model-based approach that made use of the models developed for formal
 verification and model checking in the test generation process. This approach is capable of directing test generation to hard to reach and critical
 interaction scenarios. To further increase the level of automation, we then introduced agency into the verification environment by modeling the human and
 the environment the robot interacts with as agents. Our most recent results show that using multi-agent systems as models for test generation is as
 effective as the more traditional method of model checking automata, with the extra benefits of multi-agent models being small, in the number of lines of
 code when compared to the automata, and model traversal time being low and constant.

 Ethics and Trust. We explored the viability of verifying formally whether an autonomous system is capable of behaving ethically. There
 are many different ethical systems across different societies, and it may be useful for definitions of ethical behaviour to change. A
 high-level agent programming language, Ethan, was devised to allow autonomous agents to be programmed with additional ethical
 requirements. Then, an existing agent interpreter and model checker were extended to allow for the formal verification of ethical
 behaviour. Human-robot interaction studies into trust and trustworthiness gave important insights into how people perceive 
 robots performing different types of tasks with different levels of robot performance and communication abilities. 

 Verifying Robotic Systems. We have also made progress towards the holistic framework for the V&amp;amp;V of autonomous robotic assistants, as
 depicted in the earlier diagram. As part of the programme of populating the holistic framework, we have carried out testing of
 algorithms in and formal verification of autonomy.</gtr:description><gtr:exploitationPathways>Techniques for verification of human-robot interaction used in subsequent research proposals and beginning to have an impact on robotics industry and regulatory/standards context.</gtr:exploitationPathways><gtr:id>7ADF2709-CA3A-49D0-9E24-8DBA9B06608B</gtr:id><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare,Leisure Activities, including Sports, Recreation and Tourism</gtr:sector></gtr:sectors><gtr:url>http://www.robosafe.org/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/50C8750B-62D1-443A-AE7F-6799E8CF5A84"><gtr:id>50C8750B-62D1-443A-AE7F-6799E8CF5A84</gtr:id><gtr:title>Evaluating Trust and Safety in HRI: Practical Issues and Ethical Challenges</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3212754b7dd36e3caa6779e958478eb8"><gtr:id>3212754b7dd36e3caa6779e958478eb8</gtr:id><gtr:otherNames>Salem M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/883E20EB-DCB3-4163-BC3F-AD27D089E182"><gtr:id>883E20EB-DCB3-4163-BC3F-AD27D089E182</gtr:id><gtr:title>Would You Trust a (Faulty) Robot?</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3212754b7dd36e3caa6779e958478eb8"><gtr:id>3212754b7dd36e3caa6779e958478eb8</gtr:id><gtr:otherNames>Salem M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:isbn>9781450328838</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/778BF0B9-F43D-4E5B-8347-E4CFA82A8AFF"><gtr:id>778BF0B9-F43D-4E5B-8347-E4CFA82A8AFF</gtr:id><gtr:title>Toward Reliable Autonomous Robotic Assistants Through Formal Verification: A Case Study</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Human-Machine Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d99c1e43a733c3f2cd7dc867b7b1abe5"><gtr:id>d99c1e43a733c3f2cd7dc867b7b1abe5</gtr:id><gtr:otherNames>Webster M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/EBDED837-FD97-419B-862C-72B8E29C15AD"><gtr:id>EBDED837-FD97-419B-862C-72B8E29C15AD</gtr:id><gtr:title>&amp;quot;The fridge door is open&amp;quot; - Temporal Verification of a Robotic Assistant's Behaviours</gtr:title><gtr:parentPublicationTitle>Proceedings of the 15th Towards Autonomous Robotic Systems (TAROS 2014) Conference, Lecture Notes in Computer Science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ee0fe4813626485f1f397181ceb6afe4"><gtr:id>ee0fe4813626485f1f397181ceb6afe4</gtr:id><gtr:otherNames>Dixon C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/70A2B5AF-D790-4A1E-984F-ED04E180F00E"><gtr:id>70A2B5AF-D790-4A1E-984F-ED04E180F00E</gtr:id><gtr:title>Can you trust your robotic asssistant?</gtr:title><gtr:parentPublicationTitle>5th International Conference in Social Robotics (ICSR 2013),Lecture Notes in Artificial Intelligence</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/8e23fe73af41e9258fec61cf35676ac1"><gtr:id>8e23fe73af41e9258fec61cf35676ac1</gtr:id><gtr:otherNames>Amirabdollahian F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/7BAE9890-2C62-45E7-B9A3-E80BF409010C"><gtr:id>7BAE9890-2C62-45E7-B9A3-E80BF409010C</gtr:id><gtr:title>Towards safe and trustworth social robots: Ethical challenges and practical issues</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3212754b7dd36e3caa6779e958478eb8"><gtr:id>3212754b7dd36e3caa6779e958478eb8</gtr:id><gtr:otherNames>Salem M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/B477EE24-8CC9-4B14-A9FB-2F7D7B836F6D"><gtr:id>B477EE24-8CC9-4B14-A9FB-2F7D7B836F6D</gtr:id><gtr:title>Formal Verification of an Autonomous Personal Robotic Assistant</gtr:title><gtr:parentPublicationTitle>In Formal Verification and Modeling in Human-Machine Systems: Papers from the AAAI Spring Symposium (FVHMS 2014)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d99c1e43a733c3f2cd7dc867b7b1abe5"><gtr:id>d99c1e43a733c3f2cd7dc867b7b1abe5</gtr:id><gtr:otherNames>Webster M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/K006509/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>E05CFE0B-163D-412D-A3C2-28E89B2CA336</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Software Engineering</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>