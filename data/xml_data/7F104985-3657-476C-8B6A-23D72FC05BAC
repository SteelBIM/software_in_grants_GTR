<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/94F7E647-AE22-441E-94BC-93669AF66A6B"><gtr:id>94F7E647-AE22-441E-94BC-93669AF66A6B</gtr:id><gtr:name>Okinawa Institute of Science and Tech</gtr:name><gtr:address><gtr:line1>Okinawa Institute of Science and Tech</gtr:line1><gtr:line2>12-22 Suzaki</gtr:line2><gtr:line3>Uruma-shi</gtr:line3><gtr:postCode>904-2234</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/D9D173EA-C6E0-451C-8438-F29BF99FF5D3"><gtr:id>D9D173EA-C6E0-451C-8438-F29BF99FF5D3</gtr:id><gtr:name>Macquarie University</gtr:name><gtr:address><gtr:line1>Macquarie University</gtr:line1><gtr:line4>North Ryde</gtr:line4><gtr:postCode>NSW 2109</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>Australia</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/F649AB83-DC92-4360-807F-BBFEF0DE8EE4"><gtr:id>F649AB83-DC92-4360-807F-BBFEF0DE8EE4</gtr:id><gtr:name>National Center for Scientific Research (Centre National de la Recherche Scientifique CNRS)</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/03D8AFBB-3EA5-4885-B036-BD4F9F4F9849"><gtr:id>03D8AFBB-3EA5-4885-B036-BD4F9F4F9849</gtr:id><gtr:name>University of Sheffield</gtr:name><gtr:department>Computer Science</gtr:department><gtr:address><gtr:line1>Firth Court</gtr:line1><gtr:line2>Western Bank</gtr:line2><gtr:line4>Sheffield</gtr:line4><gtr:line5>South Yorkshire</gtr:line5><gtr:postCode>S10 2TN</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/03D8AFBB-3EA5-4885-B036-BD4F9F4F9849"><gtr:id>03D8AFBB-3EA5-4885-B036-BD4F9F4F9849</gtr:id><gtr:name>University of Sheffield</gtr:name><gtr:address><gtr:line1>Firth Court</gtr:line1><gtr:line2>Western Bank</gtr:line2><gtr:line4>Sheffield</gtr:line4><gtr:line5>South Yorkshire</gtr:line5><gtr:postCode>S10 2TN</gtr:postCode><gtr:region>Yorkshire and The Humber</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/94F7E647-AE22-441E-94BC-93669AF66A6B"><gtr:id>94F7E647-AE22-441E-94BC-93669AF66A6B</gtr:id><gtr:name>Okinawa Institute of Science and Tech</gtr:name><gtr:address><gtr:line1>Okinawa Institute of Science and Tech</gtr:line1><gtr:line2>12-22 Suzaki</gtr:line2><gtr:line3>Uruma-shi</gtr:line3><gtr:postCode>904-2234</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/D9D173EA-C6E0-451C-8438-F29BF99FF5D3"><gtr:id>D9D173EA-C6E0-451C-8438-F29BF99FF5D3</gtr:id><gtr:name>Macquarie University</gtr:name><gtr:address><gtr:line1>Macquarie University</gtr:line1><gtr:line4>North Ryde</gtr:line4><gtr:postCode>NSW 2109</gtr:postCode><gtr:region>Outside UK</gtr:region><gtr:country>Australia</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/F649AB83-DC92-4360-807F-BBFEF0DE8EE4"><gtr:id>F649AB83-DC92-4360-807F-BBFEF0DE8EE4</gtr:id><gtr:name>National Center for Scientific Research (Centre National de la Recherche Scientifique CNRS)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/96E764CD-849E-4401-9831-951FF8F47978"><gtr:id>96E764CD-849E-4401-9831-951FF8F47978</gtr:id><gtr:firstName>Eleni</gtr:firstName><gtr:surname>Vasilaki</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/2319EF68-5CA1-4756-BE14-7F801E05F40F"><gtr:id>2319EF68-5CA1-4756-BE14-7F801E05F40F</gtr:id><gtr:firstName>James</gtr:firstName><gtr:otherNames>Arthur</gtr:otherNames><gtr:surname>Marshall</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/6978B5F3-7F67-45A3-BB8E-2560CB14F58A"><gtr:id>6978B5F3-7F67-45A3-BB8E-2560CB14F58A</gtr:id><gtr:firstName>Kevin</gtr:firstName><gtr:surname>Gurney</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FJ019534%2F1"><gtr:id>7F104985-3657-476C-8B6A-23D72FC05BAC</gtr:id><gtr:title>Green Brain: Computational Modelling of the Honeybee Brain</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/J019534/1</gtr:grantReference><gtr:abstractText>Building intelligent machines that can perform complex cognitive tasks as well as or better than the human brain is a long-standing challenge of modern science. This quest has seen one of its highlights when IBM's Deep Blue chess computer beat the world champion Kasparov in 1997. Despite its superior performance in chess, this system was however in no way similar to or as powerful and versatile as a brain. More recently the Blue Brain initiative, also partially funded by IBM, set out to build a real-scale model of a cortical column of the human brain, moving us closer to the goal of eventually building an artificial brain that works like its biological counterpart.
 
In the Green Brain project we propose to build such an artificial brain, but of the smaller brain of the honeybee. We will work with the world-leading research group of Prof. Martin Giurfa in Toulouse, who are experts in all aspects of bee brain anatomy, physiology and bee cognition and behavior. Bees have a surprisingly large cognitive capacity including transfer of learned associations across sensory modalities, e.g. from smells to colors, and learning abstract concepts such as the categories of &amp;quot;the same&amp;quot; and &amp;quot;different&amp;quot;. At the same time their brains are much smaller, structured and (proportionally) much better researched than the complex human brain. It is also much easier to perform invasive manipulations to dissect how different parts of the bee brain function.

In the Green Brain project we will build detailed computer models of the two most important sensory systems of the bee, the senses of smell (olfactory system) and of sight (visual system). In doing so, we will incorporate existing data, models and principles and identify further how they give rise to the observed impressive cognitive abilities. We will then combine the sensory systems with learning models and models of sensory integration in close collaboration with the experts in the Giurfa lab to eventually build a full-scale model of the bee brain. This model will be implemented on state-of-the-art massively parallel graphical processing unit (GPU) based super-computers, a new technology spearheaded by NVIDIA Corporation who is supporting this project with GPU hardware donations. Using GPU computing will allow us to simulate our Green Brain model in real time, which will be essential for the final phase of the project when we will put the Green Brain to work as the brain of an autonomous flying robot. This is an important further advance over current work on brain models because it is becoming more and more clear that an essential aspect of brain function is that the brain is not acting in isolation but in constant interaction with the body and the environment. This concept of &amp;quot;embodiment&amp;quot; and its consequences for cognition are important insights of modern cognitive science and will become equally important for modern neuroscience. 

The outputs from the Green Brain project will have impacts in several academic areas. In the neurosciences it will advance the field of large scale brain models and our understanding of how information is processed in the sensory systems of bees. We will also contribute new tools for the use of modern GPU technology for artificial brains and employing them in bio-mimetic robotics. For the cognitive sciences we will contribute to the understanding of embodiment in biologically realistic model systems.

Beyond academia, the development of autonomous flying robots may have applications in environmental exploration, search and rescue and artificial pollination. Developing a better understanding of the mechanisms underlying cognition may ultimately translate into greater insights into human cognition and cognitive disorders. Finally, developing a better understanding of the honeybee may prove to be important in its own right as bees are a key pollinator in most ecologies and hence a 'keystone species' and vital for food security.</gtr:abstractText><gtr:potentialImpactText>This project combines technology development with substantial basic research components. The ultimate impact of the technologies developed is relatively easy to predict. The impact predicted from basic research is necessarily much more speculative, however it is easy to demonstrate the economic, ecological and societal importance of the basic research problems being tackled. The potential impact of the project can be summarised as follows:

* supporting the development of autonomous and adaptive flying robots, with potential application in environmental exploration, search and rescue, artificial pollination, etc.
* developing greater understanding of the mechanisms underlying cognition, which may ultimately translate into greater understanding of human cognition.
* developing greater understanding of the honeybee, a key pollinator in most ecologies and hence a 'keystone species' and vital for human food security.

These potential impacts are described in more detail below:

Towards development of autonomous and adaptive flying robots
---
This impact is the most immediate to arise from the project. This project will develop sophisticated behaviours for control of flying robots, and demonstrate their embodiment in a testbed flying robot platform. There are obvious and innumerable applications of autonomous, adaptive flying robots. These include exploration in dangerous environments, such as search and rescue. Less obvious applications may include artificial pollination, which might become essential for human food security if current declines in honeybee populations continue. For this reason, the US National Sciences Foundation recently awarded Harvard University and partners one of three 'Expeditions in Computing' awards, worth up to $10m, to fund the Robobees project which is developing flying microrobots. Control of these is a hard problem, and an obvious potential application area for the current project which we shall explore during its development.

Understanding basic mechanisms of cognition
---
The basic research undertaken in the project may have longer term economic and societal impacts. The cognitive sophistication of the honeybee brain is often under-appreciated. In fact, honeybees exhibit many of the cognitive abilities of 'higher' organisms such as vertebrates, including humans. Understanding the mechanisms of cognition in the honeybee may ultimately translate into a greater understanding of animal and human cognitive mechanisms. Since understanding human cognitive mechanisms should help with treatment of cognitive disorders, the societal and economic benefits of such research are potentially very large. For example Parkinson's disease alone, which may be caused by malfunction of basic action selection and learning circuits in the human brain, has been estimated to cost the UK economy between &amp;pound;0.45bn and &amp;pound;3.3bn per year.

Ecological, economic and societal significance of the honeybee
---
Honeybees are vital pollinators, and thus are 'keystone species' whose absence from an ecosystem can have catastrophic consequences for other species. Human food security in particular is heavily reliant on pollination by honeybees. As has been widely reported, however, honeybee populations have been in sharp decline in Europe and North America. For this reason, the UK government made funding of &amp;pound;10m available in 2009 for investigation into the causes of honeybee decline, with similar funding initiatives in the USA. One example motivation of the NSF funded Robobees project described above is to produce 'artificial pollinators' to take over in the event of a complete collapse in honeybee numbers; the current project could ultimately contribute to such a technological solution. More fundamentally, while progress on identifying the causes of honeybee population decline has been made, further basic research into honeybees, including behavioural and neuroscience research, can only improve our understanding of them.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-08-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2013-03-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>660561</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Macquarie University</gtr:collaboratingOrganisation><gtr:country>Australia, Commonwealth of</gtr:country><gtr:description>Honeybee computational neuroscience collaboration with Andrew Barron</gtr:description><gtr:id>2AB9C6AF-7382-4201-B07A-BF6536914C12</gtr:id><gtr:impact>-</gtr:impact><gtr:partnerContribution>Expertise in invertebrate neuroscience and behaviour</gtr:partnerContribution><gtr:piContribution>Computational modelling expertise</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>National Center for Scientific Research (Centre National de la Recherche Scientifique CNRS)</gtr:collaboratingOrganisation><gtr:country>France, French Republic</gtr:country><gtr:description>Member of the NineML standardisation committee</gtr:description><gtr:id>D2527FD7-C17F-4887-9BD7-F7EABAD859FF</gtr:id><gtr:impact>The outcomes of this collaboration are the NineML model description format and the updated tools for generating and manipulating NineML based models.The collaboration involves the fields of computational neuroscience and neuroinformatics.</gtr:impact><gtr:partnerContribution>All members of the committee are involved in completing the NineML specification, and various members have responsibility for creating and maintaining software tools for writing and manipulating NineML based models.</gtr:partnerContribution><gtr:piContribution>NineML is a simulator independent language with the aim of providing an unambiguous description of neuronal network models for efficient model sharing and reusability. As a member of the standardisation committee I am involved in completing the NineML specification and generating code to allow conversion between the NineML and SpineML description formats.</gtr:piContribution><gtr:sector>Public</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Okinawa Institute of Science and Technology</gtr:collaboratingOrganisation><gtr:country>Japan</gtr:country><gtr:description>Member of the NineML standardisation committee</gtr:description><gtr:id>03E8BF93-E6F4-4B76-AA27-9EE25E2B85C0</gtr:id><gtr:impact>The outcomes of this collaboration are the NineML model description format and the updated tools for generating and manipulating NineML based models.The collaboration involves the fields of computational neuroscience and neuroinformatics.</gtr:impact><gtr:partnerContribution>All members of the committee are involved in completing the NineML specification, and various members have responsibility for creating and maintaining software tools for writing and manipulating NineML based models.</gtr:partnerContribution><gtr:piContribution>NineML is a simulator independent language with the aim of providing an unambiguous description of neuronal network models for efficient model sharing and reusability. As a member of the standardisation committee I am involved in completing the NineML specification and generating code to allow conversion between the NineML and SpineML description formats.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Virtual Robotics Outreach Project</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>53447E93-495D-4EDB-8C9B-0107C6308A8F</gtr:id><gtr:impact>Faculty of Engineering Widening Participation Activities (February - June 2016)
Title: Virtual Robotics
Aimed to support young people from a disadvantaged community to engage in cutting-edge research, as well as accessing university ideas and raising aspirations
Grant Award Amount: &amp;pound;5,540 Total</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>IUSSI 2014</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>0DCEB05F-FDFB-44EA-8BCD-589CBC2A18F1</gtr:id><gtr:impact>Talk sparked questions and discussion afterwards

After my talk there was interest expressed in the work.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited Robotics Mini-Lecture</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>CA4B1792-7F09-4305-B6D6-9E013E9B3860</gtr:id><gtr:impact>Robotics Mini-Lecture
Wed, March 30, 2016, 6pm - 8pm
Retford Post 16 Centre, Old Hall Dr, Retford DN22 7EA, United Kingdom</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Beekeepers Talk</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>B505327E-01C7-429A-9FC8-2D2F897A7FC5</gtr:id><gtr:impact>Talk to Sheffield Beekeeper's Association about what we have learned about bees in the Green Brain Project</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Media coverage including New Scientist and Sunday Times</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>C34A5805-FCBB-425E-A6E2-5AE54AE3FC8D</gtr:id><gtr:impact>-

Coverage included (among others)

&amp;quot;Summon the bee bots: Can flying robots save our crops?&amp;quot;, November 18th November 2013, New Scientist (on the cover).
&amp;quot;Flight of the robo-bee to save fruit crops&amp;quot;, 7th October 2012, The Sunday Times.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2012,2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited Talk - Drone Conference</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>14F062EE-FEE3-4A43-9F87-A77157CD2709</gtr:id><gtr:impact>Invited Oral Presentation
Drone, Data X Conference
&amp;quot;Green Brain Project&amp;quot;
Mayo, Ireland
November 2015.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Aerospace America IS Year-in-Review</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>FC88D68A-1676-44D4-B3D1-F8D1233FBC5D</gtr:id><gtr:impact>Green Brain Project was highlighted in the Intelligent Systems Year-in-Review in the annual Aerospace America magazine written by AIAA.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:url>http://www.aerospaceamerica.org/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Work Experience Student</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>637ADFF1-7D06-4B08-B110-83942DE76515</gtr:id><gtr:impact>Hosted Work Experience student from a local Rotherham school. The student developed an algorithm for a robot to do a waggle-dance in a week with us and is pursuing university in robotics.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>https://www.youtube.com/watch?v=BTVB17ps_vc</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Discovery Night</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>67126C4B-D7B9-4480-B003-8037D10B4ED3</gtr:id><gtr:impact>Booth at the Discovery Night exhibition at the University of Sheffield.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.sheffield.ac.uk/discoverynight/programme/robots</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Headstart Workshop</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>C4B56D57-7293-42BA-9BF2-4CAFF5C1295B</gtr:id><gtr:impact>HEADSTART
&amp;quot;Bee-hind a Robot Mind&amp;quot;
Tue, July 12, 2016, 1:00pm - 5:30pm
The Diamond, University of Sheffield</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Science Week Talk</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>F0B919A1-B5FA-42D0-8963-D872D25B397C</gtr:id><gtr:impact>Public Engagement talk to school children in Widening Participation school. Gave intro to the Green Brain Project, Robotics, and AI. Follow-up interactions with this school included hosting them for a day-long workshop at the University of Sheffield to more activity participate in research topics.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Digital Human BBC Radio 4 broadcast interview</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>8304DECD-D814-4E88-A06E-706BEBD89858</gtr:id><gtr:impact>Interviewed as part of Digital Human broadcast (BBC Radio 4)</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.bbc.co.uk/programmes/b05rnyz2</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Programming a Robotic Bee Outreach Activity</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>29BFEDF9-DBB6-4007-AC16-252273F94C0E</gtr:id><gtr:impact>Activity engaged students, encouraged discussion, and sparked questions related to robotics.

Students gave very positive feedback about the activity and enjoyed the introduction into programming. This activity also led to future Excellence Hubs workshops led by researchers in the Kroto Research Institute.</gtr:impact><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>http://www.sheffield.ac.uk/kroto/news/outreachday</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited talk at workshop</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>2D6547D5-4B22-4A6E-A340-36D6CE3602EB</gtr:id><gtr:impact>Invited talk at the 2nd Workshop on Code Generation at the Forschungzentrum in Julich, Germany</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>BBC Click television broadcast coverage</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>179997F4-CBDD-4254-BB29-8D966E35DCB0</gtr:id><gtr:impact>Television broadcast coverage of Green Brain project, and interviews with PI (James Marshall) and research associate (Alex Cope) on BBC Click</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.bbc.co.uk/programmes/p02npxlq</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>National Science and Engineering Week Talks</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>02B21EFD-4E76-4A45-BDB0-38F480B54638</gtr:id><gtr:impact>Activity engaged students, encouraged discussion, and sparked questions related to robotics.

Students were engaged, gave very positive feedback about the activity, and enjoyed the introduction into robotics.</gtr:impact><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Bee-ing Sherlock Holmes Outreach Activity</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>7558BA37-2B74-4D3B-B48D-98F09D7D1FC2</gtr:id><gtr:impact>Activity engaged students, encouraged discussion, and sparked questions related to modelling the brain.

Students gave very positive feedback about the activity and enjoyed the introduction into modelling. This activity also led to future Excellence Hubs workshops led by researchers in the Kroto Research Institute.</gtr:impact><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>http://www.york.ac.uk/excellencehub/subject-taster-events/eventsarchive/archive-13-14/subject-taster-events201314/science-tv/</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Bee-Hind a Robot Mind Activity</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>A2338A51-6658-43E0-A045-35D6FAB84D4B</gtr:id><gtr:impact>Day long workshop for school children to activity engage in Robotics, Artificial Intelligence, &amp;amp; Neuroscience including hands-on activities. Included 30 students which attended after a previous Public Engagement talk at their school (a Widening Participation school). Students were engaged and interest.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Robot Mind Programming Activity</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>B48B2177-B3CB-4A73-B164-58EFBDCE1AC1</gtr:id><gtr:impact>Repeat of the Bee-Hind a Robot Mind programming activity used in past outreach events. This activity was requested by the University for this program after the demonstration of success from earlier implementations. One student even reported that it was &amp;quot;the best one yet because it felt like we were activity doing something!&amp;quot; in feedback.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Mobile Uni Public Engagement Talk</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>DCFCCD78-ABD4-456B-815F-9E13E4C58E92</gtr:id><gtr:impact>Talk sparked questions and discussion afterwards with several members of the general public.

After my talk, a student from the Media Studies department approached me and did a science journalism piece on the project.</gtr:impact><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Drones Save Bees</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>AB604C19-E324-4B82-9E67-7871D0FCF52A</gtr:id><gtr:impact>Article on use of drones in the Green Brain to show drone uses in conservation and agriculture to help increase public view of them.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.dronesfutureskies.com/environmental-impact#drones-save-bees</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Sheffield Science Exhibition</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>DFEE3393-8846-4135-ABCC-E7662A3F10E4</gtr:id><gtr:impact>Booth at the Sheffield Science Exhibition which reached an audience of ~500 Students of Ages 5-10.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Oral presentation in Bernstein Conference, Green Brain workshop in Goettingen (2-5 September 2014)</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>D38F8003-1C4B-42EC-873A-58E7245D704D</gtr:id><gtr:impact>The talk helped better understanding of our goal and achievements by colleagues and it was followed by a discussion.

After the talk I could discuss with experts in my field about my and their methods and results.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>http://www.nncn.de/en/bernstein-conference/2014/workshops/green-brain-how-models-of-invertebrate-brains-can-inform-our-understanding-of-cognition</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited conference talk</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>B88C6AF2-A685-4B20-B9E3-CA5852ECE1E5</gtr:id><gtr:impact>Invited talk at the Neurosciences R&amp;amp;D Conference, Barcelona, December 4-5th 2015</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Bee-ing Sherlock Holmes Outreach Activity</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>F312D2AC-6309-4397-8B80-FE03486EC9F7</gtr:id><gtr:impact>Activity engaged students, encouraged discussion, and sparked questions related to modelling the brain.

Students gave very positive feedback about the activity and enjoyed the introduction into modelling/engineering. Had one student in particular talk to me about doing work experience in our lab for the coming summer.</gtr:impact><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>https://www.education.gov.uk/futurescholarawards/Venues/Venue.aspx?VID=445&amp;EVID=2346</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>4816675</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Brains on Board: Neuromorphic Control of Flying Robots</gtr:description><gtr:end>2021-12-02</gtr:end><gtr:fundingOrg>Engineering and Physical Sciences Research Council (EPSRC)</gtr:fundingOrg><gtr:fundingRef>EP/P006094/1</gtr:fundingRef><gtr:id>64226748-A11C-442D-B244-55A6FDC7738D</gtr:id><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-12-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>12000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Royal Society International Exchanges</gtr:description><gtr:end>2017-04-02</gtr:end><gtr:fundingOrg>The Royal Society</gtr:fundingOrg><gtr:id>B72BE63F-6FA4-4454-B102-E00498A749C0</gtr:id><gtr:sector>Academic/University</gtr:sector><gtr:start>2015-05-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>5540</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Faculty of Engineering Widening Participation Activities</gtr:description><gtr:end>2016-06-02</gtr:end><gtr:fundingOrg>University of Sheffield</gtr:fundingOrg><gtr:fundingRef>Virtual Robotics</gtr:fundingRef><gtr:id>614E5DF1-7AF2-49A4-9757-F36F30AA54BA</gtr:id><gtr:sector>Academic/University</gtr:sector><gtr:start>2016-02-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We have discovered how optic flow, the visual motion sensed by the, can be estimated in a very robust way by a plausible and simple model of the honeybee visual system. We have shown how this can be used to guide a simulated bee through a virtual environment, such that its behaviour closely mimics that of real bees trained to do the same task. This research is of potential use for robotics applications.</gtr:description><gtr:exploitationPathways>Our published results could be useful to those developing controllers for autonomous robots.</gtr:exploitationPathways><gtr:id>BCFACB54-A7B6-4DBE-8BAF-5C8DA1208E51</gtr:id><gtr:sectors><gtr:sector>Other</gtr:sector></gtr:sectors><gtr:url>http://greenbrain.group.shef.ac.uk</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>The SpineCreator graphical tool is a cross platform (OSX with retina support, Linux and (potentially) Windows) graphical drag and drop tool for SpineML model editing and simulation. It features OpenGL visualisation of networks, simulator integration and graphical analysis tools. See http://bimpa.group.shef.ac.uk/SpineML/index.php/Gui for details.</gtr:description><gtr:id>DAC9157F-7923-41FA-A886-DF41CF9A2A37</gtr:id><gtr:impact>The software is being used in the European seventh framework project NoTremor (http://notremor.eu/notremor/)</gtr:impact><gtr:openSourceLicense>true</gtr:openSourceLicense><gtr:title>SpineCreator</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/SpineML/SpineCreator</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>SpineML_2_GeNN converts neural models described in the SpineML description format into the GeNN GPU simulation framework</gtr:description><gtr:id>D9C66364-D064-4DC2-87C0-7AD68B6218AA</gtr:id><gtr:impact>This software allows computational neuroscience models to be easily simulated on the embarrassingly parallel hardware of modern NVidia graphics cards, vastly decreasing the cost required to improve simulation performance.</gtr:impact><gtr:openSourceLicense>true</gtr:openSourceLicense><gtr:title>SpineML_2_GeNN</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/genn-team/genn</gtr:url><gtr:yearFirstProvided>2014</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/E91C2756-8EB9-4587-9110-680DC8958F7A"><gtr:id>E91C2756-8EB9-4587-9110-680DC8958F7A</gtr:id><gtr:title>Bio-Inspired Visual Navigation of a Quadcopter using Optic Flow</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/8cba00e3c74a423c917eb4387da99de0"><gtr:id>8cba00e3c74a423c917eb4387da99de0</gtr:id><gtr:otherNames>Sabo C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/65D90BFE-E0BA-47FB-A30D-C95A458BD78C"><gtr:id>65D90BFE-E0BA-47FB-A30D-C95A458BD78C</gtr:id><gtr:title>Bio-Inspired Visual Navigation for a Quadcopter using Optic Flow</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/8cba00e3c74a423c917eb4387da99de0"><gtr:id>8cba00e3c74a423c917eb4387da99de0</gtr:id><gtr:otherNames>Sabo C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/B8A8D8F7-CC6C-46A3-BC3F-8281D889FDFA"><gtr:id>B8A8D8F7-CC6C-46A3-BC3F-8281D889FDFA</gtr:id><gtr:title>Decision-making and action selection in insects: inspiration from vertebrate-based theories.</gtr:title><gtr:parentPublicationTitle>Frontiers in behavioral neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/304fdd13e8bcfdad77ff272a5d501a07"><gtr:id>304fdd13e8bcfdad77ff272a5d501a07</gtr:id><gtr:otherNames>Barron AB</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1662-5153</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/40BB60E8-F359-4E62-B12F-A47EBD8A2C0F"><gtr:id>40BB60E8-F359-4E62-B12F-A47EBD8A2C0F</gtr:id><gtr:title>A computational model of the integration of landmarks and motion in the insect central complex.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/49ae35d584e1380cd12546fdec7fc436"><gtr:id>49ae35d584e1380cd12546fdec7fc436</gtr:id><gtr:otherNames>Cope AJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/EBF6F02D-4E7B-4F9C-A35E-4CAE51098118"><gtr:id>EBF6F02D-4E7B-4F9C-A35E-4CAE51098118</gtr:id><gtr:title>A neural model of the optomotor system accounts for ordered responses to decreasing stimulus spatial frequencies</gtr:title><gtr:parentPublicationTitle>BMC Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/2c48efd814cd453812cf26d64a362f18"><gtr:id>2c48efd814cd453812cf26d64a362f18</gtr:id><gtr:otherNames>Cope A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/3AEF7BCD-9AF1-4D02-9253-27387DDE9C6D"><gtr:id>3AEF7BCD-9AF1-4D02-9253-27387DDE9C6D</gtr:id><gtr:title>Measuring symmetry, asymmetry and randomness in neural network connectivity.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c9e73b71e98e54c83a0efd57600bde61"><gtr:id>c9e73b71e98e54c83a0efd57600bde61</gtr:id><gtr:otherNames>Esposito U</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/23855F4B-A082-4FB3-AD15-AC439C94C770"><gtr:id>23855F4B-A082-4FB3-AD15-AC439C94C770</gtr:id><gtr:title>Adaptation of short-term plasticity parameters via error-driven learning may explain the correlation between activity-dependent synaptic properties, connectivity motifs and target specificity.</gtr:title><gtr:parentPublicationTitle>Frontiers in computational neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c9e73b71e98e54c83a0efd57600bde61"><gtr:id>c9e73b71e98e54c83a0efd57600bde61</gtr:id><gtr:otherNames>Esposito U</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1662-5188</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/72D9DE9F-C3FF-4F0C-9973-B8193E26D9C0"><gtr:id>72D9DE9F-C3FF-4F0C-9973-B8193E26D9C0</gtr:id><gtr:title>Emergence of connectivity motifs in networks of model neurons with short- and long-term plastic synapses.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/be9036f688af7ac94283fe9aa3180303"><gtr:id>be9036f688af7ac94283fe9aa3180303</gtr:id><gtr:otherNames>Vasilaki E</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/42971A26-E1E3-44C3-9E79-F320A781DB4B"><gtr:id>42971A26-E1E3-44C3-9E79-F320A781DB4B</gtr:id><gtr:title>Quadcopter Obstacle Avoidance using Biomimetic Algorithms</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3fff870985131b893b7254f573f4031a"><gtr:id>3fff870985131b893b7254f573f4031a</gtr:id><gtr:otherNames>Simpson A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/4CDA60E6-7ED8-41A0-A725-35D3F3C48C5B"><gtr:id>4CDA60E6-7ED8-41A0-A725-35D3F3C48C5B</gtr:id><gtr:title>An Inexpensive Flying Robot Design for Embodied Robotics Research</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c12df2ec8584178eb6eb28a77c4ea438"><gtr:id>c12df2ec8584178eb6eb28a77c4ea438</gtr:id><gtr:otherNames>Sabo C.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/4E51F5FC-3652-4693-A099-2045680FD165"><gtr:id>4E51F5FC-3652-4693-A099-2045680FD165</gtr:id><gtr:title>Emulating short-term synaptic dynamics with memristive devices.</gtr:title><gtr:parentPublicationTitle>Scientific reports</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d32d8c717c9d4f8b1bcdd5b11fcc2c21"><gtr:id>d32d8c717c9d4f8b1bcdd5b11fcc2c21</gtr:id><gtr:otherNames>Berdan R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>2045-2322</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/4BE6B771-4168-4441-B0B6-3165C5E5E405"><gtr:id>4BE6B771-4168-4441-B0B6-3165C5E5E405</gtr:id><gtr:title>A Model for an Angular Velocity-Tuned Motion Detector Accounting for Deviations in the Corridor-Centering Response of the Bee.</gtr:title><gtr:parentPublicationTitle>PLoS computational biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/49ae35d584e1380cd12546fdec7fc436"><gtr:id>49ae35d584e1380cd12546fdec7fc436</gtr:id><gtr:otherNames>Cope AJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1553-734X</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/32A9614A-03A5-4C4D-BB05-FB862735292D"><gtr:id>32A9614A-03A5-4C4D-BB05-FB862735292D</gtr:id><gtr:title>Finding minimal action sequences with a simple evaluation of actions.</gtr:title><gtr:parentPublicationTitle>Frontiers in computational neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/35233ed9adaf19841a3034fd01bb9467"><gtr:id>35233ed9adaf19841a3034fd01bb9467</gtr:id><gtr:otherNames>Shah A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1662-5188</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/EB0378B4-909A-43FC-827D-8BE7EAA76CE4"><gtr:id>EB0378B4-909A-43FC-827D-8BE7EAA76CE4</gtr:id><gtr:title>Using Optic Flow for Navigation of an Autonomous Quadcopter</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3a0b3d4280f6c1a7b29a2463ef3adecc"><gtr:id>3a0b3d4280f6c1a7b29a2463ef3adecc</gtr:id><gtr:otherNames>Merry O</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/J019534/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5CBA14F4-F235-45B6-A9DD-5937D5C166CC</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Electrical Engineering</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>6624C9D3-BA2C-4506-9A85-9816946CA97A</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Robotics &amp; Autonomy</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>