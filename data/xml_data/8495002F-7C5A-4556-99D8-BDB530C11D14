<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:department>Engineering</gtr:department><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/D1774113-D5D2-4B7C-A412-66A90FE4B96F"><gtr:id>D1774113-D5D2-4B7C-A412-66A90FE4B96F</gtr:id><gtr:name>University of Cambridge</gtr:name><gtr:address><gtr:line1>Lensfield Road</gtr:line1><gtr:line4>Cambridge</gtr:line4><gtr:postCode>CB2 1EW</gtr:postCode><gtr:region>East of England</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/752EB7CE-19A3-4739-ABCF-DDB8033C01F7"><gtr:id>752EB7CE-19A3-4739-ABCF-DDB8033C01F7</gtr:id><gtr:firstName>Stephen</gtr:firstName><gtr:otherNames>John</gtr:otherNames><gtr:surname>Young</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FF013930%2F1"><gtr:id>8495002F-7C5A-4556-99D8-BDB530C11D14</gtr:id><gtr:title>Spoken Dialogue Management using Partially Observable Markov Decision Processes</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/F013930/1</gtr:grantReference><gtr:abstractText>Spoken dialogue systems have a wide range of application including call centre automation, control of devices in the home, interactive entertainment, and hands-free applications. Despite their increasing use, however, deployment costs remain high and operational systems continue to be fragile. A major contributor to both of these problems is that the core dialogue manager which interprets the spoken input, and plans the next response is a deterministic program, hand-crafted and manually tuned for each application.Experience applying statistical techniques in both speech recognition and synthesis has shown that learning from data and using optimal decision making can dramatically improve performance and lower costs. A natural framework for statistical dialogue modelling is the Markov Decision Process (MDP), however, a major limitation of MDPs is that they require the state of the system to be known exactly, and therefore they do not address the essense of the dialogue management problem which is to handle the uncertainty caused by speech recognition and understanding errors.The aim of this project is to develop a framework for spoken dialogue systems which uses a more general statistical model called a Partially Observable Markov Decision Process (POMDP). The key assumption in the POMDP is that the state of the system (which includes the goal in the user's mind) can never be known with certainty. Hence, it maintains a probability distribution over all possible states and bases its decisions on this distribution. In effect, the POMDP tracks every possible dialogue hypothesis at every turn, maintaining a probability for each. This provides it with a principled framework for handling ambiguity and uncertainty.Although this formulation is extremely powerful, it is also computationally very complex since the POMDP state is a vector in a very high dimensional continuous space. This makes direct belief monitoring and policy optimisation essentially intractable and hence little progress has been made towards real applications. Recently, however, the proposer has demonstrated that practical POMDP-based systems are feasible by exploiting two key ideas. Firstly, the complexity of belief monitoring can be greatly reduced by partitioning the state space into equivalence classes. Secondly, in the context of spoken dialogues, it is possible to map dialogue hypotheses into a much-reduced summary space where effective policy optimisation is possible. These ideas have been built into a prototype system called the Hidden Information State (HIS) system and their feasibility has been demonstrated and evaluated in a Tourist Information domain.Although it serves its purpose as a proof of concept, the HIS prototype was built using a simple 1-best recogniser interface, very simplistic probabilistic models, a hand-crafted user simulator and a rudimentary grid-based policy learning method. To fully realise the potential of POMDP-based systems, much more needs to be done and the programme of work set out in this proposal seeks to achieve this. The key areas that will be addressed are more efficient belief state partitioning and monitoring, accurate statistical user models trained on real data, integration of N-best recognition hypotheses, and improved summary state mapping and policy optimisation. The result will be a system which is trained automatically on data, which delivers high performance at low cost, which is significantly more robust to recognition errors, and which can learn and adapt on-line.</gtr:abstractText><gtr:fund><gtr:end>2010-09-30</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2007-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>360667</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The findings from this study provided the basis for two EU Framework 7 projects (CLASSIC and PARLANCE), industrial support from General Motors and Toshiba and subsequently in 2011 the formation of a spin-off company VocalIQ Ltd to develop the technology (see www.vocaliq.com).</gtr:description><gtr:firstYearOfImpact>2008</gtr:firstYearOfImpact><gtr:id>3942788D-7A6D-4DF2-914C-9DAF48C42CC4</gtr:id><gtr:impactTypes><gtr:impactType>Economic</gtr:impactType></gtr:impactTypes><gtr:sector>Digital/Communication/Information Technologies (including Software),Transport</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>A new approach to designing speech-based human-computer interfaces which are cheaper to build, more robust in operation and which continue to improve during deployment via continuous adaptation.</gtr:description><gtr:exploitationPathways>They are already being exploited via VocalIQ Limited and other R&amp;amp;D companies in this area.</gtr:exploitationPathways><gtr:id>B4E03140-335D-4610-9AAE-AA466D7BF219</gtr:id><gtr:sectors><gtr:sector>Creative Economy,Digital/Communication/Information Technologies (including Software),Financial Services, and Management Consultancy,Healthcare,Transport</gtr:sector></gtr:sectors><gtr:url>http://mi.eng.cam.ac.uk/~sjy</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs><gtr:spinOutOutput><gtr:companyName>VocalIQ Limited</gtr:companyName><gtr:description>VocalIQ is a spin-out company from the Spoken Dialogue Systems Group at University of Cambridge, UK. Still based in Cambridge, the company builds a platform for voice interfaces, making it easy for everybody to voice enable their devices and apps. Example application areas include smartphones, robots, cars, call-centres, and games. They are funded by Amadeus Capital and Cambridge Enterprise.</gtr:description><gtr:id>555DD98A-E04E-4F28-B3BE-9FD75C2C27FE</gtr:id><gtr:impact>Contracts with General Motors and Jaguar LandRover to develop state of the art voice-driven systems.</gtr:impact><gtr:url>http://www.vocaliq.com</gtr:url><gtr:yearCompanyFormed>2011</gtr:yearCompanyFormed></gtr:spinOutOutput></gtr:spinOutOutputs></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/4D4E1D3E-7152-47D5-AC64-849845F1AD08"><gtr:id>4D4E1D3E-7152-47D5-AC64-849845F1AD08</gtr:id><gtr:title>The Hidden Agenda User Simulation Model</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/2f81768f992de0369db3a25f0bf5411a"><gtr:id>2f81768f992de0369db3a25f0bf5411a</gtr:id><gtr:otherNames>Schatzmann J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/00F8212B-D29C-46B2-AB1A-85C61F393AC9"><gtr:id>00F8212B-D29C-46B2-AB1A-85C61F393AC9</gtr:id><gtr:title>Context adaptive training with factorized decision trees for HMM-based statistical parametric speech synthesis</gtr:title><gtr:parentPublicationTitle>Speech Communication</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/4ee5babd6aada8b275af983e29e4c2a2"><gtr:id>4ee5babd6aada8b275af983e29e4c2a2</gtr:id><gtr:otherNames>Yu K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/63B6823E-C57E-43A7-8C55-4D5AADCDEE60"><gtr:id>63B6823E-C57E-43A7-8C55-4D5AADCDEE60</gtr:id><gtr:title>The Hidden Information State model: A practical framework for POMDP-based spoken dialogue management</gtr:title><gtr:parentPublicationTitle>Computer Speech &amp; Language</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ac95d35d82495a7bfff7f23cb13d44f3"><gtr:id>ac95d35d82495a7bfff7f23cb13d44f3</gtr:id><gtr:otherNames>Young S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/94B6F51D-F7A1-4826-9E70-E24A27B71291"><gtr:id>94B6F51D-F7A1-4826-9E70-E24A27B71291</gtr:id><gtr:title>Continuous F0 Modeling for HMM Based Statistical Parametric Speech Synthesis</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/4ee5babd6aada8b275af983e29e4c2a2"><gtr:id>4ee5babd6aada8b275af983e29e4c2a2</gtr:id><gtr:otherNames>Yu K</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/E82B82CE-7050-4883-835F-E930207035F9"><gtr:id>E82B82CE-7050-4883-835F-E930207035F9</gtr:id><gtr:title>Cognitive User Interfaces</gtr:title><gtr:parentPublicationTitle>IEEE Signal Processing Magazine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ac95d35d82495a7bfff7f23cb13d44f3"><gtr:id>ac95d35d82495a7bfff7f23cb13d44f3</gtr:id><gtr:otherNames>Young S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/1496A1F1-C73F-49C6-882B-AE773A9A050E"><gtr:id>1496A1F1-C73F-49C6-882B-AE773A9A050E</gtr:id><gtr:title>Parameter Estimation for agenda-based user simulation</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/9791fca23775ade4aa0ea7fe0a977f7e"><gtr:id>9791fca23775ade4aa0ea7fe0a977f7e</gtr:id><gtr:otherNames>Simon Keizer</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/61E3D582-850C-406F-9A12-EA6476B401AA"><gtr:id>61E3D582-850C-406F-9A12-EA6476B401AA</gtr:id><gtr:title>Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems</gtr:title><gtr:parentPublicationTitle>Computer Speech &amp; Language</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/692e32cb96d7f29c612d1535239745c1"><gtr:id>692e32cb96d7f29c612d1535239745c1</gtr:id><gtr:otherNames>Thomson B</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/F013930/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>699D8438-2A43-4BCF-B1A4-6240ED82CEEE</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Human Communication in ICT</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>