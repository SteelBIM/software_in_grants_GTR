<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/28CC501F-055A-49BC-BAB1-E322A3A13A4F"><gtr:id>28CC501F-055A-49BC-BAB1-E322A3A13A4F</gtr:id><gtr:name>University of Buenos Aires</gtr:name><gtr:address><gtr:line1>Calle 508 N. 881</gtr:line1><gtr:line2>Quequen</gtr:line2><gtr:line4>Buenos Aires</gtr:line4><gtr:line5>Buenos Aires, CP 7631</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Argentina</gtr:country></gtr:address></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/C842A34F-18F7-454D-A259-FED802368496"><gtr:id>C842A34F-18F7-454D-A259-FED802368496</gtr:id><gtr:name>University of Leicester</gtr:name><gtr:department>Engineering</gtr:department><gtr:address><gtr:line1>University Road</gtr:line1><gtr:line4>Leicester</gtr:line4><gtr:line5>Leicestershire</gtr:line5><gtr:postCode>LE1 7RH</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/C842A34F-18F7-454D-A259-FED802368496"><gtr:id>C842A34F-18F7-454D-A259-FED802368496</gtr:id><gtr:name>University of Leicester</gtr:name><gtr:address><gtr:line1>University Road</gtr:line1><gtr:line4>Leicester</gtr:line4><gtr:line5>Leicestershire</gtr:line5><gtr:postCode>LE1 7RH</gtr:postCode><gtr:region>East Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/28CC501F-055A-49BC-BAB1-E322A3A13A4F"><gtr:id>28CC501F-055A-49BC-BAB1-E322A3A13A4F</gtr:id><gtr:name>University of Buenos Aires</gtr:name><gtr:address><gtr:line1>Calle 508 N. 881</gtr:line1><gtr:line2>Quequen</gtr:line2><gtr:line4>Buenos Aires</gtr:line4><gtr:line5>Buenos Aires, CP 7631</gtr:line5><gtr:region>Outside UK</gtr:region><gtr:country>Argentina</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/710674CA-6C6D-4071-82D5-8E455CDEC2D2"><gtr:id>710674CA-6C6D-4071-82D5-8E455CDEC2D2</gtr:id><gtr:firstName>Matias</gtr:firstName><gtr:otherNames>Julian</gtr:otherNames><gtr:surname>Ison</gtr:surname><gtr:orcidId>0000-0003-2937-8069</gtr:orcidId><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FI016899%2F1"><gtr:id>A080E02B-F0E4-4C07-A523-8E8E5CED1523</gtr:id><gtr:title>Bridging the gap between eye movements and event-related potentials</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/I016899/1</gtr:grantReference><gtr:abstractText>In this project we will measure the brain activity of subjects searching for hidden targets in crowded scenes (e.g. Waldo in the Where's Waldo game). Neuronal activity will be registered non-invasively with an electroencephalographic (EEG) system. Simultaneously, the subject's gaze will be recorded with an eye tracker. This combined methodology will represent a shift in the way conventional EEG paradigms are performed, where eye movements are minimised and experimental conditions are fully controlled by the experimenter. We propose to combine eye tracking and EEG to gain new insights into the neuronal underpinning of visual search. By merging both technologies, we will be able to study brain activity under naturalistic conditions where the subject decides where and how to explore a scene. Moreover, we will optimise different methodologies to assess and reduce the impact of eye movements on the EEG signal. Overall, this project has multiple areas of application including defence and the health-care sector.</gtr:abstractText><gtr:potentialImpactText>The proposed research has the potential to have a wide impact over multiple application domains: The proposed methodology to obtain and analyse concurrent EEG and eye movements recordings will be considered for patent submission, directly benefiting the University of Leicester and increasing the economic competitiveness of the United Kingdom. A possible collaboration with NHS will be looked for to apply the methods developed during this project. This would benefit patients and healthcare practitioners. Visual search is a task of great importance appearing in diverse fields. For example, the military industry has multiple needs for aerial reconnaissance. The single-trial analysis of ERPs where subjects are allowed to change their gaze can improve the performance of subjects in time demanding decision-making tasks. This can potentially be relevant for national security. The proposed research's main ideas are easily comprehensible. This key fact will be used for reaching the general audience through several events for public engagement. This will contribute to increasing public awareness and understanding of science.</gtr:potentialImpactText><gtr:fund><gtr:end>2013-01-03</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2011-11-04</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>101504</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of Buenos Aires</gtr:collaboratingOrganisation><gtr:country>Argentina, Argentine Republic</gtr:country><gtr:department>Department of Computer Science</gtr:department><gtr:description>Juan</gtr:description><gtr:id>93690136-3258-4461-8E27-C3FAEF3498E3</gtr:id><gtr:impact>Lisandro Kaunitz, Juan E Kamienkowski, Alexander Varatharajah, Mariano Sigman, Rodrigo Quian Quiroga &amp;amp; Matias J. Ison
Looking for a face in the crowd: fixation-related potentials in an eye-movement visual search task.
NeuroImage 89, 297-305 (2014).
Juan E Kamienkowski*, Matias J Ison*, Rodrigo Quian Quiroga, Mariano Sigman 
Fixation-related potentials in visual search: a combined EEG and eye tracking study.
J Vis July 9, 12(7): 4 (2012). *Equal Contribution.</gtr:impact><gtr:partnerContribution>Design, Execution of Research, Data Analyses</gtr:partnerContribution><gtr:piContribution>Design, Execution of Research, Data Analyses</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2010-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>European Conference of Eye Movements (Lund)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>E83B0C3E-10C2-4A14-89C3-500653170CAB</gtr:id><gtr:impact>An international conference, where the study I collaborated on was presented by team member Dr. Matias Ison. We were hoping to get opinions from experts in the field, as well as acknowledgement on some of the findings. The feedback was all positive and the questions posed led to other branches of analysis to be performed, and key improvements made that were the foundations for later work. The research presented was later published (can be seen in the publication section).</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Study participants or study members</gtr:primaryAudience><gtr:url>http://ecem2013.eye-movements.org/</gtr:url><gtr:year>2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Labman</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>7C374038-0C8A-4374-9308-851838D0B0E4</gtr:id><gtr:impact>2nd LATIN AMERICAN BRAN MAPPING NETWORK MEETING. To take place in Buenos Aires (Argentina) in March, 2017.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Undergraduate students</gtr:primaryAudience><gtr:url>http://2ndmeeting.labman.org/meeting_schedule/</gtr:url><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>European Conference of Eye Movements (Vienna)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>61A86802-08FD-454D-A3FF-03D6CF69D874</gtr:id><gtr:impact>International conference where I presented the main findings of the research I have undertaken in the last 3 years. The main aim was to present my work and defend it against scrutiny from leading experts in the field. The work was successfully defended and the result was better than expected; with many researchers in a similar field asking how we performed certain data collection, as well as the resulting analysis. After the presentation I remained after to discuss the findings with many other researchers who were interested in what we had found.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Study participants or study members</gtr:primaryAudience><gtr:url>http://ecem2015.univie.ac.at/</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Postgraduate Festival (University of Leicester)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>6E8D5E0B-A485-465B-9D24-4098F4517429</gtr:id><gtr:impact>Presented a poster on the work to date, where the majority of those attending where industry specialists. A lot of questions on the work were how it applied to the &amp;quot;real world&amp;quot;, and what effect it could have. There were quite a few long discussions and engagement with some attending, very interested in the work and where it could progress to. Many of whom I exchanged contact information with.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:url>http://www2.le.ac.uk/research/festival</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Brain Awareness Day (University of Leicester)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>223C5E7B-174A-40BB-A161-7C5603FAA545</gtr:id><gtr:impact>Presented a poster on the research at an open day on &amp;quot;Brain Awareness Day&amp;quot;. This was open to the public but had many schools visiting with over 100 potential students asking questions about the research and finding a new interest to pursue. With a students discovering for the first time what neuroscience involved.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:url>http://www2.le.ac.uk/departments/npb/news-1/baw/brain-awareness-day-event-for-a-level-students</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>585000</gtr:amountPounds><gtr:country>Argentina, Argentine Republic</gtr:country><gtr:currCode>ARS</gtr:currCode><gtr:currCountryCode>Argentina</gtr:currCountryCode><gtr:currLang>es_AR</gtr:currLang><gtr:description>PIP 2015-2017</gtr:description><gtr:end>2019-08-02</gtr:end><gtr:fundingOrg>National Scientific and Technical Research Council (Argentina)</gtr:fundingOrg><gtr:fundingRef>11220150100787CO</gtr:fundingRef><gtr:id>FD859E0B-8BEE-4F3B-AAC2-AD1AF2C78DD7</gtr:id><gtr:sector>Public</gtr:sector><gtr:start>2016-09-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>323993</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:department>EPSRC Doctoral Training Grant</gtr:department><gtr:description>EPSRC</gtr:description><gtr:end>2015-09-02</gtr:end><gtr:fundingOrg>Faculty of Engineering</gtr:fundingOrg><gtr:id>0641FD90-176D-4566-874D-5B3F28CC2A6B</gtr:id><gtr:sector>Academic/University</gtr:sector><gtr:start>2012-10-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The possible applications of our research have been disseminated to the General Public by talks and press releases (receiving wide media coverage from The Huffington Post, theEngineer, CNN &amp;quot;What's Next&amp;quot;, among others. It has therefore contributed to increasing public awareness and understanding of science.</gtr:description><gtr:firstYearOfImpact>2013</gtr:firstYearOfImpact><gtr:id>A3164C0F-9139-45AC-A5CD-1AE4D8F40E36</gtr:id><gtr:impactTypes><gtr:impactType>Societal</gtr:impactType></gtr:impactTypes><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>This work aimed to perform a non-invasive study of brain activity under free-viewing conditions. For that purpose novel methodologies were developed to combine simultaneous electroencephalographic (EEG) and eye movements recordings. We designed an eye-movement visual search paradigm that allowed us to concurrently record EEG and eye movements while subjects were asked to find a hidden target face in a crowded scene with distractor faces. We calculated the brain signals aligned to fixations landing on targets and distractors and further compared those signals with the ones obtained in a control (classical) task at fixation. 

The original objectives of the proposal were largely achieved. As originally hypothesised, we showed the emergence of robust sensory components associated with the perception of stimuli and cognitive components associated with the detection of target faces, showing qualitative similarities as well as differences in terms of scalp topography and latency between free-viewing and classical tasks. 

By using single trial analyses, we also showed that fixations to target and distractors could be decoded from the EEG signals above chance level in 11 out of 12 subjects. 

Altogether, our results show that EEG signatures related to cognitive behavior develop across spatially unconstrained exploration of natural scenes and provide a first step towards understanding the mechanisms of target detection during natural search.</gtr:description><gtr:exploitationPathways>We believe our results will encourage further work to understand the mechanisms of object processing and target detection during visual exploration of natural scenes. The methodology we developed can be further exploited by Neuroscientists and Psychologists who routinely use EEG recordings. 
Visual search is a ubiquitous task of great importance appearing in many diverse fields. For example, the military industry has multiple needs for aerial reconnaissance. An expert typically has to quickly detect a structure. The single-trial analyses of ERPs aligned to fixation onset are potentially relevant for national security. 
In a wider context, the research grant could other applications in different domains. One example is the detection of drowsiness in drivers, where the simultaneous use of EEG and eye movements recordings could help detect when those drivers start to feel tired and possibly prevent dangerous accidents. 
The brain and eye-tracking technology could also be used to develop brain computer interfaces, which aim to restore movement or communication to people with serious movement disabilities. For instance, people with amyotrophic lateral sclerosis, a disease that causes progressive degeneration of motor neurons, maintain good control of their eye movements until late stages of the illness.
 Incorporating eye-tracking with EEG control could lead to improved brain computer interfaces. The same principle could also be used for hands-free video games in which players control the action with their eye movements and thoughts.</gtr:exploitationPathways><gtr:id>373729AF-78A0-4A36-9F0A-5C43C667BD7E</gtr:id><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Creative Economy,Digital/Communication/Information Technologies (including Software),Healthcare,Transport</gtr:sector></gtr:sectors><gtr:url>http://www.sciencedirect.com/science/article/pii/S105381191301210X</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/39FE426F-25D5-4F1C-8880-0A3B0C741E9E"><gtr:id>39FE426F-25D5-4F1C-8880-0A3B0C741E9E</gtr:id><gtr:title>EEG Signal Dynamics in Unrestricted Natural Visual Search</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/cd0e814703fc53b4d5049673079d35f8"><gtr:id>cd0e814703fc53b4d5049673079d35f8</gtr:id><gtr:otherNames>Varatharajah, A.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/A1F4FDAB-DB66-4C43-87F3-625553A84E06"><gtr:id>A1F4FDAB-DB66-4C43-87F3-625553A84E06</gtr:id><gtr:title>Looking for a face in the crowd: fixation-related potentials in an eye-movement visual search task.</gtr:title><gtr:parentPublicationTitle>NeuroImage</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/df9550471e9e1ac8df53921d1bfd4c2e"><gtr:id>df9550471e9e1ac8df53921d1bfd4c2e</gtr:id><gtr:otherNames>Kaunitz LN</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1053-8119</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/8DB2F164-3791-4758-B8F1-645BF7507AEF"><gtr:id>8DB2F164-3791-4758-B8F1-645BF7507AEF</gtr:id><gtr:title>Fixation-related potentials in visual search: a combined EEG and eye tracking study.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/9a0ce99828454b2047639af045acacad"><gtr:id>9a0ce99828454b2047639af045acacad</gtr:id><gtr:otherNames>Kamienkowski JE</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/I016899/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>55</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>45</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>EFFEC6B1-6BC8-4C9D-9D77-02CEF5E4E301</gtr:id><gtr:percentage>45</gtr:percentage><gtr:text>Biomedical neuroscience</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>55</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>