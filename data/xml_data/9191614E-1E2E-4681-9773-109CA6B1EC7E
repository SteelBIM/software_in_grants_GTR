<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Phonetics and Linguistics</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/F620AB49-FD4E-4FF0-A718-BEB65B3027A4"><gtr:id>F620AB49-FD4E-4FF0-A718-BEB65B3027A4</gtr:id><gtr:firstName>Valerie</gtr:firstName><gtr:otherNames>Lilian</gtr:otherNames><gtr:surname>Hazan</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=ES%2FF002262%2F1"><gtr:id>9191614E-1E2E-4681-9773-109CA6B1EC7E</gtr:id><gtr:title>Speaker-controlled variability in connected discourse: acoustic-phonetic characteristics and impact on speech perception</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/F002262/1</gtr:grantReference><gtr:abstractText>&lt;p>This project investigates why certain speakers are easier to understand than others. Speech production is highly variable both across and within speakers. This is partly due to differences in the vocal tract anatomy and partly under the control of the speaker. This project examines whether clearer speakers are more extreme in their articulations (as measured from the acoustic properties of their speech) or whether they are more consistent in their production of speech sounds. In order to better model natural communication, the speech to be analysed is recorded using a new task aimed at eliciting spontaneous dialogue with specific keywords. The first study investigates whether 'inherent' speaker clarity is consistent across different types of discourse and whether speaker clarity is more closely correlated with cross-category differences or within-category consistency in production. The second study investigates whether clearer speakers show a greater degree of adaptation to the needs of listeners. This study has implications for models of speech perception. Understanding what makes a 'clear speaker' will also be informative for applications requiring clear communication, such as teaching, speech and language therapy, and the selection of voices for clinical testing and for speech technology applications.&lt;/p></gtr:abstractText><gtr:fund><gtr:end>2011-02-28</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2008-03-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>311969</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Invited lecture: What can speaker-listener interaction tell us about speech perception in adverse listening conditions?</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>6096CE7C-B668-4992-A6DC-5F3A0D6EE670</gtr:id><gtr:impact>This was an invited presentation at a workshop on psycholinguistic approaches to speech perception in adverse listening conditions. This presentation publicised our ESRC project and also our newly-developed diapixUK task that can be used for recording corpora of spontaneous speech

Other labs have started using our diapixUK materials for their recordings</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2010</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited lecture: Clear speech strategies in speaker-listener interactions</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>E01759DB-8B51-4E94-A9C2-D02BC10C3DEC</gtr:id><gtr:impact>Invited lecture - Research colloquium series, MARCS Laboratories, University of Western Sydney, Sydney, Australia.



This lecture gave an overview of our work on this project.

Discussions that took place during my visit to MARCS led to a successful ESRC grant application.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2011</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Media - Radio 4 interview about our project</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>A60A38BA-9C2E-46D1-9937-101ADCEC5AA1</gtr:id><gtr:impact>Interview with Valerie Hazan on Material World, BBC Radio 4 about the Noisy World exhibit at the Royal Society Summer Exhibition 2011 which included a demonstration linked to work developed within this research project. The interview is available online and includes a demonstration of our diapix task.

This publicised our project at a crucial time and aided our participant recruitment.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.bbc.co.uk/programmes/b01292vf</gtr:url><gtr:year>2011</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Noisy world exhibit - Royal Society summer exhibition</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>3B8280BF-6408-4401-83C2-E5DDAC015AFC</gtr:id><gtr:impact>Our modern world is full of noise: from machinery, transport, radio &amp;amp; television, MP3 players, and other people talking. This exhibit showed how background noises of all types affect our ability to understand speech, and makes it harder for us to think about and remember things. 

The exhibit involved a live demonstration of the diapix task and test conditions that we used in our project to record interactions between two speakers in good and adverse conditions.

Our work received great exposure as the result of our inclusion in the RS Summer Exhibition. It was features on Radio 4 and the website and other materials developed for the Summer Exhibition were very useful tools for further dissemination. We also recruited some participants who found out about our work at the exhibition.</gtr:impact><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://royalsociety.org/summer-science/2011/noisy-world/</gtr:url><gtr:year>2011</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>British library event - Do you hear what i hear?</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>CCA7C6EC-1262-4EE8-A237-08BBCD1DF814</gtr:id><gtr:impact>Our demonstration of the Diapix task was included in a public event at the British Library which aimed to highlight how our brain perceives and interprets speech and music.

This event gave use valuable experience which led us to then submit a successful proposal for inclusion in the Royal Society Summer Exhibition.</gtr:impact><gtr:partOfOfficialScheme>true</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.bl.uk/reshelp/experthelp/science/eventsandprojects/eventsummaries.html#brainandsound</gtr:url><gtr:year>2010</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>307179</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Speaker-controlled variability in children's speech in interaction</gtr:description><gtr:end>2014-05-02</gtr:end><gtr:fundingOrg>Economic and Social Research Council (ESRC)</gtr:fundingOrg><gtr:fundingRef>RES-062-23-3106</gtr:fundingRef><gtr:id>A2879482-932E-4AD8-90EE-C564CF1AB82C</gtr:id><gtr:sector>Public</gtr:sector><gtr:start>2011-06-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>13450</gtr:amountPounds><gtr:country>Australia, Commonwealth of</gtr:country><gtr:currCode>AUD</gtr:currCode><gtr:currCountryCode>Australia</gtr:currCountryCode><gtr:currLang>en_AU</gtr:currLang><gtr:description>Clear speech strategies : how auditory and visual cues are weighted</gtr:description><gtr:end>2012-12-02</gtr:end><gtr:fundingOrg>University of Western Sydney</gtr:fundingOrg><gtr:fundingRef>20211.71719 [ORS]</gtr:fundingRef><gtr:id>4874CBAF-6F52-4CEA-8022-30397AF15729</gtr:id><gtr:sector>Academic/University</gtr:sector><gtr:start>2011-09-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The use of the diapix method, developed to collect speaker/listener interactions in good and adverse conditions is beginning to be investigated as a clinical tool to look at communication efficiency in children and adults with language or hearing impairments.</gtr:description><gtr:firstYearOfImpact>2016</gtr:firstYearOfImpact><gtr:id>0FE6EF9E-1FF6-478D-AD46-158BC57EC247</gtr:id><gtr:impactTypes><gtr:impactType>Societal</gtr:impactType></gtr:impactTypes><gtr:sector>Digital/Communication/Information Technologies (including Software),Education,Healthcare</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We recorded the speech of pairs of participants while they completed a 'spot the difference task' ('diapix') in good listening conditions or when one of the participants found it hard to hear the other due to a simulated cochlear implant (VOC), the presence of babble noise (BAB) or because s/he was not a native English speaker (L2). We analysed the acoustic-phonetic characteristics of the speech produced by 40 speakers (while hearing normally) when interacting with interlocutors experiencing these three different types of communication barrier (VOC, BABBLE, L2). We found that the acoustic-phonetic enhancements made were tailored to counteract a specific adverse condition. Relative to their conversational speech, talkers spoke with higher and more varied pitch range and greater mid-frequency energy when clarifying their speech for an interlocutor hearing them in noise, but did not change these characteristics when clarifying their speech for an interlocutor hearing them via a noise-excited vocoder, where most pitch information is lost and audibility thresholds not an issue. Talkers made these specific adjustments even though not directly experiencing the adverse listening condition As proposed by Lindblom's Hyper-Hypo theory, speech production appeared to be guided by the needs of the listener to the cost of greater effort for the speaker. Perception experiments showed a significant link between improvement in clarity ratings between the casual and VOC condition and degree of acoustic-phonetic change. Talkers' clarity measures were significantly correlated across different diapix conditions: although talkers became clearer in the VOC and BABBLE conditions, their clarity 'ranking' remained consistent relative to their inherent clarity in the 'no barrier' condition. 



We also compared the type of clear speech naturally elicited due to communicative needs with clear speech obtained when participants were instructed to read sentences clearly. Clear read speech was found to have more extreme acoustic-phonetic enhancements than clear spontaneous speech, as more consistently hyper-articulated. 



We investigated the relation between the internal structure of phonetic categories and consonant intelligibility for two phonetic contrasts. Measures of cross-category distance (CCD) (i.e., the difference between two sound categories) and within-category dispersion (WCD) (i.e., of the variability within each sound category) were obtained using 32 iterations per category for each of 40 speakers. These measures varied substantially across talkers but were not correlated across contrasts suggesting a lack of within-talker consistency in CCD and WCD. Consonant identification data for eight talkers presenting extremes of CCD or WCD revealed some talker effects on reaction time, but these were not correlated with either of the two measures. We found no significant correlations between CCD or WCD measures and broader measures of clarity or communication effectiveness in the diapix tasks. We conclude that the conclusions of Newman et al (2001) were premature and that a talker's consistency of production or contrast salience does not appear to be directly correlated with their inherent intelligibility.</gtr:description><gtr:exploitationPathways>The diapixUK materials that we developed for this project could be further developed for clinical use by speech and language therapists. They are appropriate for use with children as well as adults, and a simple measure of transaction time provides a general measure of communication efficiency. The speech that is recorded can be analysed to investigate aspects of communication such as clarification requests, repair strategies, lexical diversity. The complete corpus of speech recordings and aligned orthographic transcriptions is available online (LUCID corpus), and is made available to other researchers on request.

The diapixUK picture materials are also available for use by other researchers. They have been constructed so that they can easily be adapted for other research purposes.

Both the corpus and test materials are in regular demand and in use by researchers from many different countries</gtr:exploitationPathways><gtr:id>E8D9EE9B-44F9-454C-AB0D-E8C163DC573C</gtr:id><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Healthcare</gtr:sector></gtr:sectors><gtr:url>http://www.ucl.ac.uk/psychlangsci/research/speech/variability/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>The LUCID (London UCL Clear speech in interaction) corpus contains all of the speech recordings made for this project as well as word-aligned orthographic transcriptions. The corpus is available to other researchers for non-commercial purposes as part of the online OSCAAR resource on password request.</gtr:description><gtr:id>1AFF5CD7-D80B-4C80-B904-91EBF49EA4EC</gtr:id><gtr:impact>This corpus and the related picture materials have now been used by a number of other researchers who have published work based on the use of Diapix at major international conferences such as Interspeech and in journal articles.</gtr:impact><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>LUCID corpus</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://oscaar.ling.northwestern.edu/collection.php?c=19</gtr:url><gtr:yearFirstProvided>2011</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/4F0EF981-667F-41A4-8E41-39DBAFAA4BFC"><gtr:id>4F0EF981-667F-41A4-8E41-39DBAFAA4BFC</gtr:id><gtr:title>DiapixUK: task materials for the elicitation of multiple spontaneous speech dialogs.</gtr:title><gtr:parentPublicationTitle>Behavior research methods</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d8960949b7145d41cb88c41c76118195"><gtr:id>d8960949b7145d41cb88c41c76118195</gtr:id><gtr:otherNames>Baker R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1554-351X</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/106A816B-201A-49ED-AA3F-F6B8CD6F59D5"><gtr:id>106A816B-201A-49ED-AA3F-F6B8CD6F59D5</gtr:id><gtr:title>How does foreigner-directed speech differ from other forms of listener-directed clear speaking styles?</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/fccf95ea72a09d39687e96078b8602c6"><gtr:id>fccf95ea72a09d39687e96078b8602c6</gtr:id><gtr:otherNames>Hazan V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/C4C38C8F-8E7C-4912-8B5B-B9BAE019D4C4"><gtr:id>C4C38C8F-8E7C-4912-8B5B-B9BAE019D4C4</gtr:id><gtr:title>Clear speech strategies and speech perception in adverse listening conditions</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/95779e5731faddba0fdb82905521df86"><gtr:id>95779e5731faddba0fdb82905521df86</gtr:id><gtr:otherNames>Grynpas, J.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/A7FE1CA7-1805-4F13-A57A-C9E092373884"><gtr:id>A7FE1CA7-1805-4F13-A57A-C9E092373884</gtr:id><gtr:title>Acoustic-phonetic characteristics of clear speech in bilinguals</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3734a64d5056b1148c3e5e8ef171e1d3"><gtr:id>3734a64d5056b1148c3e5e8ef171e1d3</gtr:id><gtr:otherNames>Granlund, S.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/B44E2D3E-F63A-47D4-89CE-CC1731BBF91D"><gtr:id>B44E2D3E-F63A-47D4-89CE-CC1731BBF91D</gtr:id><gtr:title>Do talkers produce less dispersed phoneme categories in a clear speaking style?</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/bf1fcbf170b10a7ee34b7c823e035a48"><gtr:id>bf1fcbf170b10a7ee34b7c823e035a48</gtr:id><gtr:otherNames>Tuomainen O</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/6CB9D56D-7C66-40C0-BCF0-296E6DADF5D8"><gtr:id>6CB9D56D-7C66-40C0-BCF0-296E6DADF5D8</gtr:id><gtr:title>LUCID : a corpus of spontaneous and read clear speech in British English</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/6d3877f7b81a52ecc89b044cd3b2a18c"><gtr:id>6d3877f7b81a52ecc89b044cd3b2a18c</gtr:id><gtr:otherNames>Baker, R.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/BBD94E46-9BED-4039-BB89-3B7692074B0A"><gtr:id>BBD94E46-9BED-4039-BB89-3B7692074B0A</gtr:id><gtr:title>Does reading clearly produce the same acoustic-phonetic modifications as spontaneous speech in a clear speaking style?</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/7a236fd029e7b14725277ba5ee9d3ca5"><gtr:id>7a236fd029e7b14725277ba5ee9d3ca5</gtr:id><gtr:otherNames>Hazan V.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/D646E419-FEA7-4E1F-9F27-0100AA98C172"><gtr:id>D646E419-FEA7-4E1F-9F27-0100AA98C172</gtr:id><gtr:title>Is consonant perception linked to within-category dispersion or across-category distance?</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/da16f6a5c88a704e5202cadf0cb3c561"><gtr:id>da16f6a5c88a704e5202cadf0cb3c561</gtr:id><gtr:otherNames>Hazan, V.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/4692EAE7-2845-497A-96B5-73233356963C"><gtr:id>4692EAE7-2845-497A-96B5-73233356963C</gtr:id><gtr:title>Acoustic-phonetic characteristics of speech produced with communicative intent to counter adverse listening conditions.</gtr:title><gtr:parentPublicationTitle>The Journal of the Acoustical Society of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/fccf95ea72a09d39687e96078b8602c6"><gtr:id>fccf95ea72a09d39687e96078b8602c6</gtr:id><gtr:otherNames>Hazan V</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>0001-4966</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/A4796167-7FF1-49DF-95FF-F2B61B229DB1"><gtr:id>A4796167-7FF1-49DF-95FF-F2B61B229DB1</gtr:id><gtr:title>An acoustic-phonetic comparison of the clear speaking styles of Finnish-English late bilinguals</gtr:title><gtr:parentPublicationTitle>Journal of Phonetics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/e7a705293eca76e99c402200dcc7e893"><gtr:id>e7a705293eca76e99c402200dcc7e893</gtr:id><gtr:otherNames>Granlund S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RES">RES-062-23-0681</gtr:identifier><gtr:identifier type="RCUK">ES/F002262/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>B94A2498-60DA-4055-A957-686B6CB42654</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Linguistics</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>28710E94-8B47-404A-BD40-7BCB8C709774</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Linguistics (General)</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>