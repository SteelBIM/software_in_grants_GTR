<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/CD35D908-C2AF-4C14-9BC4-519C775CDB6E"><gtr:id>CD35D908-C2AF-4C14-9BC4-519C775CDB6E</gtr:id><gtr:name>City University London</gtr:name><gtr:department>School of Health Sciences</gtr:department><gtr:address><gtr:line1>Northampton Square</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>EC1V 0HB</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/CD35D908-C2AF-4C14-9BC4-519C775CDB6E"><gtr:id>CD35D908-C2AF-4C14-9BC4-519C775CDB6E</gtr:id><gtr:name>City University London</gtr:name><gtr:address><gtr:line1>Northampton Square</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>EC1V 0HB</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name><gtr:address><gtr:line1>Economic and Social Research Council</gtr:line1><gtr:line2>North Star Avenue</gtr:line2><gtr:line3>Polaris Way</gtr:line3><gtr:line4>Swindon</gtr:line4><gtr:line5>Wiltshire</gtr:line5><gtr:postCode>SN2 1UJ</gtr:postCode><gtr:region>South West</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>CO_FUNDER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/99F5082C-DE7A-48BF-872D-03E150CEDD53"><gtr:id>99F5082C-DE7A-48BF-872D-03E150CEDD53</gtr:id><gtr:firstName>Michael</gtr:firstName><gtr:surname>Morgan</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/09CF3B75-7707-4B8D-8EFC-47EA288E5D65"><gtr:id>09CF3B75-7707-4B8D-8EFC-47EA288E5D65</gtr:id><gtr:firstName>Joshua</gtr:firstName><gtr:otherNames>Adam</gtr:otherNames><gtr:surname>Solomon</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FH033955%2F1"><gtr:id>83467D25-4A40-49F4-B1E7-3CD3E2A953EF</gtr:id><gtr:title>Efficiency of Visual Statistics</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/H033955/1</gtr:grantReference><gtr:abstractText>The merest glance is usually sufficient for an observer to get the gist of a scene. That is because the visual system statistically summarises its input. For example, the observer may infer a forest scene if there are significantly more than 20 trees in the picture. If most of those trees aren't within a few degrees of vertical, the observer may infer that the camera was tilted. Our interest is primarily the efficiencies with which statistics like these are calculated. For example, how many trees can the observer use to estimate camera angle? Certain pictorial details are also inaccessible when observers do not look directly at an object. Like brief glimpses, our peripheral vision is often merely statistical. We will compare the efficiencies with which central and peripheral vision are capable of computing various image statistics, like orientation, position, and size. We will also investigate claims of greater efficiency for noticing differences in humanoid images. In fact, we now know that the visual system tends to exaggerate image differences. Happy or dark faces can appear less happy or dark, when surrounded by even happier or darker ones. We will test how well the amount of exaggeration can be predicted by visibility of the difference. To insulate our results from bias, we will focus on pictorial differences that cannot be so easily described.</gtr:abstractText><gtr:potentialImpactText>This proposal is a collaboration between City University London, Max-Planck Koln and UC-Irvine. Our research will be disseminated in the usual way: the PI's and postdoc will attend one international conference each year, and present their work. All three institutions have PR departments which can help generate buzz. The postdoc should certainly enjoy his/herself working in the Solomon/Morgan lab. And of course we would attempt to further a good postdoc's career in any way possible. At the very least, our research will be of interest to the other vision scientists (e.g. Roger Watt and Steve Dakin) who have focussed on orientation statistics. Naturally, we hope that the more cognitively oriented psychologists who have investigated the visual statistics of size (e.g. Dan Arielly, Anne Treisman and Dan Simons) will adopt what we feel is a more principled approach to the measurement of statistical efficiency. If our intuition regarding crowding (i.e. that it reflects an obligatory statistical analysis with high efficiency) proves correct, then our work may influence the much larger group of scientists currently trying to understand that topic. Our other major, as-yet-untested intuition concerns the relationship between salience and gain control. Both of these topics have come under intense scrutiny by psychologists, neuroscientists and computational modellers. Our grandest ambition is that our research may inspire parallel extensions in all of these fields. Vision Science has a long history of benefitting health care, but it is hard to judge the specific implications of our research and when they may be realised. That is the nature of basic research; its benefits are often unforeseen. For example, Solomon's wavelet sensitivity functions (Watson et al 1997) surprisingly formed the basis of many digital watermarks and Chubb et al's (1989) contrast-contrast exaggeration surprisingly has the potential to separate schizophrenics from normal observers (Dakin et al 2005). Of course, the other side of the coin is that harm is also often unforeseen. Nonetheless, we can be reasonably confident our research will not directly benefit any terrorism or other evil.</gtr:potentialImpactText><gtr:fund><gtr:end>2014-02-13</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2011-02-14</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>432941</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>In a series of six papers, Solomon and colleagues investigated human observers' ability to form statistical summaries from multiple sources of visual information. The statistical summary investigated by Morgan et al (2012) was positional variance. A random adjustment was applied to the position of each dot in an otherwise regular geometric pattern. Observers were asked to compare two such patterns and select the one with the larger positional variance. The results clearly demonstrated that human observers considered the positions of more than one dot in each pattern. However, an ideal observer could have performed just as well with as few as 5 or 6 dots. 

Visual estimates of average size are limited to a similar number of items (Solomon et al 2012 used circles). Gorea et al (2014) pursued this line of research, and found that the sizes of 5 or 6 circles could be estimated simultaneously, almost as soon as the circles became visible. This latter finding suggests some hard-wired neural circuit, capable of making multiple size estimates in parallel. 

Also consistent with the idea of a hard-wired neural circuit is the finding of an after-effect of perceived regularity (Ouhnana et al 2013): The apparent positional variance in any dot array will be reduced after staring at other dot arrays with higher variance.

Inconsistent with the idea of a hard-wired neural circuit are results from our investigations of orientation averaging. Observers asked to compare the mean orientations in two sets of oriented elements effectively ignore all but 2 or 3 elements in each set (Solomon 2010). When viewing time is limited, the average observer effectively ignores all but 2 (Solomon et al 2016). 

In the aforementioned six papers, proposals are made for the computations performed by the neural circuits putatively responsible for regularity discrimination and size averaging. However, given human observers' particularly low efficiency, there probably is no neural circuit devoted to orientation averaging. 

Finally, in a series of three papers, May and Solomon (2013, 2015a, 2015b) describe the mathematical relationship between neural activity and the consistencies with which human observers can a) detect faint visual stimuli and b) discriminate between stimuli of almost identical contrast.</gtr:description><gtr:exploitationPathways>Here are three ways our findings have already been used:
1) Kompaniez, Abbey, Boone, and Webster cited the after-effect of regularity as inspiration in their search for an after-effect of viewing dense radiological images. (They found one. Subsequently viewed images appear less dense.)
2) Protonotarios, Baum et al (J. R. Soc. Interface 2014) applied a modified version of our model for positional-variance encoding to the distribution of bristle cells on developing fruit flies. The aforementioned variance decreases as the flies age. If that isn't a prime example of the unexpected application of basic research, then I don't know what is!
3) Groups as diverse as Hu, Lesmes et al (J. Vis. 2015) who developed a protocol for rapidly assessing contrast sensitivity in clinical populations, Stirman, Townsend, and Smith (Vis. Res. 2016) who developed a touchscreen-based method for assesing motion perception in mice, and Hathibelagal, Feigl et al (JOSA A, 2016) who measured rod-cell signalling have all used May &amp;amp; Solomon's (2013) 'Four Theorems' to fine-tune their psychophysical methods.</gtr:exploitationPathways><gtr:id>1D4FB973-2340-4C23-8572-1FAA7BF76BB5</gtr:id><gtr:sectors><gtr:sector>Pharmaceuticals and Medical Biotechnology</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/E1E930DB-7A5B-4D34-8DBE-7C89B1F6EA5E"><gtr:id>E1E930DB-7A5B-4D34-8DBE-7C89B1F6EA5E</gtr:id><gtr:title>Aftereffect of perceived regularity.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/44d61952c940def8c63ae76cf314c135"><gtr:id>44d61952c940def8c63ae76cf314c135</gtr:id><gtr:otherNames>Ouhnana M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/F72C6433-3B71-45BD-A895-793D07D023BD"><gtr:id>F72C6433-3B71-45BD-A895-793D07D023BD</gtr:id><gtr:title>Inefficiency of orientation averaging: Evidence for hybrid serial/parallel temporal integration.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/decc6d3fa6a7a8bfc2e7504d77de3596"><gtr:id>decc6d3fa6a7a8bfc2e7504d77de3596</gtr:id><gtr:otherNames>Solomon JA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/F6811F59-3484-4324-8B93-D2975BD4702C"><gtr:id>F6811F59-3484-4324-8B93-D2975BD4702C</gtr:id><gtr:title>Perceived direction of motion determined by adaptation to static binocular images.</gtr:title><gtr:parentPublicationTitle>Current biology : CB</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/a62152c799cf061a35f82daba78c1893"><gtr:id>a62152c799cf061a35f82daba78c1893</gtr:id><gtr:otherNames>May KA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0960-9822</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/5A6CCBCF-3B85-4D72-960D-414496066B4E"><gtr:id>5A6CCBCF-3B85-4D72-960D-414496066B4E</gtr:id><gtr:title>One &amp;quot;shape&amp;quot; fits all: the orientation bandwidth of contour integration.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/70124292f27fea5adbccf90351a861a6"><gtr:id>70124292f27fea5adbccf90351a861a6</gtr:id><gtr:otherNames>Hansen BC</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/C907E680-A2D1-481C-B0D0-3E9412B36530"><gtr:id>C907E680-A2D1-481C-B0D0-3E9412B36530</gtr:id><gtr:title>Efficiencies for the statistics of size discrimination.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/decc6d3fa6a7a8bfc2e7504d77de3596"><gtr:id>decc6d3fa6a7a8bfc2e7504d77de3596</gtr:id><gtr:otherNames>Solomon JA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/1C2AF053-C8B4-478A-9146-19620C6873A7"><gtr:id>1C2AF053-C8B4-478A-9146-19620C6873A7</gtr:id><gtr:title>Connecting psychophysical performance to neuronal response properties II: Contrast decoding and detection.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/a62152c799cf061a35f82daba78c1893"><gtr:id>a62152c799cf061a35f82daba78c1893</gtr:id><gtr:otherNames>May KA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/3D8A23F9-CF10-4728-8748-1D33F9AE1543"><gtr:id>3D8A23F9-CF10-4728-8748-1D33F9AE1543</gtr:id><gtr:title>Four theorems on the psychometric function.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/a62152c799cf061a35f82daba78c1893"><gtr:id>a62152c799cf061a35f82daba78c1893</gtr:id><gtr:otherNames>May KA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/F914C99C-ABFE-4218-8B91-469FC010E0D9"><gtr:id>F914C99C-ABFE-4218-8B91-469FC010E0D9</gtr:id><gtr:title>Connecting psychophysical performance to neuronal response properties I: Discrimination of suprathreshold stimuli.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/a62152c799cf061a35f82daba78c1893"><gtr:id>a62152c799cf061a35f82daba78c1893</gtr:id><gtr:otherNames>May KA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/75B25389-C510-4A8B-9CA5-C0EFCDBB2CA2"><gtr:id>75B25389-C510-4A8B-9CA5-C0EFCDBB2CA2</gtr:id><gtr:title>Perceived pattern regularity computed as a summary statistic: implications for camouflage.</gtr:title><gtr:parentPublicationTitle>Proceedings. Biological sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/67bd836e4ec268976f904fa358a76ac6"><gtr:id>67bd836e4ec268976f904fa358a76ac6</gtr:id><gtr:otherNames>Morgan MJ</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>0962-8452</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/FE44C197-9B17-4430-AFBD-3F45FB5F93CC"><gtr:id>FE44C197-9B17-4430-AFBD-3F45FB5F93CC</gtr:id><gtr:title>Contour extracting networks in early extrastriate cortex.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c12787f78239497a0d4d05198b14e8ff"><gtr:id>c12787f78239497a0d4d05198b14e8ff</gtr:id><gtr:otherNames>Dumoulin SO</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/4D729AE4-FB61-4F2B-93CF-26CCD66BC619"><gtr:id>4D729AE4-FB61-4F2B-93CF-26CCD66BC619</gtr:id><gtr:title>The potential roles of saturating and supersaturating contrast-response functions in conjunction detection: reply to Peirce.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/a62152c799cf061a35f82daba78c1893"><gtr:id>a62152c799cf061a35f82daba78c1893</gtr:id><gtr:otherNames>May KA</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/EFCC038C-5C44-4A1F-99D6-02D2CE44C99F"><gtr:id>EFCC038C-5C44-4A1F-99D6-02D2CE44C99F</gtr:id><gtr:title>Pattern masking: the importance of remote spatial frequencies and their phase alignment.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/5af710f9148323a36fb66c3be2955ffc"><gtr:id>5af710f9148323a36fb66c3be2955ffc</gtr:id><gtr:otherNames>Huang PC</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/H033955/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>