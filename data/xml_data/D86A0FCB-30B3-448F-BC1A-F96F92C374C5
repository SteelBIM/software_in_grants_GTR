<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/CD35D908-C2AF-4C14-9BC4-519C775CDB6E"><gtr:id>CD35D908-C2AF-4C14-9BC4-519C775CDB6E</gtr:id><gtr:name>City University London</gtr:name><gtr:department>Sch of Social Sciences</gtr:department><gtr:address><gtr:line1>Northampton Square</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>EC1V 0HB</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/CD35D908-C2AF-4C14-9BC4-519C775CDB6E"><gtr:id>CD35D908-C2AF-4C14-9BC4-519C775CDB6E</gtr:id><gtr:name>City University London</gtr:name><gtr:address><gtr:line1>Northampton Square</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>EC1V 0HB</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/602DB7B6-7020-41C1-8D0D-916F049B4ECB"><gtr:id>602DB7B6-7020-41C1-8D0D-916F049B4ECB</gtr:id><gtr:firstName>Richard</gtr:firstName><gtr:surname>Cook</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=ES%2FK008226%2F1"><gtr:id>D86A0FCB-30B3-448F-BC1A-F96F92C374C5</gtr:id><gtr:title>Motor contributions to the perception of facial expressions</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>ES/K008226/1</gtr:grantReference><gtr:abstractText>&lt;p>This project seeks to understand the psychological mechanisms that allow us to interpret the facial expressions of others. Facial expressions provide a wealth of information about our social environment, making accurate perception essential. Convergent experiments will determine whether knowledge of how we perform facial expressions improves our ability to perceive the expressions we observe.&lt;/p>

&lt;p>First, neuroimaging will be used to study the patterns of brain activation when people view facial expressions. By analysing how those patterns change over time, it is possible to estimate the amount of information flowing from ?motor? areas responsible for performing expressions, to visual areas responsible for expression recognition.&lt;/p>

&lt;p>The second work package studies a phenomenon known as ?adaptation?; a process whereby the mechanisms responsible for expression recognition ?recalibrate? following prolonged visual exposure to a particular expression. The experiments proposed in this package will determine whether repeated expression performance can elicit similar recalibration.&lt;/p>

&lt;p>&amp;nbsp;&lt;/p>

&lt;p>The third work package will determine whether training people with clinically impaired expression recognition to perform particular expressions improves their visual recognition of the trained expressions. If performance expertise contributes to visual perception, perfecting expression execution should improve visual expression recognition.&lt;/p></gtr:abstractText><gtr:potentialImpactText>The project will impact upon clinical research and practice by advancing our understanding of expression perception; helping to elucidate the functional role of the mirror neuron system; and identifying whether impaired expression perception can be enhanced through training. 

i) Impaired expression recognition in clinical and developmental populations
Several developmental and clinical disorders are known to be associated with impaired recognition of facial expressions, including ADHD, alexithymia, autism, dementia, developmental prosopagnosia, dyslexia, multiple sclerosis, and schizophrenia. Moreover, it is widely acknowledged that difficulties recognising expressions are likely to contribute to the profound social difficulties that many of these groups encounter. Developing a sophisticated understanding of the perceptual mechanisms responsible for expression recognition is a necessary step towards developing cognitive and behavioural interventions with a view to improving the quality of life of individuals with these conditions. 

ii) Clinical implications of mirror neuron system dysfunction 
There has been considerable speculation that mirror neuron system dysfunction plays a causal role in the social deficits associated with autistic spectrum conditions. More recently, there has also been increasing speculation that atypical mirror system functioning may also contribute to some of the symptoms experienced by individuals with schizophrenia. By helping to understand the function of the mirror system; whether it mediates a motor contribution to the perception of facial expressions, this project will inform both of these lines of research. 

iii) Expression recognition training in alexithymia 
Drawing on the findings from the first two work packages, the third work package will directly test which types of training improve expression recognition in a group of alexithymics. Alexithymia is a phenomenon characterised by difficulties recognising, distinguishing and describing feelings from the bodily sensations of emotional arousal. There is a growing appreciation of the clinical significance of this trait. For example, while the incidence of alexithymia in the general population is thought to be only 10%, studies suggest severe degrees of alexithymia in at least 50% of individuals with autism. Alexithymia has also been implicated in a range of other conditions including eating disorders, depression, anxiety, schizophrenia, psychopathy, and addictive behaviours. Identifying the types of training that are most effective in enhancing expression recognition, this project will inform the development of interventions aimed at improving alexithymics' quality of life.</gtr:potentialImpactText><gtr:fund><gtr:end>2015-10-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/924BE15C-91F2-4AAD-941A-3F338324B6AE"><gtr:id>924BE15C-91F2-4AAD-941A-3F338324B6AE</gtr:id><gtr:name>ESRC</gtr:name></gtr:funder><gtr:start>2013-11-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>246232</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Talk (Cognitive Psychology Research Group, City University London)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>7F916CF3-2B80-4B3E-A3F1-88863A799698</gtr:id><gtr:impact>Talk sparked questions and discussion afterwards.

Talk increased awareness of research activities.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Invited talk (Institute of Psychiatry, Psychology and Neuroscience; King's College London)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>3FDF8B60-E28B-417E-B83A-4AFF50B94BC1</gtr:id><gtr:impact>Talk sparked questions and discussion afterwards.

Talk generated new collaboration and increased awareness of research activities.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Other academic audiences (collaborators, peers etc.)</gtr:primaryAudience><gtr:url>http://kingsexperience.wordpress.com/2014/09/29/project-report-social-brain/</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>BBC Radio 5 interview</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>BD0DCE1A-E83A-453A-A771-968F681F86AB</gtr:id><gtr:impact>Interview given to Peter Allen on BBC Radio 5 (4th November 2015). Questions related to clinical and neurodevelopmental disorders, including autism and alexithymia, and how they can affect social perception.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public engagement article written for The Conversation</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>0CE1358C-0AD6-434F-89D4-C592848C41CB</gtr:id><gtr:impact>Increased public awareness of social perception research (over 50,000 reads worldwide)</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://theconversation.com/facial-symmetry-and-good-health-may-not-be-related-30637</gtr:url><gtr:year>2014</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Talk given to House of Lords Hansard</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>AD63A8D7-DF76-4DD5-8878-ECE0CDC3C350</gtr:id><gtr:impact>The Hansard are responsible for documenting the debates in the houses of parliament. Their role requires them to learn many new faces each year, and recognise individuals at distance, and from a variety of viewing angles. Prompted by their interest in face recognition, The House of Lords Hansard invited me to Westminster to give a talk on social perception and clinical disorders that impair identity and expression recognition. Around 50 members of the Hansard, civil servants and parliamentarians attended the talk which sparked questions and lively discussion.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>BBC Local Radio interview</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>3CC1B5DF-EE1F-441B-884A-AA51A0683B9A</gtr:id><gtr:impact>Interview given to the Mark Forrest Show (broadcast around the country via BBC local radio network) on 3rd December 2015. Questions related to clinical disorders and neurodevelopmental conditions (e.g. autism, prosopagnosia, alexithymia) affecting social perception.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public engagement article written for The Conversation</gtr:description><gtr:form>A magazine, newsletter or online publication</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>21819A85-A2B4-49BB-9723-0E09740D813D</gtr:id><gtr:impact>Increased public awareness of social perception research (over 65,000 reads worldwide)</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>https://theconversation.com/always-forget-a-face-so-does-brad-pitt-dont-just-blame-your-memory-50334</gtr:url><gtr:year>2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>School Visit (Brampton College, Hendon, London)</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>D9F3B8CD-0860-4767-BE28-F286FACF61EC</gtr:id><gtr:impact>Around 40 pupils attended talks given at a local school in 2014 and 2015. Prompted questions and discussion afterwards. The school reported increased interest in Psychology. This has since become a regular annual event.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2014,2015</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>City University London - Open Days</gtr:description><gtr:form>Participation in an open day or visit at my research institution</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>AA7E5D0B-99B8-432C-ACA3-70050017A0AC</gtr:id><gtr:impact>Research presentations given twice each year at City University Open Day events. Presentations sparked questions and discussion afterwards.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Schools</gtr:primaryAudience><gtr:year>2014,2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>So-called 'motor theories' of expression perception claim that observers simulate the facial expressions of others within their motor system, likened to a form of covert imitation, thereby improving interpretation of communicative and affective signals. However, while motor theories have proved popular with academics and the public, these accounts have lacked experimental support. 

Consistent with the predictions of motor theories, we found that asking observers to produce vowel sounds shortly before the visual presentation of expression stimuli, reduced the accuracy of judgements made about those stimuli. Specifically, the precision with which observers were able to categorise ambiguous smiles as 'sincere' or 'insincere' was reduced. Observers were also less able to judge whether sequentially presented expressions of surprise (either with a happy or fearful valence) were, or were not, identical. 

Crucially, these interference effects were not seen when observers passively listened to vowel sounds while viewing expressions, indicating that the motor production component of the concurrent task was crucial. The production of vowel sounds did not interfere with observers' judgements of facial gender, a task that is not thought to benefit from simulation, indicating that motor loads may disproportionately impair interpretation of expressions. Producing vowel sounds appears to engage the motor structures responsible for planning and producing facial expressions, thereby 'blocking' simulation. 

We sought to provide convergent evidence by examining the recognition of facial expressions and gestures in individuals with autism spectrum disorder and alexithymia - neurodevelopmental conditions thought to be associated with diminished internal simulation. 

Observers with autism were found to be insensitive to a new facial motion illusion. When typical observers view a face that simultaneously opens and closes its eyes and mouth, the presence of asynchronous mouth movements induces illusory slowing of the eye transitions, revealing predictive perceptual processing. Interestingly, however, observers with autism exhibited little or no susceptibility to this illusory feature slowing. In addition, we found that people with autism are better than typical observers at interpreting the expressions produced by members of the autism-spectrum population. It is possible that observers with autism are able to simulate these expressions more accurately than typical observers, and therefore exhibit superior interpretation. 

Alexithymia is a condition associated with impaired awareness of bodily sensations ('interoception'). Alexithymia can occur independently, but often co-occurs with other clinical conditions. Interestingly, we found that observers with eating disorders (anorexia nervosa and bulimia nervosa) who also had co-occurring alexithymia showed problems recognising facial emotions (happiness, sadness, fear, disgust, anger, surprise). In contrast, those who did not have co-occurring alexithymia showed typical recognition of facial emotion, irrespective of the presence of an eating disorder. 

Finally, in related work, we found the motor system contributes to visual perception in other ways. For example, the performance of actions and gestures seems to bias the perceived duration of similar actions performed by others. Similarly, the performance of rhythmic actions interferes with the perception of 'relative phase' - the degree to which visual changes occur in synchrony or asynchronously.</gtr:description><gtr:exploitationPathways>These results suggest that observers may simulate facial expressions and gestures in order to interpret communicative and affective signals. Diminished or atypical simulation may underlie difficulties understanding facial expressions in several clinical disorders, including autism and alexithymia. Future work should determine whether interventions that i) encourage observers to simulate, or ii) improve the accuracy of simulation, improve expression recognition where deficits are observed. 

The findings that individuals with autism and alexithymia have difficulties interpreting the facial expressions of others may prove useful in various healthcare and educational contexts. Training programmes may be designed to promote effective social interaction with these groups. For example, strategies may be developed to encourage professionals to augment facial gestures with other forms of non-verbal communication.</gtr:exploitationPathways><gtr:id>03004C1F-1FB1-4E2A-8CD5-D98AA220CD93</gtr:id><gtr:sectors><gtr:sector>Communities and Social Services/Policy,Education,Healthcare</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/BDECD14F-0285-48E4-BED1-A8A36517DB80"><gtr:id>BDECD14F-0285-48E4-BED1-A8A36517DB80</gtr:id><gtr:title>Orienting Toward Face-Like Stimuli in Early Childhood.</gtr:title><gtr:parentPublicationTitle>Child development</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ba43a8c84179a4bab97facdb50d7e8de"><gtr:id>ba43a8c84179a4bab97facdb50d7e8de</gtr:id><gtr:otherNames>Shah P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0009-3920</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/89399D3F-A378-47C3-B46C-E37233FBD783"><gtr:id>89399D3F-A378-47C3-B46C-E37233FBD783</gtr:id><gtr:title>Illusory feature slowing: evidence for perceptual models of global facial change.</gtr:title><gtr:parentPublicationTitle>Psychological science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/5a657a8acd50b386edc6cb5523249e9d"><gtr:id>5a657a8acd50b386edc6cb5523249e9d</gtr:id><gtr:otherNames>Cook R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0956-7976</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/568A81C8-F020-495C-9A5A-BA5FBD6AE5EF"><gtr:id>568A81C8-F020-495C-9A5A-BA5FBD6AE5EF</gtr:id><gtr:title>Beyond action-specific simulation: domain-general motor contributions to perception.</gtr:title><gtr:parentPublicationTitle>Trends in cognitive sciences</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/b14083da5ec0a4fb1444368c27246db7"><gtr:id>b14083da5ec0a4fb1444368c27246db7</gtr:id><gtr:otherNames>Press C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1364-6613</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/1386177D-D8BA-489B-B0E0-E19452FB9ACB"><gtr:id>1386177D-D8BA-489B-B0E0-E19452FB9ACB</gtr:id><gtr:title>Moving time: the influence of action on duration perception.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. General</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/b14083da5ec0a4fb1444368c27246db7"><gtr:id>b14083da5ec0a4fb1444368c27246db7</gtr:id><gtr:otherNames>Press C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0022-1015</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/83B7A9CE-4DC1-41AF-BFB8-C0D49E91C46D"><gtr:id>83B7A9CE-4DC1-41AF-BFB8-C0D49E91C46D</gtr:id><gtr:title>Face processing in autism: Reduced integration of cross-feature dynamics.</gtr:title><gtr:parentPublicationTitle>Cortex; a journal devoted to the study of the nervous system and behavior</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ba43a8c84179a4bab97facdb50d7e8de"><gtr:id>ba43a8c84179a4bab97facdb50d7e8de</gtr:id><gtr:otherNames>Shah P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0010-9452</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/C90EF2F9-BC8D-42F8-92A8-CDC352CDC267"><gtr:id>C90EF2F9-BC8D-42F8-92A8-CDC352CDC267</gtr:id><gtr:title>Exemplar variance supports robust learning of facial identity.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/dfd786f55172b9bb9f31fc5f0625c34e"><gtr:id>dfd786f55172b9bb9f31fc5f0625c34e</gtr:id><gtr:otherNames>Murphy J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/60CC5166-7E11-4CBD-9975-A717A7E2620F"><gtr:id>60CC5166-7E11-4CBD-9975-A717A7E2620F</gtr:id><gtr:title>Atypical trait inferences from facial cues in alexithymia.</gtr:title><gtr:parentPublicationTitle>Emotion (Washington, D.C.)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ecd61bfe670c1ca93ebff97f8bf729ba"><gtr:id>ecd61bfe670c1ca93ebff97f8bf729ba</gtr:id><gtr:otherNames>Brewer R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1528-3542</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/D482A055-8B73-4FCF-95A1-803EF37092C2"><gtr:id>D482A055-8B73-4FCF-95A1-803EF37092C2</gtr:id><gtr:title>Emotion recognition deficits in eating disorders are explained by co-occurring alexithymia.</gtr:title><gtr:parentPublicationTitle>Royal Society open science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ecd61bfe670c1ca93ebff97f8bf729ba"><gtr:id>ecd61bfe670c1ca93ebff97f8bf729ba</gtr:id><gtr:otherNames>Brewer R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>2054-5703</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/74567EE9-E7C7-4EAD-A25F-126DD98418CF"><gtr:id>74567EE9-E7C7-4EAD-A25F-126DD98418CF</gtr:id><gtr:title>Can Neurotypical Individuals Read Autistic Facial Expressions? Atypical Production of Emotional Facial Expressions in Autism Spectrum Disorders.</gtr:title><gtr:parentPublicationTitle>Autism research : official journal of the International Society for Autism Research</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ecd61bfe670c1ca93ebff97f8bf729ba"><gtr:id>ecd61bfe670c1ca93ebff97f8bf729ba</gtr:id><gtr:otherNames>Brewer R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1939-3806</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/FB66EDCE-BF3A-44E4-A9E6-BCC2B3AC6938"><gtr:id>FB66EDCE-BF3A-44E4-A9E6-BCC2B3AC6938</gtr:id><gtr:title>Motor contributions to the perception of relative phase.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/5a657a8acd50b386edc6cb5523249e9d"><gtr:id>5a657a8acd50b386edc6cb5523249e9d</gtr:id><gtr:otherNames>Cook R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/FBB80949-6709-4AEC-AF2C-09485A1AADBE"><gtr:id>FBB80949-6709-4AEC-AF2C-09485A1AADBE</gtr:id><gtr:title>Moving time: the influence of action on duration perception.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. General</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/b14083da5ec0a4fb1444368c27246db7"><gtr:id>b14083da5ec0a4fb1444368c27246db7</gtr:id><gtr:otherNames>Press C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0022-1015</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/04D3BBE0-AD61-49BB-9CB5-3337AD25E75C"><gtr:id>04D3BBE0-AD61-49BB-9CB5-3337AD25E75C</gtr:id><gtr:title>The impact of autism spectrum disorder and alexithymia on judgments of moral acceptability.</gtr:title><gtr:parentPublicationTitle>Journal of abnormal psychology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ecd61bfe670c1ca93ebff97f8bf729ba"><gtr:id>ecd61bfe670c1ca93ebff97f8bf729ba</gtr:id><gtr:otherNames>Brewer R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0021-843X</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/022008AA-429C-4117-BB51-EC1200C074CA"><gtr:id>022008AA-429C-4117-BB51-EC1200C074CA</gtr:id><gtr:title>Alexithymia: a general deficit of interoception.</gtr:title><gtr:parentPublicationTitle>Royal Society open science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ecd61bfe670c1ca93ebff97f8bf729ba"><gtr:id>ecd61bfe670c1ca93ebff97f8bf729ba</gtr:id><gtr:otherNames>Brewer R</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>2054-5703</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/304806F8-A5C0-411E-9A85-1D724FD0C300"><gtr:id>304806F8-A5C0-411E-9A85-1D724FD0C300</gtr:id><gtr:title>Inducing a concurrent motor load reduces categorization precision for facial expressions.</gtr:title><gtr:parentPublicationTitle>Journal of experimental psychology. Human perception and performance</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/547a2b0a13d66150e1e7ac2acbf45f2d"><gtr:id>547a2b0a13d66150e1e7ac2acbf45f2d</gtr:id><gtr:otherNames>Ipser A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>0096-1523</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">ES/K008226/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>E457FFDE-A4C1-4907-AE12-A394D95A3AE5</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Cognitive Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E1AC33C6-9927-41AC-B23B-2EED8F593588</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Experimental Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>56C9394E-9F52-4433-9619-6A14493473A8</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Social Psychology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>