<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/215C8CB9-38B2-495F-89F4-21D4414B80C6"><gtr:id>215C8CB9-38B2-495F-89F4-21D4414B80C6</gtr:id><gtr:name>University of California, Berkeley</gtr:name><gtr:address><gtr:line1>University of California, Berkeley</gtr:line1><gtr:line2>191 University Hall</gtr:line2><gtr:postCode>CA 94720</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/092E63B3-B179-4B94-956F-1896588D7FF4"><gtr:id>092E63B3-B179-4B94-956F-1896588D7FF4</gtr:id><gtr:name>SRI International (inc)</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/318B5D98-4CB4-4B10-A876-08FC93071A56"><gtr:id>318B5D98-4CB4-4B10-A876-08FC93071A56</gtr:id><gtr:name>King's College London</gtr:name><gtr:department>Engineering</gtr:department><gtr:address><gtr:line1>Capital House</gtr:line1><gtr:line2>2nd Floor, Guys Campus</gtr:line2><gtr:line3>42 Weston Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE1 3QD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/318B5D98-4CB4-4B10-A876-08FC93071A56"><gtr:id>318B5D98-4CB4-4B10-A876-08FC93071A56</gtr:id><gtr:name>King's College London</gtr:name><gtr:address><gtr:line1>Capital House</gtr:line1><gtr:line2>2nd Floor, Guys Campus</gtr:line2><gtr:line3>42 Weston Street</gtr:line3><gtr:line4>London</gtr:line4><gtr:postCode>SE1 3QD</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/215C8CB9-38B2-495F-89F4-21D4414B80C6"><gtr:id>215C8CB9-38B2-495F-89F4-21D4414B80C6</gtr:id><gtr:name>University of California, Berkeley</gtr:name><gtr:address><gtr:line1>University of California, Berkeley</gtr:line1><gtr:line2>191 University Hall</gtr:line2><gtr:postCode>CA 94720</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/092E63B3-B179-4B94-956F-1896588D7FF4"><gtr:id>092E63B3-B179-4B94-956F-1896588D7FF4</gtr:id><gtr:name>SRI International (inc)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/2973B318-9A93-4F7C-B2D6-D31AD7AEC566"><gtr:id>2973B318-9A93-4F7C-B2D6-D31AD7AEC566</gtr:id><gtr:firstName>Peter</gtr:firstName><gtr:surname>Sollich</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/00500CF2-BC27-44BF-B441-5E5A6308F5D6"><gtr:id>00500CF2-BC27-44BF-B441-5E5A6308F5D6</gtr:id><gtr:firstName>Zoran</gtr:firstName><gtr:surname>Cvetkovic</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FD053005%2F1"><gtr:id>C7E030EC-A33B-4674-B637-4F999EB32CA2</gtr:id><gtr:title>Robust Syllable Recognition in the Acousic-Waveform Domain</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/D053005/1</gtr:grantReference><gtr:abstractText>This proposal is concerned with robust classification/recognition of speech units (phonemes and consonant-vowel syllables) in the domain of acoustic waveforms. The motivation for this research comes from the idea that speech units should be much better separated in the high-dimensional spaces formed by acoustic waveforms than in the smaller representation spaces which are used in state-of-the-art speech recognition systems and which involve significant compression and dimension reduction. Hence, recognition/classification in the acoustic waveform domain should exhibit a higher level of robustness to additive noise than classification in low-dimensional feature spaces.In the first phase of the project we will investigate classification of speech units in the acoustic waveform domain under severe noise conditions, around 0dB signal-to-noise ratio and below, while in the second phase we will study techniques which would make classification robust also to linear filtering. The particular tasks that will be tackled in the first phase can be summarized as follows:1. Study the detailed structure of the sets of acoustic waveforms of individual speech units; in particular their intrinsic dimensions, and the existence of possible nonlinear surfaces on which the data are concentrated.2. Guided by the findings from item 1 above, estimate statistical models of the distribution of speech units in the acoustic waveform domain. We will then design and systematically assess so-called generative classifiers, whose defining property is that they are based on such statistical models.3. Investigate classification of speech units in the acoustic waveform domain using discriminative classification techniques (artificial neural networks, support vector machines, and relevance vector machines). These can be a useful alternative to generative techniques because they focus directly on the classification problem without building explicit models of waveform distributions for each speech unit.4. Construct classifiers by grouping speech units hierarchically. Top-level classifiers will be constructed to distinguish between a small of groups of similar speech units, followed by classifiers separating groups into subgroups and so on. Different methods for defining subgroups will be explored, including confusion matrices of the classifiers from item 3, appropriate distance measures between the statistical models obtained in item 2, and possibly perceptual experiments.A potential argument against our approach is that classification in the acoustic waveform domain will break down in the presence of linear filtering. However, this can be avoided by considering narrow-band signals: for these, the effect of linear filtering is approximately equivalent to amplitude scaling and time delay. In the second phase of the project, we will therefore consider speech classification using narrow-band components of acoustic waveforms. For classification of signals in individual sub-bands, the techniques investigated in the first phase of the project will be considered. A new issue is then how to combine the results of sub-band classifiers to minimize the overall classification error. Here recently developed machine learning techniques will be used, as specified in the case for support.As explained, individual sub-band classifiers should be robust to linear filtering because the latter does not significantly alter the shape of narrow-band signals. On the other hand, the dimension of the spaces of sub-band waveforms will be still high enough to facilitate classification robust to additive noise. Hence, the overall scheme is expected to be robust to both additive noise and linear fitering.</gtr:abstractText><gtr:fund><gtr:end>2010-03-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2006-10-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>207533</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>University of California</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:department>University of California, Berkeley</gtr:department><gtr:description>UC Berkeley</gtr:description><gtr:id>2189405E-3A09-43DF-8034-F817ED1AA06D</gtr:id><gtr:impact>Two conference papers, and one journal paper.
A grant proposal on robust speech recognition is formulated jointly, in which UC Berkeley appears as a formal partner.
It is a collaborative project at the interface between signal processing, statistics, and machine learning, addressing a problem in speech technologies.</gtr:impact><gtr:partnerContribution>Collaboration on several joint publications, and on formulating a grant proposal to continue collaboration on robust speech recognition.
They also co-sponsored a visit of Prof. Cvetkovic in 2012, and were hosting him for 7 months in 2013.</gtr:partnerContribution><gtr:piContribution>Collaboration on several joint publications, and on formulating a grant proposal to continue collaboration on robust speech recognition.</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2007-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>SRI International (inc)</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:description>SRI</gtr:description><gtr:id>4AD7E509-428F-4B73-8207-86BA1BDDD002</gtr:id><gtr:impact>We formulated a grant proposal, submitted to EPSRC, with SRI as a formal partner.
It is a multidisciplinary project involving signal processing, statistics, and machine learning, applied to a problem in speech technologies.</gtr:impact><gtr:partnerContribution>Exchange of ideas and technical discussions.
They were co-sponsoring one visit of Prof Cvetkovic in 2012,
and they were hosting him for 4 months (full or part time) at the lab in 2014.</gtr:partnerContribution><gtr:piContribution>Exchange of ideas and technical discussions.</gtr:piContribution><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2012-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>21059</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Travel grant</gtr:description><gtr:end>2014-03-02</gtr:end><gtr:fundingOrg>EPSRC and CRUK</gtr:fundingOrg><gtr:fundingRef>EP/K034626/1</gtr:fundingRef><gtr:id>25EF9E97-AD83-47D5-8FF8-B15E4354D1C8</gtr:id><gtr:sector>Private</gtr:sector><gtr:start>2013-03-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>The project was a proof-of-concept study, exploring a paradigm shift concept in automatic speech recognition. As such, findings of the project are still of fundamental scientific nature, but have gained us partnership with researchers from the University of California, Berkeley, and SRI (Stanford Research Institute) International for further exploration of the developed concepts to the point where they could be successfully deployed in practical automatic speech recognition systems.</gtr:description><gtr:id>3DDDC849-34F0-45F5-81AE-F76304DA64E3</gtr:id><gtr:impactTypes/></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>The project has demonstrated a significant potential of solving the long standing issue of the lack of robustness of automatic speech recognition (ASR) systems by posing the problem in high-dimensional spaces of acoustic waveforms of speech, possibly transformed by some linear orthogonal transforms. Further, for that purpose generative and discriminative (support vector machine) models are developed on this project.</gtr:description><gtr:exploitationPathways>The findings of this research are relevant for products and systems in defence, healthcare, and various other telecommunications and information systems, where speech is or can be used as mode of

human-computer interaction. Findings of the project open up a new direction in the area of ASR as well as issues of learning in high dimensions and kernel methods, which are area of intense activity is several academic communities, including statistics, computer science, signal processing</gtr:exploitationPathways><gtr:id>C4891378-DF50-478C-9E8E-94628BD58F74</gtr:id><gtr:sectors><gtr:sector>Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software),Electronics,Healthcare,Leisure Activities, including Sports, Recreation and Tourism,Security and Diplomacy</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/A2ECD5A1-C7FA-4A42-A23F-032632D1A6FD"><gtr:id>A2ECD5A1-C7FA-4A42-A23F-032632D1A6FD</gtr:id><gtr:title>Towards robust phoneme classification: Augmentation of PLP models with acoustic waveforms</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/fb1d9aa02c453b71fb39a6686d434eb3"><gtr:id>fb1d9aa02c453b71fb39a6686d434eb3</gtr:id><gtr:otherNames>Ager M.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date><gtr:issn>22195491</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/E5E7BB90-D745-4065-A9E5-525B93D9DA58"><gtr:id>E5E7BB90-D745-4065-A9E5-525B93D9DA58</gtr:id><gtr:title>Costume designed SVM kernels for improved robustness of phoneme classification</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference, EUSIPCO 2009</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/1566bf79b822ce0d3dc6bec59123515a"><gtr:id>1566bf79b822ce0d3dc6bec59123515a</gtr:id><gtr:otherNames> Jibran Yousafzai (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/A5784EF9-958C-49AA-BE3F-003B697E7006"><gtr:id>A5784EF9-958C-49AA-BE3F-003B697E7006</gtr:id><gtr:title>Tuning support vector machines for robust phoneme classification with acoustic waveforms</gtr:title><gtr:parentPublicationTitle>Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/93ab8edbd9eba4934cc511938b54878e"><gtr:id>93ab8edbd9eba4934cc511938b54878e</gtr:id><gtr:otherNames>Yousafzai J.</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date><gtr:issn>19909772</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/68FD08FE-C9E0-48D3-BEDF-25AE19202C95"><gtr:id>68FD08FE-C9E0-48D3-BEDF-25AE19202C95</gtr:id><gtr:title>Discriminative and generative machine learning approaches towards robust phoneme classification</gtr:title><gtr:parentPublicationTitle>Information Theory and Applications Workshop, ITA 2008</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/0fd8581354266287eb22ff1317e7f48b"><gtr:id>0fd8581354266287eb22ff1317e7f48b</gtr:id><gtr:otherNames>Yousafzai Jibran</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/CDF5EE56-8E26-4434-BB8C-09DE422CED5A"><gtr:id>CDF5EE56-8E26-4434-BB8C-09DE422CED5A</gtr:id><gtr:title>High-dimensional linear representations for robust speech recognition</gtr:title><gtr:parentPublicationTitle>Information Theory and Applications Workshop, ITA 2010</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/a9ce88c35c7c574c7e021b62b5f6991a"><gtr:id>a9ce88c35c7c574c7e021b62b5f6991a</gtr:id><gtr:otherNames>Ager, M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/818637A2-D7C8-4B49-B22A-B20F634F7078"><gtr:id>818637A2-D7C8-4B49-B22A-B20F634F7078</gtr:id><gtr:title>Effects of domain-specific SVM kernel design on the robustness of automatic speech recognition</gtr:title><gtr:parentPublicationTitle>18th International Conference of Digital Signal Processing, DSP 2013</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c02139e80bf918b6a86418ae01cf1705"><gtr:id>c02139e80bf918b6a86418ae01cf1705</gtr:id><gtr:otherNames>Yousafzai, J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/ACFEF4C9-429D-4E13-ADAD-AB6B065E1E48"><gtr:id>ACFEF4C9-429D-4E13-ADAD-AB6B065E1E48</gtr:id><gtr:title>Combined Features and Kernel Design for Noise Robust Phoneme Classification Using Support Vector Machines</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d06e2e559f4bfd18d45476d323dc7bfb"><gtr:id>d06e2e559f4bfd18d45476d323dc7bfb</gtr:id><gtr:otherNames>Yousafzai J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/7B81494E-00DF-44B2-8D4E-C0EF94D75CF7"><gtr:id>7B81494E-00DF-44B2-8D4E-C0EF94D75CF7</gtr:id><gtr:title>Combined Features and Kernel Design for Noise Robust Phoneme Classification Using Support Vector Machines</gtr:title><gtr:parentPublicationTitle>IEEE Transactions on Audio, Speech, and Language Processing</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d06e2e559f4bfd18d45476d323dc7bfb"><gtr:id>d06e2e559f4bfd18d45476d323dc7bfb</gtr:id><gtr:otherNames>Yousafzai J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/0B15472D-312E-4BAF-8393-B344ED6A9E7A"><gtr:id>0B15472D-312E-4BAF-8393-B344ED6A9E7A</gtr:id><gtr:title>Combined PLP - acoustic waveform classification for robust phoneme recognition using support vector machines</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference, EUSIPCO 2008</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/541ee8ac3bfeffa008bc0bfba42e413e"><gtr:id>541ee8ac3bfeffa008bc0bfba42e413e</gtr:id><gtr:otherNames> J Yousafzai</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2008-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/94DE7CB8-3A22-4627-9447-05AD6D23EA7A"><gtr:id>94DE7CB8-3A22-4627-9447-05AD6D23EA7A</gtr:id><gtr:title>Redundancy in speech signals and robustness of automatic speech recognition</gtr:title><gtr:parentPublicationTitle>XIII International Symposium on Problems of Redundancy in Information and Control Systems</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/0fd8581354266287eb22ff1317e7f48b"><gtr:id>0fd8581354266287eb22ff1317e7f48b</gtr:id><gtr:otherNames>Yousafzai Jibran</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/750F6C1A-F31D-45F5-955D-784FCB554B69"><gtr:id>750F6C1A-F31D-45F5-955D-784FCB554B69</gtr:id><gtr:title>Towards robust phoneme classification with hybrid features</gtr:title><gtr:parentPublicationTitle>IEEE International Symposium on Information Theory, ISIT 2010</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/52f36972dcaec9280c1cd4f41d90360a"><gtr:id>52f36972dcaec9280c1cd4f41d90360a</gtr:id><gtr:otherNames> Yousafzai, J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/F2CDD9D6-7F08-4205-984D-264CA8F9ABE9"><gtr:id>F2CDD9D6-7F08-4205-984D-264CA8F9ABE9</gtr:id><gtr:title>Robust phoneme classification: exploiting the adaptability of acoustic waveform models</gtr:title><gtr:parentPublicationTitle>European Signal Processing Conference, EUSIPCO 2009</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/0aef673b22f711d88572821c81664e3e"><gtr:id>0aef673b22f711d88572821c81664e3e</gtr:id><gtr:otherNames> Matthew Ager (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2009-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/9BAE52BB-625E-41D0-8691-3BFC25B8872B"><gtr:id>9BAE52BB-625E-41D0-8691-3BFC25B8872B</gtr:id><gtr:title>Combined waveform-cepstral representation for robust speech recognition</gtr:title><gtr:parentPublicationTitle>International Symposium on Information Theory, ISIT 2011</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/a9ce88c35c7c574c7e021b62b5f6991a"><gtr:id>a9ce88c35c7c574c7e021b62b5f6991a</gtr:id><gtr:otherNames>Ager, M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2011-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/5C23DAE7-82C9-467F-B718-F16ADC3557D6"><gtr:id>5C23DAE7-82C9-467F-B718-F16ADC3557D6</gtr:id><gtr:title>Subband acoustic waveform front-end for robust speech recognition using support vector machines</gtr:title><gtr:parentPublicationTitle>IEEE Workshop on Spoken Language Technology, SLT 2010</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/1566bf79b822ce0d3dc6bec59123515a"><gtr:id>1566bf79b822ce0d3dc6bec59123515a</gtr:id><gtr:otherNames> Jibran Yousafzai (Author)</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2010-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/D053005/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>699D8438-2A43-4BCF-B1A4-6240ED82CEEE</gtr:id><gtr:percentage>75</gtr:percentage><gtr:text>Human Communication in ICT</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>089C8106-E4C8-4473-A5AB-F932AF4EC07C</gtr:id><gtr:percentage>25</gtr:percentage><gtr:text>Music &amp; Acoustic Technology</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>