<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address></gtr:collaborator><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/9B520E8D-05F2-4A18-9EDF-C1503366E9E1"><gtr:id>9B520E8D-05F2-4A18-9EDF-C1503366E9E1</gtr:id><gtr:name>Eli Lilly &amp; Company Ltd</gtr:name></gtr:collaborator><gtr:collaborator url="http://gtr.rcuk.ac.uk:80/organisation/1D747F83-0211-40DF-84E7-DB44C10B03F1"><gtr:id>1D747F83-0211-40DF-84E7-DB44C10B03F1</gtr:id><gtr:name>Fred Hutchinson Cancer Research Center (FHCRC)</gtr:name></gtr:collaborator></gtr:collaborations><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Institute of Neurology</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/9B520E8D-05F2-4A18-9EDF-C1503366E9E1"><gtr:id>9B520E8D-05F2-4A18-9EDF-C1503366E9E1</gtr:id><gtr:name>Eli Lilly &amp; Company Ltd</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/1D747F83-0211-40DF-84E7-DB44C10B03F1"><gtr:id>1D747F83-0211-40DF-84E7-DB44C10B03F1</gtr:id><gtr:name>Fred Hutchinson Cancer Research Center (FHCRC)</gtr:name><gtr:roles><gtr:role><gtr:name>COLLABORATOR</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/468F2797-5295-4912-BDED-8F3402CE246A"><gtr:id>468F2797-5295-4912-BDED-8F3402CE246A</gtr:id><gtr:name>New York University</gtr:name><gtr:address><gtr:line1>7 East 12th Street</gtr:line1><gtr:region>Outside UK</gtr:region><gtr:country>United States</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/E70B04FB-85AE-423A-829D-77139B3492A5"><gtr:id>E70B04FB-85AE-423A-829D-77139B3492A5</gtr:id><gtr:name>Axona Ltd</gtr:name><gtr:address><gtr:line1>Unit 4U, Long Spring</gtr:line1><gtr:line2>Porters Wood</gtr:line2><gtr:postCode>AL3 6EN</gtr:postCode><gtr:region>Unknown</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/C35047FC-EF08-4E59-AE21-BC7EE757A0C1"><gtr:id>C35047FC-EF08-4E59-AE21-BC7EE757A0C1</gtr:id><gtr:firstName>Kenneth</gtr:firstName><gtr:otherNames>Daniel</gtr:otherNames><gtr:surname>Harris</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FK015141%2F1"><gtr:id>3CC8BDE9-41C2-4881-8B25-117E6B5C91DD</gtr:id><gtr:title>iPROBE: in-vivo Platform for the Real-time Observation of Brain Extracellular activity</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/K015141/1</gtr:grantReference><gtr:abstractText>Understanding how the trillions of action potentials of the brain's billions of neurons produce our thoughts, perceptions, and actions is one of the greatest challenges of 21st century science. Similarly, understanding how this activity is disrupted by neurological and psychiatric diseases is one of the greatest challenges of 21st century medicine. Due to the massively parallel nature of the brain's computations, answering these questions experimentally relies on being able to monitor very large numbers of neurons simultaneously. Advances in electrode microfabrication and high-throughput data analysis have allowed scientists to record from hundreds of neurons in a small local area of brain. However, as both healthy and unhealthy neural operation arises from interaction of multiple, widely-distributed brain circuits, its understanding requires a technological step-change that allows monitoring of much larger numbers of neurons over many brain areas. The research of this proposal will for the first time make this possible. This will not only provide a previously unimaginable opportunity for understanding how the healthy brain functions, but also allow us and others to develop empirically-based treatments for diseases such as Parkinson's, epilepsy, schizophrenia, and Alzheimer's. 

Large-scale neuronal recording relies on the use of microfabricated multielectrode arrays (MEAs). Arrays capable of recording from hundreds of local neurons are now commercially available. In principle, these arrays provide the ability to record from thousands of neurons across multiple brain structures, simply by using a large number of probes simultaneously. However, accessing the data produced by these electrodes cannot be achieved with current technologies, as it is simply impossible to pass a sufficient number of very low amplitude analogue signals, as in current passive connection systems. We will solve this problem by using an approach common in computing: a daisy-chain digital serial interface. By allowing simple, robust, and low-noise connection of several multi-electrode arrays, this will allow us to monitor thousands of neurons from multiple structures using a single interface. The system will exploit cheap, commercially available microelectrode arrays (eg. NeuroNexus), connected to a custom CMOS Integrated Circuit (IC) via high-density flexible ribbon cables. CMOS ICs are low cost, produce high yield and area efficient active electronics suitable for amplifying, filtering, analog-to-digital conversion and encoding of each electrode array's spiking neuron data. Each daisy chain (i.e. group of serially-connected probes) will terminate into a standard USB interface. The new USB-3.0 protocol (marketed using the SuperSpeed term) can allow for serial data speeds of 5Gbps. For data sampled at 25kS/sec at 12-bit resolution, this could provide a bandwidth capable of supporting over 10,000 electrodes: two orders of magnitude beyond current technology.

The recording systems we develop will produce vast quantities of data. A second, and essential, part of the platform is thus to develop the algorithms and software that are essential for the timely conversion of this information to concise conclusions about brain function. We will do this by leveraging our previous work, now the de facto worldwide standard for processing of multi-neuron recordings.

Our aim is to produce a system that is widely adopted by the UK and worldwide neuroscientific communities, thereby maximizing its impact on the understanding and treatment of a very wide range of disorders. To ensure that the system meets the need of both basic and clinical brain research, our team includes the world's leading expert on neuronal population recording, as well as the UK's leading manufacturer of neural recording systems. We thus have the expertise needed not only to develop the system, but also enable its rapid commercialization and distribution to scientists worldwide.</gtr:abstractText><gtr:potentialImpactText>This project will create a new interdisciplinary partnership bridging two of the UK's key academic and commercial strengths: microelectronic design and the biomedical sciences. The technology developed in this project will produce a step-change in the study of neuronal circuit function, exceeding previous recording capability by an order of magnitude. We have strong links with the national and international neuroscience community and will actively support the use of this technology to establish the UK as the world's leading location for the study of neural circuit function. As neural interfaces move from the research lab to the clinic, an expertise base in this critical skill will be of vital importance to the UK's future competitive position in medical technologies.

Understanding how the brain's circuits process information is essential to developing rational treatments for neurological and psychiatric disorders such as Alzheimer's, Parkinson's, schizophrenia, epilepsy, depression, and autism. The technologies we will develop in this project will allow us and others to study the large-scale coordination of activity in both the healthy brain, and in animal models of these devastating diseases, allowing the rational development and testing of both drug and device-based treatments for them. The system we design here is aimed in the first instance at animal models. However, similar designs can be used for interfacing to the human brain. Neural devices now constitute a $2 billion/year industry that is predicted to grow twice as fast as the cardiac implant market. EPSRC has recognised the importance of this area in its initiative 'Developing a Common Vision for UK Research in Microelectronic Design' which describes the interface of electronics to biology and in particular the brain as a Grand Challenge for UK microelectronics. Although the UK has several excellent groups researching non-invasive (EEG-based) BMIs and peripheral interfaces (nerve and muscle FES), it currently lags behind in the invasive BMI field while other countries are investing heavily. For example, the Japanese Strategic Research Program for Brain Sciences (SRPBS) recently chose BMI research as one of two priority areas in its first year with a budget of &amp;pound;14 million. To compete internationally and generate viable commercial spinouts, a portfolio of technology and expertise is essential. The proposed collaboration brings together complementary strengths and IP in medical devices and neural signal analysis. Together these resources make this partnership ideally suited to the challenge of translating basic research and technology development into devices with real clinical and commercial application.

Our partnership with Axona Ltd., the UK's (and Europe's) leading manufacturer of multichannel neural recording systems, will ensure that our technologies can be rapidly commercialized, allowing their widespread application to research on a large number of neurological disorders, as well as benefiting the UK economy. The neural probe market is currently estimated to be worth US$20M, and is growing rapidly. The iPROBE signal acquisition technology is ideally placed to become a value-added component that could be integrated with any of a wide range of probe devices. The simple design of the technology allows it to be manufactured without requiring highly expense custom microfabrication equipment; in addition, iPROBE chips in quantity could be produced cheaply enough that they would fall into the highly desirable &amp;quot;consumables&amp;quot; category. This would generate an income stream and consequently employment in the UK from a guaranteed export market, since no comparable technology exists worldwide. With a solid foothold in the research market, the iPROBE technology would be ideally placed to realise the large returns which will inevitably follow as large-scale neural interfaces transition to from research to clinical use.</gtr:potentialImpactText><gtr:fund><gtr:end>2016-08-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2013-09-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>265156</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs><gtr:collaborationOutput><gtr:collaboratingOrganisation>Fred Hutchinson Cancer Research Center (FHCRC)</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:department>Howard Hughes Medical Institute (HHMI)</gtr:department><gtr:description>Neuropixels project</gtr:description><gtr:id>4978A625-E33F-4B44-B018-C982690887E1</gtr:id><gtr:impact>The first generation of probes have been fabricated.

Disciplines: microfabrication; microelectronics; computer science; neuroscience.</gtr:impact><gtr:partnerContribution>I listed the in-kind contribution as &amp;pound;2,000,000 which represents the amount of money other funders have contributed to the project. 

But in reality, their contribution is priceless. There is no other way we could have obtained these probes; no-one else in the world has access to them.</gtr:partnerContribution><gtr:piContribution>We are testing a new generation of high-count active microelectrodes that are set to revolutionize neuronal recordings. The first recordings have been made in visual cortex, with excellent results.</gtr:piContribution><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2013-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>University College London (UCL)</gtr:collaboratingOrganisation><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:description>Collaboration with Prof John O'Keefe, UCL</gtr:description><gtr:id>6FA8B4F1-A973-433E-9C2C-9A11BA4ED2B4</gtr:id><gtr:impact>The first results of these experiments are expected in a few months.</gtr:impact><gtr:partnerContribution>We have devised and tested a strategy for silencing the outputs of a small numbers of hippocampal pyramidal neurons, and supplied reagents to make this possible in the O'Keefe lab.</gtr:partnerContribution><gtr:piContribution>In collaboration with Prof. John O'Keefe and Dr. Julija Krupic (a postdoc in the O'Keefe lab), we are investigating the retroaxonal hypothesis experimentally using two-photon microscopy in the hippocampus of behaving mice</gtr:piContribution><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput><gtr:collaborationOutput><gtr:collaboratingOrganisation>Eli Lilly &amp; Company Ltd</gtr:collaboratingOrganisation><gtr:country>United States of America</gtr:country><gtr:department>Neuroscience Eli Lilly</gtr:department><gtr:description>Neuronal network disruption in Alzheimer's disease</gtr:description><gtr:id>4E4E2281-8837-4D78-B4BD-DB824B1C565C</gtr:id><gtr:impact>Computing 
Mathematics
Neuroscience</gtr:impact><gtr:partnerContribution>They record from the brains of Alzheimer's disease model mice</gtr:partnerContribution><gtr:piContribution>We analyze data recorded from the brains of Alzheimer's disease model mice</gtr:piContribution><gtr:sector>Private</gtr:sector><gtr:start>2014-01-01</gtr:start></gtr:collaborationOutput></gtr:collaborationOutputs><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Artificial Intelligence and the Brain</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>C67E17AB-216F-4AE9-8A21-06941C74ED57</gtr:id><gtr:impact>A panel discussion open to the public, on the question of how what we learn from the brain can inform building of intelligent machines</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Nature Podcost</gtr:description><gtr:form>A press release, press conference or response to a media enquiry/interview</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>D06501FB-7C2A-455C-A1E6-FCB726241110</gtr:id><gtr:impact>Raised awareness of our research to an international audience, via an interview for Nature.com's podcast, a very highly respected and widely downloaded podcast for popular science</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:year>2013</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>333333</gtr:amountPounds><gtr:country>United States of America</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Simons Collaboration on the Global Brain</gtr:description><gtr:end>2017-06-02</gtr:end><gtr:fundingOrg>Simons Foundation</gtr:fundingOrg><gtr:fundingRef>325512</gtr:fundingRef><gtr:id>09AAC8B0-A159-45A9-95F8-EE43342E82E0</gtr:id><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2014-07-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>4189482</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Functional Neuromics of the Cerebral Cortex</gtr:description><gtr:end>2020-12-02</gtr:end><gtr:fundingOrg>The Wellcome Trust Ltd</gtr:fundingOrg><gtr:fundingRef>108726/Z/15/Z</gtr:fundingRef><gtr:id>71A1FD82-8DED-432F-AD85-80DC4263D05D</gtr:id><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2016-01-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>101327</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Industrial CASE award</gtr:description><gtr:end>2018-09-02</gtr:end><gtr:fundingOrg>Medical Research Council (MRC)</gtr:fundingOrg><gtr:fundingRef>MR/L015404/1</gtr:fundingRef><gtr:id>9C11A054-C6D0-495C-B05F-951D8F97A299</gtr:id><gtr:sector>Academic/University</gtr:sector><gtr:start>2014-10-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>1300000</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Integration of Internal and External Signals in the Cortex</gtr:description><gtr:end>2017-10-02</gtr:end><gtr:fundingOrg>The Wellcome Trust Ltd</gtr:fundingOrg><gtr:fundingRef>095668/Z/11/Z</gtr:fundingRef><gtr:id>AC51168D-8A0F-43AD-AF98-3B184EC235B7</gtr:id><gtr:sector>Charity/Non Profit</gtr:sector><gtr:start>2012-10-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>Our results have enabled the generation of new systems for recording from large numbers of neurons in the brain.

The working of the brain is a matter of great importance to society; furthermore by gaining this understanding we will open new avenues to the treatment of neurological and psychiatric disorders.</gtr:description><gtr:firstYearOfImpact>2014</gtr:firstYearOfImpact><gtr:id>290720B0-5860-4DAB-B26C-357D4C18EA49</gtr:id><gtr:impactTypes/><gtr:sector>Education,Electronics,Healthcare,Pharmaceuticals and Medical Biotechnology</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Our results have enabled the generation of new systems for recording from large numbers of neurons in the brain.

The working of the brain is a matter of great importance to society; furthermore by gaining this understanding we will open new avenues to the treatment of neurological and psychiatric disorders.</gtr:description><gtr:exploitationPathways>The tools we have produced are already in use by hundreds of scientists worldwide on a daily basis.</gtr:exploitationPathways><gtr:id>10E8666E-E9E6-4713-AB0F-C074532A4CC6</gtr:id><gtr:sectors><gtr:sector>Education,Electronics,Healthcare</gtr:sector></gtr:sectors><gtr:url>http://klusta-team.github.io/</gtr:url></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs><gtr:policyInfluenceOutput><gtr:areas/><gtr:description>GE/Kavli foundation Brain Trust</gtr:description><gtr:geographicReach>Multiple continents/international</gtr:geographicReach><gtr:id>79D44003-668F-40D2-91FC-665715F4EAE8</gtr:id><gtr:impact>This committee, convened and funded by General Electric Corporation and the Kavli foundation, seeks to maximize the impact of neuroscience research on patient outcomes through provision of next-generation e-health technology, and by closely integrating brain research with clinical practice.</gtr:impact><gtr:type>Participation in advisory committee</gtr:type></gtr:policyInfluenceOutput><gtr:policyInfluenceOutput><gtr:areas/><gtr:description>Technologies for Understanding the Brain</gtr:description><gtr:geographicReach>Multiple continents/international</gtr:geographicReach><gtr:id>A5FC5F21-70C9-4D9C-B549-61618A5C3CB4</gtr:id><gtr:type>Participation in a national consultation</gtr:type></gtr:policyInfluenceOutput></gtr:policyInfluenceOutputs><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>Software for detection of action potentials in high-count neural probes</gtr:description><gtr:id>EDC018BC-BED1-4989-843E-49D92BD1F618</gtr:id><gtr:impact>Used by over 200 scientists in over 30 leading research labs worldwide</gtr:impact><gtr:openSourceLicense>true</gtr:openSourceLicense><gtr:title>SpikeDetekt</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/klusta-team/spikedetekt2</gtr:url><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>A universal file format for neurophysiology data</gtr:description><gtr:id>E865D373-5DE9-4095-866B-364F27BEDB90</gtr:id><gtr:impact>Will allow easy sharing of data between investigators in the field</gtr:impact><gtr:title>Neurodata Without Borders Format</gtr:title><gtr:type>Systems, Materials &amp; Instrumental Engineering</gtr:type><gtr:url>https://crcns.org/NWB</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>Software for graphical analysis of spike sorting data</gtr:description><gtr:id>20160A41-3BBE-436D-A39E-AAC504DE9850</gtr:id><gtr:impact>Used so far by over 200 scientists in over 30 leading research labs worldwide</gtr:impact><gtr:openSourceLicense>true</gtr:openSourceLicense><gtr:title>KlustaViewa</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/klusta-team/klustaviewa</gtr:url><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>Next-generation software for analysis of electrophysiogy with several hundred channels</gtr:description><gtr:id>16BE715F-20C6-4376-8A37-9A0C23DCD226</gtr:id><gtr:impact>First product to allow data digestion from next-generation silicon probes</gtr:impact><gtr:openSourceLicense>true</gtr:openSourceLicense><gtr:title>phy</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/kwikteam/phy</gtr:url><gtr:yearFirstProvided>2015</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>Software for automatic cluster analysis</gtr:description><gtr:id>34DF4CAF-747D-4178-8FE6-B5AC192DE06C</gtr:id><gtr:impact>Used by over 200 scientists in over 30 research labs worldwide.

Also finding increasing use outside of neuroscience, including in systems biology</gtr:impact><gtr:openSourceLicense>true</gtr:openSourceLicense><gtr:title>MaskedKlustaKwik</gtr:title><gtr:type>Software</gtr:type><gtr:url>https://github.com/klusta-team/klustakwik</gtr:url><gtr:yearFirstProvided>2013</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/0A74681F-F971-490E-8818-CE7ACEFB20B9"><gtr:id>0A74681F-F971-490E-8818-CE7ACEFB20B9</gtr:id><gtr:title>Top-down control of cortical state.</gtr:title><gtr:parentPublicationTitle>Neuron</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3ca6910e6ac4b1485e6837a0aca8e2ea"><gtr:id>3ca6910e6ac4b1485e6837a0aca8e2ea</gtr:id><gtr:otherNames>Harris KD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0896-6273</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/1FD4B16A-930F-4B37-BCD5-2F9E04F05279"><gtr:id>1FD4B16A-930F-4B37-BCD5-2F9E04F05279</gtr:id><gtr:title>Hardware-accelerated interactive data visualization for neuroscience in Python.</gtr:title><gtr:parentPublicationTitle>Frontiers in neuroinformatics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/12f9d44dcd2f68c276158c64beca72f9"><gtr:id>12f9d44dcd2f68c276158c64beca72f9</gtr:id><gtr:otherNames>Rossant C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1662-5196</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/675D3EAA-0B39-47E7-BF8C-50970E348D43"><gtr:id>675D3EAA-0B39-47E7-BF8C-50970E348D43</gtr:id><gtr:title>Cortical connectivity and sensory coding.</gtr:title><gtr:parentPublicationTitle>Nature</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3ca6910e6ac4b1485e6837a0aca8e2ea"><gtr:id>3ca6910e6ac4b1485e6837a0aca8e2ea</gtr:id><gtr:otherNames>Harris KD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>0028-0836</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/F13DFC5E-7459-4603-BD92-3F6B9A24571D"><gtr:id>F13DFC5E-7459-4603-BD92-3F6B9A24571D</gtr:id><gtr:title>Diverse coupling of neurons to populations in sensory cortex.</gtr:title><gtr:parentPublicationTitle>Nature</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/a3f44d1605b0fccd4eb8ad4c12645abd"><gtr:id>a3f44d1605b0fccd4eb8ad4c12645abd</gtr:id><gtr:otherNames>Okun M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0028-0836</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/45F101EB-6D13-4D5A-AB62-5EE3F18DE989"><gtr:id>45F101EB-6D13-4D5A-AB62-5EE3F18DE989</gtr:id><gtr:title>Sleep replay meets brain-machine interface.</gtr:title><gtr:parentPublicationTitle>Nature neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3ca6910e6ac4b1485e6837a0aca8e2ea"><gtr:id>3ca6910e6ac4b1485e6837a0aca8e2ea</gtr:id><gtr:otherNames>Harris KD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>1097-6256</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/5FAD7466-E05B-437F-8BA1-00DCEC7C9C44"><gtr:id>5FAD7466-E05B-437F-8BA1-00DCEC7C9C44</gtr:id><gtr:title>High-dimensional cluster analysis with the masked EM algorithm.</gtr:title><gtr:parentPublicationTitle>Neural computation</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c67092facd3715d636e720b49abf3966"><gtr:id>c67092facd3715d636e720b49abf3966</gtr:id><gtr:otherNames>Kadir SN</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0899-7667</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/44B168EA-8848-4F69-9179-BFB6BA6EE421"><gtr:id>44B168EA-8848-4F69-9179-BFB6BA6EE421</gtr:id><gtr:title>Stochastic transitions into silence cause noise correlations in cortical circuits.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/8408363f05e909152ae605acb197abab"><gtr:id>8408363f05e909152ae605acb197abab</gtr:id><gtr:otherNames>Mochol G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/D5BF2DD7-C3D1-4485-B0D5-10B5DE68139F"><gtr:id>D5BF2DD7-C3D1-4485-B0D5-10B5DE68139F</gtr:id><gtr:title>Packet-based communication in the cortex.</gtr:title><gtr:parentPublicationTitle>Nature reviews. Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/f3343178b082d14d7fe8ce3a9e59382c"><gtr:id>f3343178b082d14d7fe8ce3a9e59382c</gtr:id><gtr:otherNames>Luczak A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1471-003X</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/B69ED333-0984-44C6-B2E9-2E0BB0AFEF1C"><gtr:id>B69ED333-0984-44C6-B2E9-2E0BB0AFEF1C</gtr:id><gtr:title>Ongoing network state controls the length of sleep spindles via inhibitory activity.</gtr:title><gtr:parentPublicationTitle>Neuron</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/d5b10b320a35de1d13fb2842e77f376c"><gtr:id>d5b10b320a35de1d13fb2842e77f376c</gtr:id><gtr:otherNames>Barth? P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0896-6273</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/C033E998-DF4F-4036-B62A-D6F07878077D"><gtr:id>C033E998-DF4F-4036-B62A-D6F07878077D</gtr:id><gtr:title>Integration of visual motion and locomotion in mouse visual cortex.</gtr:title><gtr:parentPublicationTitle>Nature neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c4d2935bb8d48ed389d835620d5f930f"><gtr:id>c4d2935bb8d48ed389d835620d5f930f</gtr:id><gtr:otherNames>Saleem AB</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1097-6256</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/BC43E776-C5D9-4931-9F70-C5D47F6C0BAD"><gtr:id>BC43E776-C5D9-4931-9F70-C5D47F6C0BAD</gtr:id><gtr:title>Neurodata Without Borders: Creating a Common Data Format for Neurophysiology.</gtr:title><gtr:parentPublicationTitle>Neuron</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/5409dbba77ca8dc2821a910f7e8b90aa"><gtr:id>5409dbba77ca8dc2821a910f7e8b90aa</gtr:id><gtr:otherNames>Teeters JL</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0896-6273</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/A28CF862-BB63-49CE-AE37-7A08D8D06CCD"><gtr:id>A28CF862-BB63-49CE-AE37-7A08D8D06CCD</gtr:id><gtr:title>Supervised learning with decision margins in pools of spiking neurons.</gtr:title><gtr:parentPublicationTitle>Journal of computational neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/2af41ea3348822f1515cd76082960b6e"><gtr:id>2af41ea3348822f1515cd76082960b6e</gtr:id><gtr:otherNames>Le Mouel C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>0929-5313</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/0F62CE8E-9985-4747-B561-A9583600330E"><gtr:id>0F62CE8E-9985-4747-B561-A9583600330E</gtr:id><gtr:title>Vision during navigation in mouse primary visual cortex</gtr:title><gtr:parentPublicationTitle>PERCEPTION</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/8b4686cf43b91f9d763ab464922841c6"><gtr:id>8b4686cf43b91f9d763ab464922841c6</gtr:id><gtr:otherNames>Saleem A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/80865B84-FEDE-4E17-A52C-C00E5D1FE471"><gtr:id>80865B84-FEDE-4E17-A52C-C00E5D1FE471</gtr:id><gtr:title>Cortical computation in mammals and birds.</gtr:title><gtr:parentPublicationTitle>Proceedings of the National Academy of Sciences of the United States of America</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3ca6910e6ac4b1485e6837a0aca8e2ea"><gtr:id>3ca6910e6ac4b1485e6837a0aca8e2ea</gtr:id><gtr:otherNames>Harris KD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0027-8424</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/D72E734D-2236-4F85-93C1-E8A3FA7B7B0D"><gtr:id>D72E734D-2236-4F85-93C1-E8A3FA7B7B0D</gtr:id><gtr:title>The Convallis rule for unsupervised learning in cortical networks.</gtr:title><gtr:parentPublicationTitle>PLoS computational biology</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/02b309c69c695eee75db4a49ae45c6fd"><gtr:id>02b309c69c695eee75db4a49ae45c6fd</gtr:id><gtr:otherNames>Yger P</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1553-734X</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/42BE44F0-1EF2-4C07-9679-F9EAFF895CEA"><gtr:id>42BE44F0-1EF2-4C07-9679-F9EAFF895CEA</gtr:id><gtr:title>The Nature of Shared Cortical Variability.</gtr:title><gtr:parentPublicationTitle>Neuron</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/cde1cdda1666eda724dc5f93cef4e279"><gtr:id>cde1cdda1666eda724dc5f93cef4e279</gtr:id><gtr:otherNames>Lin IC</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0896-6273</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/D702BC70-E585-4B26-9542-DE136631E8A6"><gtr:id>D702BC70-E585-4B26-9542-DE136631E8A6</gtr:id><gtr:title>Hardware-accelerated interactive data visualization for neuroscience in Python.</gtr:title><gtr:parentPublicationTitle>Frontiers in neuroinformatics</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/12f9d44dcd2f68c276158c64beca72f9"><gtr:id>12f9d44dcd2f68c276158c64beca72f9</gtr:id><gtr:otherNames>Rossant C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1662-5196</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/C38B636C-ED64-4898-9856-FB651677DCB6"><gtr:id>C38B636C-ED64-4898-9856-FB651677DCB6</gtr:id><gtr:title>Sleep and the single neuron: the role of global slow oscillations in individual cell rest.</gtr:title><gtr:parentPublicationTitle>Nature reviews. Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/1b155cf60d98cb75bbdcfa75b465f4b3"><gtr:id>1b155cf60d98cb75bbdcfa75b465f4b3</gtr:id><gtr:otherNames>Vyazovskiy VV</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1471-003X</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/B61F33CA-C386-48B4-8706-05498B99BC1C"><gtr:id>B61F33CA-C386-48B4-8706-05498B99BC1C</gtr:id><gtr:title>Sleep and the single neuron: the role of global slow oscillations in individual cell rest.</gtr:title><gtr:parentPublicationTitle>Nature reviews. Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/1b155cf60d98cb75bbdcfa75b465f4b3"><gtr:id>1b155cf60d98cb75bbdcfa75b465f4b3</gtr:id><gtr:otherNames>Vyazovskiy VV</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2013-01-01</gtr:date><gtr:issn>1471-003X</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/7D569FCA-22DA-4BB5-8EC8-F6D15F0EA80C"><gtr:id>7D569FCA-22DA-4BB5-8EC8-F6D15F0EA80C</gtr:id><gtr:title>The neocortical circuit: themes and variations.</gtr:title><gtr:parentPublicationTitle>Nature neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/3ca6910e6ac4b1485e6837a0aca8e2ea"><gtr:id>3ca6910e6ac4b1485e6837a0aca8e2ea</gtr:id><gtr:otherNames>Harris KD</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1097-6256</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/FFBCD59E-AAF6-4EA3-BD80-0864EFAC0E7B"><gtr:id>FFBCD59E-AAF6-4EA3-BD80-0864EFAC0E7B</gtr:id><gtr:title>Trial-to-trial performance of visually guided navigation can be predicted by hippocampal activity</gtr:title><gtr:parentPublicationTitle>PERCEPTION</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/8b4686cf43b91f9d763ab464922841c6"><gtr:id>8b4686cf43b91f9d763ab464922841c6</gtr:id><gtr:otherNames>Saleem A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/13D510CD-D1F8-462F-A869-63F52DAD1C75"><gtr:id>13D510CD-D1F8-462F-A869-63F52DAD1C75</gtr:id><gtr:title>Cortical state determines global variability and correlations in visual cortex.</gtr:title><gtr:parentPublicationTitle>The Journal of neuroscience : the official journal of the Society for Neuroscience</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/4b5e5f7c4dbfc8b47fa0bda840370c26"><gtr:id>4b5e5f7c4dbfc8b47fa0bda840370c26</gtr:id><gtr:otherNames>Sch?lvinck ML</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0270-6474</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/92C18618-271B-48DA-9EF1-445BB4A06366"><gtr:id>92C18618-271B-48DA-9EF1-445BB4A06366</gtr:id><gtr:title>A genuine layer 4 in motor cortex with prototypical synaptic circuit connectivity.</gtr:title><gtr:parentPublicationTitle>eLife</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/5bf243652c407d752942548cbebf56db"><gtr:id>5bf243652c407d752942548cbebf56db</gtr:id><gtr:otherNames>Yamawaki N</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2014-01-01</gtr:date><gtr:issn>2050-084X</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/K015141/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>6BF947B0-8E6E-48DB-AB68-7130938F2DF2</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Instrument. sensor &amp; detectors</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>F78E4567-DD59-4364-9D1F-0A778996E941</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Instrumentation Eng. &amp; Dev.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>