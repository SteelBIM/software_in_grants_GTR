<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:department>Oxford Physics</gtr:department><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9"><gtr:id>3EAE04CA-9D62-4483-B9C4-F91AD9F4C5A9</gtr:id><gtr:name>University of Oxford</gtr:name><gtr:address><gtr:line1>University Chest</gtr:line1><gtr:line2>Wellington Square</gtr:line2><gtr:line4>Oxford</gtr:line4><gtr:postCode>OX1 2JD</gtr:postCode><gtr:region>South East</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/EA00A299-10A4-43F9-A503-ACEC833268D1"><gtr:id>EA00A299-10A4-43F9-A503-ACEC833268D1</gtr:id><gtr:firstName>Richard</gtr:firstName><gtr:otherNames>Michael</gtr:otherNames><gtr:surname>Berry</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FF041306%2F1"><gtr:id>DBFA0CD3-8716-4721-B791-DAE413384EC1</gtr:id><gtr:title>Listening to the Micro-World</gtr:title><gtr:status>Closed</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/F041306/1</gtr:grantReference><gtr:abstractText>Technologies associated with looking at the microworld are extremely mature, and include a wide variety of microscopies. By contrast little work has been done to extend our sense of hearing into the micro-world. The purpose of this grant is to develop a basic technology for listening to the micro world, in as sense a micro ear.Just like our own ears, most sound detectors respond to changes in pressure, creating small acoustic forces and corresponding displacement of a sensor. One extremely sensitive way of measuring force is to compare it against the momentum of a light beam. Tightly focused laser beams are now routinely used to form optical tweezers, which can trap micron-sized beads, overcoming both the thermal and gravitation forces. These tweezers systems are typically built around a microscope and manipulate samples suspended in a fluid medium / such that the technology is highly compatible with biological systems. Using a microscope to observe the bead position allows the measurement of piconewton forces and the corresponding displacement of a few nanometres. The subtle movements of these optically trapped beads will form the basis of our micro-ear. We plan to develop, demonstrate and test a number of different micro-ear approaches. All imaging systems based upon focusing are restricted to scales of a wavelength or so. Even in water, acoustic wavelengths are 100s mm, making the concept of focussing irrelevant to microscopic systems. However, as evident by most wind instruments or antique hearing aids, sub wavelength horns still work. In this proposal we plan to use microfabrication techniques to produce structures that channel the fluid flow from the emitting object to the sensor bead, providing a method of guiding the pressure wave, and if necessary amplifying it (e.g. in a flared channel). We will use the optically trapped beads as sensors to measure these forces (as described above). However, it is important to consider that, at the microscale, the movements of the beads due to an acoustic response may be masked by Brownian motion / and hence distinguishing the real signal from this thermal background will be a major challenge challenge.The key to overcoming the Brownian background will be the use of high-speed cameras to measure the position of many beads simultaneously. Rather than the signal being derived from one bead, it is the correlated motion of the beads that distinguishes the sensor response from the uncorrelated background. We envisage two basic configurations. In the first, simplest case, the beads will be positioned at the ends of defined flared microfluidic structures to measure molecular interactions resulting from mechanical biological systems (molecular motors). Alternatively, we will create a circular array around the test object and measure the radial breathing of the ring. In this latter configuration there is the possibility of being able to make new and exciting biological measurements in a non-contact mode, where we will determine both short and long range interactions between cells and surfaces.</gtr:abstractText><gtr:fund><gtr:end>2011-12-30</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2008-10-06</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>135227</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs><gtr:furtherFundingOutput><gtr:amountPounds>119434</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:description>Tool Research and Development Fund Grant Award from the BBSRC: Digital Holographic Microscopy</gtr:description><gtr:end>2013-11-02</gtr:end><gtr:fundingOrg>Biotechnology and Biological Sciences Research Council (BBSRC)</gtr:fundingOrg><gtr:id>912548A5-B2B0-45A2-A044-9BB1DDAE8923</gtr:id><gtr:sector>Public</gtr:sector><gtr:start>2012-07-01</gtr:start></gtr:furtherFundingOutput><gtr:furtherFundingOutput><gtr:amountPounds>46915</gtr:amountPounds><gtr:country>United Kingdom of Great Britain &amp; Northern Ireland (UK)</gtr:country><gtr:currCode>GBP</gtr:currCode><gtr:currCountryCode>United Kingdom</gtr:currCountryCode><gtr:currLang>en_GB</gtr:currLang><gtr:department>The John Fell Fund</gtr:department><gtr:description>JFF-Digital Holographic Microscopy</gtr:description><gtr:end>2014-11-02</gtr:end><gtr:fundingOrg>University of Oxford</gtr:fundingOrg><gtr:id>F1EF5B1D-23E2-48B9-BE4C-914B68488438</gtr:id><gtr:sector>Academic/University</gtr:sector><gtr:start>2013-11-01</gtr:start></gtr:furtherFundingOutput></gtr:furtherFundingOutputs><gtr:impactSummaryOutputs><gtr:impactSummaryOutput><gtr:description>We have designed and built prototype inline and off-axis digital holographic microscopes. As well as the optical design, a major component of the work has been programming the numerical reconstruction software. We generate high-resolution images at fast video rates. We want to see our digital holographic technology widely used in the microscopy community. Anyone with an interest in true 3D microscopic video imaging is a potential user, and we have already had expressions of interest. Follow-on funding has moved our system towards wider uptake by other users.</gtr:description><gtr:firstYearOfImpact>2011</gtr:firstYearOfImpact><gtr:id>B6F5B9DE-ABB8-4C38-92B3-D7C1B0CC1DDE</gtr:id><gtr:impactTypes/><gtr:sector>Education,Other</gtr:sector></gtr:impactSummaryOutput></gtr:impactSummaryOutputs><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>We have designed and built prototype inline and off-axis digital holographic microscopes. As well as the optical design, a major component of the work has been programming the numerical reconstruction software. We generate high-resolution images at fast video rates. These are used to reconstruct 3D images of microscopic samples, also at fast video rates.</gtr:description><gtr:exploitationPathways>We want to see our digital holographic technology widely used in the microscopy community. Anyone with an interest in true 3D microscopic video imaging is a potential user, and we have already had expressions of interest. Target uses include sperm tracking in livestock, diagnosis using micro-crystals in medicine, and detection and tracking bacteria in water, food and biomedical research sectors.</gtr:exploitationPathways><gtr:id>E21FF272-6628-4332-B2B7-A1482E51F264</gtr:id><gtr:sectors><gtr:sector>Agriculture, Food and Drink,Education,Environment,Healthcare,Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>Analysis package for Digital Holographic Microscopy for use on Graphics Processing Units (GPUs). Software written to: 1) pre-process raw holographic image data; 2) apply scalar diffraction theory to reconstruct 3D light fields from holographic data; 3) extract 3D position data of objects encoded in original hologram. Software makes use of the parallel processing capabilities of GPUs to increase computation time by several orders of magnitude of that afforded by conventional computer processing unit (CPU) techniques</gtr:description><gtr:id>5B4058D5-8828-4C10-8C0C-11E2D07CDEA9</gtr:id><gtr:impact>N/A</gtr:impact><gtr:title>Pym</gtr:title><gtr:type>Software</gtr:type><gtr:yearFirstProvided>2011</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>Dark field microscopy is combined with off-axis holography to produce a novel technique for 3D imaging. dark field image is created by 1) a physical mask in the centre of a conjugate Fourier plane in the optical path,or 2) a hole in a mirror in a conjugate Fourier plane. Both methods have the result of removing the direct illumination component and allowing the dark field object signal to pass to form a hologram. This technique allows for the three-dimensional localisation of a dilute suspension of gold nanoparticles and for phase and amplitude reconstructions of the light emanating from a given sample</gtr:description><gtr:id>918DE960-DE6A-41F8-875E-1EE1AD12A334</gtr:id><gtr:impact>N/A</gtr:impact><gtr:title>Dark field off-axis digital holographic microscopy through optical Fourier filtering</gtr:title><gtr:type>New/Improved Technique/Technology</gtr:type><gtr:yearFirstProvided>2011</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>A high-magnification in-line digital holographic microscope capable of 225x magnification, high speed (up to 2,000fps) video hologram capture. Able to record for minutes due to hardware data transfer optimisation. Extensible to operate in off-axis and inline imaging modalities. Inline imaging modality able to be reconfigured easily to lower magnifications (down to 45x). Samples able to be studied: motile microorganisms, especially but not limited to bacteria; a dilute suspension of any other microorganism or micro-sized object; gold nano particles to investigate fluid motion around microorganisms. Inline modality (for cell imaging) able to track particles in a 3D volume, up to 100um depth from bottom of chamber. Off-axis modality (for gold np imaging) able to track particles in 3D volume up to 15um from bottom of the sample chamber</gtr:description><gtr:id>11064AF3-8810-4CA3-B8BA-C55E67E0E65E</gtr:id><gtr:impact>N/A</gtr:impact><gtr:title>High-magnification digital holographic microscope</gtr:title><gtr:type>New/Improved Technique/Technology</gtr:type><gtr:yearFirstProvided>2011</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>Dark field microscopy is combined with off-axis holography to produce a novel technique for 3D imaging. dark field image is created by 1) a physical mask in the centre of a conjugate Fourier plane in the optical path,or 2) a hole in a mirror in a conjugate Fourier plane. Both methods have the result of removing the direct illumination component and allowing the dark field object signal to pass to form a hologram. This technique allows for the three-dimensional localisation of a dilute suspension of gold nanoparticles at high magnifications and of a suspension of motile bacteria at up to OD 0.04. Phase and amplitude reconstructions can be obtained of the light emanating from a given sample.</gtr:description><gtr:id>ABBF7CA3-B8DA-4556-9D5F-6921D963DFCA</gtr:id><gtr:impact>N/A</gtr:impact><gtr:title>Dark field off-axis digital holographic microscopy through optical Fourier filtering</gtr:title><gtr:type>New/Improved Technique/Technology</gtr:type><gtr:yearFirstProvided>2012</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput><gtr:softwareAndTechnicalProductOutput><gtr:description>Graphical User Interface (GUI) for processing and analysing hologram data. Provides a non-specialist-friendly interface to the Pym software package that pre-processes and reconstructs holographic data.</gtr:description><gtr:id>D6A5A30F-8DFC-4E55-BF31-F2365E993A44</gtr:id><gtr:impact>N/A</gtr:impact><gtr:title>Pym GUI</gtr:title><gtr:type>Software</gtr:type><gtr:yearFirstProvided>2011</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/7912D425-9A06-4B80-84BF-26C74103D21B"><gtr:id>7912D425-9A06-4B80-84BF-26C74103D21B</gtr:id><gtr:title>Digital holographic microscopy for three-dimensional studies of bacteria</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/7d675e8be646287c34efbec8b7cf2385"><gtr:id>7d675e8be646287c34efbec8b7cf2385</gtr:id><gtr:otherNames>Flewellen James Lewis</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2012-01-01</gtr:date></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/F041306/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>60</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>9CD2DA3B-F052-4076-95ED-10F46E76C382</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Optics, photonics &amp; lasers</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>99E0B904-CAB5-4511-AFB3-AA6D2B171F97</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Process engineering</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>16789F01-D35F-4BF9-B293-420DF6B7F0A3</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Bioelectronic Devices</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>9C387DA5-CD5F-43E4-AA74-82CBF4DB6617</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Bioprocess Engineering</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>96B4D986-4762-4E29-9962-0B2240D10CE2</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Image &amp; Vision Computing</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>66CE6BAB-875D-4F4D-B415-F93CA7A2C4CA</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>Optical Devices &amp; Subsystems</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>1E31C833-3A35-4F54-A499-31D0C245B5D5</gtr:id><gtr:percentage>20</gtr:percentage><gtr:text>System on Chip</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>