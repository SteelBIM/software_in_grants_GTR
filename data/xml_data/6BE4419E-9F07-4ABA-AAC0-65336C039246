<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:department>Dentistry</gtr:department><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/818CD6C9-61EE-41F2-9F37-0C7A8F43E25D"><gtr:id>818CD6C9-61EE-41F2-9F37-0C7A8F43E25D</gtr:id><gtr:name>University of Birmingham</gtr:name><gtr:address><gtr:line1>Edgbaston Park Road</gtr:line1><gtr:line2>Edgbaston</gtr:line2><gtr:postCode>B15 2TT</gtr:postCode><gtr:region>West Midlands</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/240A5976-40F1-47B8-A637-17BBCFB1D8C5"><gtr:id>240A5976-40F1-47B8-A637-17BBCFB1D8C5</gtr:id><gtr:firstName>Hisham</gtr:firstName><gtr:surname>Mehanna</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/1D8C6583-1DDB-4AA7-B4F0-209D036DF666"><gtr:id>1D8C6583-1DDB-4AA7-B4F0-209D036DF666</gtr:id><gtr:firstName>David</gtr:firstName><gtr:otherNames>Anthony</gtr:otherNames><gtr:surname>Randell</gtr:surname><gtr:roles><gtr:role><gtr:name>RESEARCHER</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/28B897D1-6445-467B-8A67-2D79F07E06D1"><gtr:id>28B897D1-6445-467B-8A67-2D79F07E06D1</gtr:id><gtr:firstName>Gabriel</gtr:firstName><gtr:surname>Landini</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/2FCC0348-AF7A-48E8-93BD-4FB12CDBFAF1"><gtr:id>2FCC0348-AF7A-48E8-93BD-4FB12CDBFAF1</gtr:id><gtr:firstName>Antony</gtr:firstName><gtr:otherNames>Peter</gtr:otherNames><gtr:surname>Galton</gtr:surname><gtr:roles><gtr:role><gtr:name>CO_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FM023869%2F1"><gtr:id>6BE4419E-9F07-4ABA-AAC0-65336C039246</gtr:id><gtr:title>Novel context-based segmentation algorithms for intelligent microscopy</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/M023869/1</gtr:grantReference><gtr:abstractText>The aim of this proposal is to develop new computer methods to analyse, quantify and understand the information contained in images of cells and tissues obtained using digital microscopy. This will have wide applications in many areas of biomedicine, especially in histopathology, where it can be used to diagnose cancer, predict the potential behaviour of malignant disease, and implement the most suitable form of treatment. 
Currently, decisions about histopathological diagnosis rely to a great extent on expert observers and their experience, but this has the disadvantage that the inevitable element of subjectivity in visual observation makes it difficult to reach quantitative or reproducible judgements.
In this project we will design 'context-based' imaging programs to help advance automated analysis and diagnosis of cancer. By 'context-based' here we understand the use of data constructs that (1) allow the structure and relations of cells and tissues in biopsy samples to be modelled in a way that enables computer programs to subsequently 'reason' about the image contents, and (2) allow methods of data extraction that are both quantitative and reproducible.
This will be achieved by using a spatial logic called Discrete Mereotopology (DM). We already have proof-of-concept software and a peer-reviewed preliminary publication which demonstrate the efficacy of this approach for encoding and querying relations between the biologically-relevant entities (e.g. cell nucleus, tissue layers, staining patterns) and the image segments detected to correspond to them, thereby enabling histologically relevant models (e.g. cells, tissue types and voids) to be formulated that can be operated on at a level that has not been possible before. This is a departure from traditional pixel-based routines, leading to region-based algorithms that are histologically relevant to the range of images and structures that are expected in histological imaging.
This logic-based approach to image analysis brings several advantages. Firstly, it provides a robust, rigorous mathematical foundation for software development. Secondly, it allows histological images to be systematically interpreted in terms of histologically-relevant entities, not just pixels. Thirdly, it enables symbolic and automated reasoning programs to be used alongside numerical methods.
We will also incorporate immunohistochemical markers to our histologically relevant models. A key innovation in the proposal is the use of DM to explicitly model the histological localisation of molecular markers, which has never been done before. This will allow a rational evaluation of immunohistochemical patterns and subsequent development of histological predictor markers associated with tumour behaviour and outcome, i.e., what patterns are observed in what kinds of neoplasm, where in tissues the markers are expressed, and how characteristic the patterns are to recorded case outcomes.
Finally we will develop markers of data quality to label structures according to how well they approach the expected models they represent. In this way indications of 'confidence in the results' can be associated to the models found in microscopy images. So far this feature is not provided by any form of histological imaging.
We believe that the approach outlined here is both translational and invaluable in most biological areas using microscopy, where quantitative results are required to make sound evidence-based decisions.</gtr:abstractText><gtr:potentialImpactText>This is a cross-disciplinary translational project where the immediate beneficiaries are cancer patients and the healthcare profession. The overall aim of this research is to address clinical needs in the performance of imaging programs for understanding biological data from microscopy images. While this proposed project specifically targets the diagnosis and prognosis of oropharyngeal carcinomas, the methods adopted are by no means restricted to this type of cancer, or even cancer in general, but will be applicable to most biological areas dealing with interpretation of microscopy images of cells and tissues. Deliverables from this project will make an impact by enabling imaging technologies to elevate the interpretation of biological data (histological imagery) to levels that so far have been difficult to establish. 

For the healthcare profession this extends to impact arising from new software tools that enable reliable data extraction and mechanical reasoning on microscopy image contents in ways that have not been possible before. These will provide the means to implement high-throughput systems to analyse more data than is currently feasible, to develop new histological diagnostic standards based on quantifiable evidence-based research, and to create better diagnostic and prognostic models of disease. 

The expectations of impact in society are high.
1) Faster and more reliable diagnosis of cancers, resulting in quicker turnaround, with fewer delays in instituting a definitive therapy or adjuvant therapy post-operatively. As outcomes have been shown to be associated with time delay to therapy, faster diagnosis and quicker treatment times are likely to result in better survival rates.
2) Studies have shown that the period of awaiting a definitive diagnosis is the time of highest stress for patients. Faster turnaround in analysing samples will help to ameliorate this.
3) Higher reliability of tests will result in fewer incorrect diagnoses, with less harm to patients and lower health, social and economic costs of implementing incorrect treatments.
4) There is a shortage of histopathologists in the UK. By enabling their work to be more efficient through automation, this will result in a decrease in the delays caused by overstretched resources, and consequently in lower costs, that would translate into efficient use of resources for the NHS. 

In terms of benefits to academia and commercial research, the work will advance context-based imaging algorithms that are sensitive to the spatial localisation of features in tissues as it will make it possible to pinpoint not only what cell and tissue patterns are detected, but also where within the samples those features of interest are localised. The research will also provide key insights to the qualitative expression of immunohistochemical markers in images to enable those markers to be related to tissue biological behaviour and therefore to the prognosis of tumours.</gtr:potentialImpactText><gtr:fund><gtr:end>2018-07-31</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2015-08-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>525906</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>Engagement with Industry: GSK Dental Discovery Day</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>B4AF2E5E-04F6-4B99-BAF0-E89130F7EDB1</gtr:id><gtr:impact>Showcase of Preclinical and Clinical Research at Birmingham School of Dentistry to GlaxoSmithKline (Regional Clinical Operations Director for EU, Innovation Snr Scientist, Media Affairs, Clinical Director for Oral Health, Category Medical Affairs Principal Scientist Oral Health, College Business Engagement Partner.Business Engagement Officer, others) . Presented our current progress on Intelligent Microscopy in relation to cancer diagnosis and applications of the techniques to other areas of biological imaging.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Industry/Business</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Seminar on Histological Imaging, Computer Science Department, Aberystwyth University.</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>03017B0B-6A4A-4E93-BDAD-C534C6CD1C05</gtr:id><gtr:impact>Seminar talk to Computer Science department.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Biosciences lecture</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Local</gtr:geographicReach><gtr:id>8A0C86B3-3079-4338-8FBB-CF36AB0AE1EB</gtr:id><gtr:impact>Lecture to Biosciences students (year 2), Birmingham University (7 Feb 2017) on epithelial tissue including architectural features, and pathologies of the oral mucosa. This included a showcase of diagnostic problems faced by histopathologists and some of the solutions we are pursuing in characterising those tissues.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Undergraduate students</gtr:primaryAudience><gtr:year>2017</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Ontological Levels in Histological Imaging. Presented by Dr G. Galton at Exeter Imaging Network.</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>7598E11A-DF57-4EA0-9324-CBE4A84E402F</gtr:id><gtr:impact>A presentation was made to about 30 people in the Exeter Imaging Network (part of GW4 partnership) on our work on ontologies in histological imaging. Interest was expressed in the work and a request for a paper recently submitted to FOIS 2016.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Landini G, Randell DA, Fouad SA. Histopathological Problems and Imaging. Invited seminar, Warwick University, Department of Computer Science.</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>2EABC33D-A322-4B67-B81F-8AC343E5C285</gtr:id><gtr:impact>Presented principles of mererotopology and intelligent microscopy applied to histological imaging and discussed common problems in the subject area.

Had the opportunity to show our approach to spatial reasoning in histological imaging problems as well as learning about the activities ongoing at Warwick University. 
Set up excellent contacts for future collaboration.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Postgraduate students</gtr:primaryAudience><gtr:year>2015</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>* We developed two automated methods for extracting cell nuclei from microscopy images, inspired by strategies observed in humans when adjusting manually sliders controls. One of the methods achieved the best performance versus a gold standard, when compared to other 23 existing thresholding methods. We also developed a novel boundary concavity-based method for separation of nuclei clusters in images to infer merged regions.

* We digitised samples of oropharyngeal carcinomas in tissue micro array format (the database is currently 8772 images including 3 staining methods). We developed methods to reduce the computational cost of analysing the images by automatically eliminating unnecessary background space. On a subset of those, hand-generated gold standards were produced for 3 types of image components and various segmentation and clustering procedures were implemented. Preliminary results indicate that the 3 types of components can be separated using unsupervised clustering methods with ~80% accuracy without human interaction, opening a possible avenue for automated sample pre-screening and data driven analysis.

* We have developed a model-based method to correct segmentation errors using relations between regions. We found that the number of operators and operations needed for certain corrections dictate the complexity of the procedure which could become computationally expensive unless other constraints (shape and size) are taken into consideration. We found links between these procedures and the ontological levels referred earlier to restrict the amount of computation necessary.

* We found that ordering a sequence of spatial configurations to meet certain transition constraints is NP-complete when using the RCC8 relation set. Consequently, a framework was proposed where the temporal aspect of that sequence is constrained by a Point Algebra network. This again showed that the task remains NP complete.

* We formulated an ontological histological imaging framework, integrating quantitative and algorithmic analyses of cells and tissue images. This enables hypothesising about biologically meaningful models from microscopy images. This process can be understood as a progression through various ontological levels, each populated by entities related in systematic ways to entities at other levels. This also provides a useful basis for classifying the various kinds of artefacts and anomalies that arise at different stages of the imaging pipeline and we are currently working on publications to present these ideas.

* Collaborative work with researchers in Brazil on Connectivity Descriptors resulted in a new generic multiscale texture image analysis method. This provided the best performance in texture classification when compared to other state of the art methods on three well established databases. We also investigated the Bouligand-Minkowski descriptors for classifying tissue architecture in three types jaw cysts (radicular cyst, solitary- and syndromic- odontogenic keratocysts). These descriptors submitted to a machine learning algorithm were able to discriminate between radicular and odontogenic keratocysts in 98% of the images, and 68% of two subtypes of keratocysts, improving over previously reported classification rates in the literature.

* Our algorithms for tissue segmentation/architectural analysis were applied to a biodiversity problem in the analysis of plant taxonomy through histology. Geometrical measures from cells and tissue layers were combined into vectors of features for species categorization. This achieved a classification success rate of 91.7% when applied to a histological database of 10 plant species from Brazil, outperforming other classical shape-based approaches in the literature.</gtr:description><gtr:exploitationPathways>We have not yet released all our software, pending on publications and continuing development, but we anticipate sharing our software tools with imaging community as the project progresses.</gtr:exploitationPathways><gtr:id>FF900FAE-7E1A-4C64-8C00-25ECBC222FAC</gtr:id><gtr:sectors><gtr:sector>Digital/Communication/Information Technologies (including Software),Education,Healthcare,Manufacturing, including Industrial Biotechology,Pharmaceuticals and Medical Biotechnology</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs><gtr:softwareAndTechnicalProductOutput><gtr:description>The procedures implemented are based on a reinterpretation of the strategy observed in human operators when adjusting thresholds manually and interactively by means of 'slider' controls.
Users most often find the &amp;quot;right&amp;quot; threshold value by repeatedly over- and under-thresholding the image until the thresholded phase more or less coincides with the sought objects in the image. The advantage of the computerised versions presented here is that the methods do not suffer from the uncertainty of &amp;quot;when to stop adjusting&amp;quot; the threshold.
Two different methods were implemented. The first one is a simple global thresholding procedure suitable for single or multiple global thresholds (i.e. one value for the whole image). The procedure consists of searching the greyscale space for a threshold value that generates a phase whose boundary coincides with the largest gradients in the original image.
The plugin is called Threshold_Global_Gradient and it has the option of using two possible measures of the phase gradient (the mean and the total gradient).

The second method is a more complex variation of the same principle, but operates on the discrete connected components of the thresholded phase (i.e. candidate binary regions that might represent the intended object in the image) independently, therefore becoming an adaptive local thresholding procedure which operates on regions, rather than on pixels of local image subsets as is the case in the vast majority of local thresholding methods in the literature.</gtr:description><gtr:id>F2D39470-492B-41E4-B78C-71D435F8D34B</gtr:id><gtr:impact>Provides an automated ways of nuclear thresholding/segmentation in sections of tissues. 
In terms of performance on our samples, the software provides better (more accurate and cleaner) results than other currently methods available to perform the same task.
For details on performance, see Landini G, Randell DA, Fouad S, Galton A. Automatic thresholding from the gradients of region boundaries. Journal of Microscopy, 2016.</gtr:impact><gtr:openSourceLicense>true</gtr:openSourceLicense><gtr:title>Automatic thresholding plugins for ImageJ</gtr:title><gtr:type>Software</gtr:type><gtr:url>http://www.mecourse.com/landinig/software/threshgrad/threshgrad.html</gtr:url><gtr:yearFirstProvided>2016</gtr:yearFirstProvided></gtr:softwareAndTechnicalProductOutput></gtr:softwareAndTechnicalProductOutputs><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/8F6A47EC-5C3C-454A-B8B4-0F31122B6B1C"><gtr:id>8F6A47EC-5C3C-454A-B8B4-0F31122B6B1C</gtr:id><gtr:title>Image Analysis and Recognition</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/9ab2d158ef948abad18a43a7e0396ea0"><gtr:id>9ab2d158ef948abad18a43a7e0396ea0</gtr:id><gtr:otherNames>Fouad S</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:isbn>978-3-319-41500-0</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/872E91B5-7714-4C10-B30C-8694F407D1CD"><gtr:id>872E91B5-7714-4C10-B30C-8694F407D1CD</gtr:id><gtr:title>Artificial Intelligence Applications and Innovations</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/6853905870f1de2ee10febf6c2eeecd6"><gtr:id>6853905870f1de2ee10febf6c2eeecd6</gtr:id><gtr:otherNames>Sioutis M</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:isbn>978-3-319-23867-8</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/3E1C6B0A-62D0-4750-ADF3-43A4F9BAE52F"><gtr:id>3E1C6B0A-62D0-4750-ADF3-43A4F9BAE52F</gtr:id><gtr:title>Automatic thresholding from the gradients of region boundaries.</gtr:title><gtr:parentPublicationTitle>Journal of microscopy</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/0ec481e59aab3b9cee318505ddfb1688"><gtr:id>0ec481e59aab3b9cee318505ddfb1688</gtr:id><gtr:otherNames>Landini G</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0022-2720</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/C609AA81-3E3D-4CD0-B62F-76E18704AFDD"><gtr:id>C609AA81-3E3D-4CD0-B62F-76E18704AFDD</gtr:id><gtr:title>Identifying plant species using architectural features in leaf microscopy images</gtr:title><gtr:parentPublicationTitle>Botany</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/689620a64df13f1b16ae31986eb327cd"><gtr:id>689620a64df13f1b16ae31986eb327cd</gtr:id><gtr:otherNames>Florindo J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/4D098CD4-AAE2-477E-B018-C5CD11DE720A"><gtr:id>4D098CD4-AAE2-477E-B018-C5CD11DE720A</gtr:id><gtr:title>Three-dimensional connectivity index for texture recognition</gtr:title><gtr:parentPublicationTitle>Pattern Recognition Letters</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/689620a64df13f1b16ae31986eb327cd"><gtr:id>689620a64df13f1b16ae31986eb327cd</gtr:id><gtr:otherNames>Florindo J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/EA8D0FFB-6C9E-4751-8FD3-F208B67A93AD"><gtr:id>EA8D0FFB-6C9E-4751-8FD3-F208B67A93AD</gtr:id><gtr:title>Ontological Levels in Histological Imaging</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/68c092110fe3f57fc878078d162a5867"><gtr:id>68c092110fe3f57fc878078d162a5867</gtr:id><gtr:otherNames>Galton, A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/B75EBA67-B92D-4FD4-8935-7443C5AB67EB"><gtr:id>B75EBA67-B92D-4FD4-8935-7443C5AB67EB</gtr:id><gtr:title>Nuclear morphometry and ploidy of normal and neoplastic haemocytes in mussels.</gtr:title><gtr:parentPublicationTitle>PloS one</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/6cdc1ccf146bcec45bc26a9a954cbcce"><gtr:id>6cdc1ccf146bcec45bc26a9a954cbcce</gtr:id><gtr:otherNames>Carella F</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>1932-6203</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/33079A3C-F4A8-48EC-8F17-4D364208945C"><gtr:id>33079A3C-F4A8-48EC-8F17-4D364208945C</gtr:id><gtr:title>Morphological classification of odontogenic keratocysts using Bouligand-Minkowski fractal descriptors.</gtr:title><gtr:parentPublicationTitle>Computers in biology and medicine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/c7492063132c4784c184fcc4c9c108ac"><gtr:id>c7492063132c4784c184fcc4c9c108ac</gtr:id><gtr:otherNames>Florindo JB</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0010-4825</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">EP/M023869/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>6723A70B-A523-40AB-9740-B6AD2A0677B7</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Medical &amp; health interface</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>16595C3C-600D-4AD2-B394-16E06F96495F</gtr:id><gtr:percentage>100</gtr:percentage><gtr:text>Med.Instrument.Device&amp; Equip.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>