<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:department>Institute of Ophthalmology</gtr:department><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/3A5E126D-C175-4730-9B7B-E6D8CF447F83"><gtr:id>3A5E126D-C175-4730-9B7B-E6D8CF447F83</gtr:id><gtr:name>University College London</gtr:name><gtr:address><gtr:line1>Gower Street</gtr:line1><gtr:line4>London</gtr:line4><gtr:postCode>WC1E 6BT</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/655934E2-68DD-46DD-82AB-EAB98B663D9C"><gtr:id>655934E2-68DD-46DD-82AB-EAB98B663D9C</gtr:id><gtr:firstName>Andrew</gtr:firstName><gtr:surname>Stockman</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=BB%2FM00211X%2F1"><gtr:id>BF959085-A564-48AB-B595-F307521F5B47</gtr:id><gtr:title>Multiple signals interact in flicker: recursive surround networks</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>BB/M00211X/1</gtr:grantReference><gtr:abstractText>Before visual stimuli arriving at the eye are consciously perceived they are transformed and encoded by multiple circuits in the intervening visual pathways. These processes subtly alter our perception of visual stimuli. Many of the processes cannot be directly observed - they are carried out by very small neurons with a very large number of even smaller connectors and it is the whole nest of these complex interconnections that determine the way the nest behaves. One way to determine some of the characteristics of these inaccessible processes is to study behaviour that depends on them. Our aim is to determine how the circuitry of the human visual system works through careful perceptual measurements of flicker perception. We rely on the fact that interactions between different circuits within the visual system alter visual signals in characteristic ways. Typically, these interactions cause flicker to be relatively less visible at some frequencies but easy to see at other frequencies. By looking for those characteristic effects in perceptual measurements, we can tease apart the different underlying visual circuits and their contributions to perception. In previous work, we discovered a surprisingly complex circuitry that uses the signals from the individual light receptors-cones-in several different and unexpected ways. In this project, we propose to monitor and model those signals under a variety of new conditions to understand more about how the eye and brain work. We confidently expect to provide a greater understanding of vision and visual processing, which will yield important benefits in other areas of vision research, and will help to bridge the widening gap between relatively simple models of the visual pathways and what we are now learning about the complex structure and function of the visual system from other disciplines.</gtr:abstractText><gtr:technicalSummary>The primary aim is to elucidate the functional circuitry of the human visual system through psychophysical experiments. Our approach is based on the prediction that different visual circuits produce signals with amplitudes and delays that vary with temporal frequency in characteristically different ways. We successfully used this approach to identify-in addition to the expected, fast positive M- and L-cone inputs-sluggish middle(M)- and long(L)-wavelength-sensitive-cone inputs of both positive and negative sign into the luminance or achromatic pathway. The measurements were made on deep-red (658-nm) adapting fields. We propose to make extensive measurements using other adapting field wavelengths to determine the influence of wavelength and intensity on the relative strengths of the various cone inputs into the human luminance channel. As before, a vector model will be used to analyse the data and identify the signs and strengths of the various inputs. Preliminary evidence shows sluggish inputs are clearly evident on adapting fields of short and middle-wavelengths. We confidently expect to produce a more realistic model of the human visual system and human visual processing, and, by characterizing the signals that are accessible by observers and evident in their behaviour, help to provide new links between behavioural and physiological experiments.</gtr:technicalSummary><gtr:potentialImpactText>The primary goal of this research project is the elucidation of fundamental properties of the human and primate visual system. Consequently, the initial beneficiaries of this research will be other scientists studying the visual system. These will include not just visual psychophysicists like the PI, but also sensory physiologists, electrophysiologists and cognitive neuroscientists working on visual processing in the human and primate visual system. The initial impact will be, we expect, the provision of a model of early visual processing that identifies the visually significant signals that should also be evident using other objective measurements. Many other scientists, who are less directly involved in vision research, including some geneticists, anatomists working on the early stages of the visual system, and brain-imaging specialists will also potentially benefit from this research. At the more applied level, this work may also benefit engineers interested in the ergonomics of man-machine interfaces. Such interfaces and displays include videos, films, mobile phones and other dynamic presentation devices.
Longer term benefits will include clinical applications of the research. Once we have defined and modelled the characteristics of visual processing in normal observers, we can make comparable measurements in patients with specific clinical visual deficits. As we have found with other similar paradigms, this can be very fruitful in way of understanding the nature of the clinical deficit. We already have several ongoing collaborations with our sister institution Moorfields Eye Hospital.
Given the wide range of interest in vision research across many disciplines it will be important that our results and models are widely disseminated. We will publish our work in open source journals and present the data at international conferences. As part of this project, we also propose to make our data available at the Colour and Vision Research Laboratory (CVRL) website run by the PI at http://www.cvrl.org This resource is well-known and widely used in colour research both by academics and in industry. We propose to develop this resource further to provide general information on vision.</gtr:potentialImpactText><gtr:fund><gtr:end>2017-11-23</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/2512EF1C-401B-4222-9869-A770D4C5FAC7"><gtr:id>2512EF1C-401B-4222-9869-A770D4C5FAC7</gtr:id><gtr:name>BBSRC</gtr:name></gtr:funder><gtr:start>2014-11-24</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>416282</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs><gtr:disseminationOutput><gtr:description>PI was chair and co-chair of the Colour Group GB</gtr:description><gtr:form>Participation in an activity, workshop or similar</gtr:form><gtr:geographicReach>National</gtr:geographicReach><gtr:id>3F98DA44-8130-40CD-A0BB-B18941B8E5B9</gtr:id><gtr:impact>The Colour Group GB organizes public meetings, school lectures and events on the broad topic of colour.

Wider interest and appreciation of the scientific and artistic aspects of colour.</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Public/other audiences</gtr:primaryAudience><gtr:url>http://www.colour.org.uk</gtr:url><gtr:year>2009,2010,2011,2012,2013</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public lecture on Human Colour Vision IOP London</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>1EA8B531-7932-43A2-A5C2-3626211470C3</gtr:id><gtr:impact>Colour Vision
Public lecture at the Institute of Physics London</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.iop.org/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public lecture on Human Colour Vision IOP Open University</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>DE061E70-DF0A-49BF-96D9-7C6A70A93D02</gtr:id><gtr:impact>Colour vision
Invited public lecture, Institute of Physics, Open University, Milton Keynes</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.iop.org/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>TEDxUAL talk on Color Vision</gtr:description><gtr:form>A broadcast e.g. TV/radio/film/podcast (other than news/press)</gtr:form><gtr:geographicReach>International</gtr:geographicReach><gtr:id>3F5ED17B-E6EC-4661-AA01-CB665ABF44A8</gtr:id><gtr:impact>TEDxUAL speaker, University of the Arts London. On-line</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Media (as a channel to the public)</gtr:primaryAudience><gtr:url>http://www.tedxual.com/</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput><gtr:disseminationOutput><gtr:description>Public lecture on Human Colour Vision IOP Canterbury</gtr:description><gtr:form>A talk or presentation</gtr:form><gtr:geographicReach>Regional</gtr:geographicReach><gtr:id>94B86BFC-2874-491D-A5AA-B07C3BFFC41D</gtr:id><gtr:impact>Public lecture on Human Colour Vision IOP Canterbury</gtr:impact><gtr:partOfOfficialScheme>false</gtr:partOfOfficialScheme><gtr:primaryAudience>Professional Practitioners</gtr:primaryAudience><gtr:url>http://www.iop.org</gtr:url><gtr:year>2016</gtr:year></gtr:disseminationOutput></gtr:disseminationOutputs><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:keyFindingsOutput><gtr:description>Psychophysical measurements reveal clear evidence for antagonistic and synergistic interactions between visual responses generated by uniform fields of flickering light. Such light generates fast or slow responses with the slower responses' being delayed by tens of milliseconds and being of either the same or the opposite sign as the faster response. 
The interactions of fast and slow responses can be clearly seen in the delays between pairs of S-, M- or L-cone flicker stimuli measured using a flicker-photometric cancellation technique, which expose ubiquitous and often sizeable delays between the various responses. The interactions can alter the shape of temporal contrast sensitivities depending on the frequencies at which the responses constructively or destructively interfere.</gtr:description><gtr:exploitationPathways>This is an ongoing grant and we are continuing this research work.</gtr:exploitationPathways><gtr:id>5A2279E1-ABEB-4DD5-8673-EAF74525A583</gtr:id><gtr:sectors><gtr:sector>Other</gtr:sector></gtr:sectors></gtr:keyFindingsOutput><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs><gtr:researchDatabaseAndModelOutput><gtr:description>This web resource provides an annotated database of downloadable standard functions and data sets relevant to colour and vision research and to colour technology, as well as providing information about the research outputs of our group. Updated frequently.</gtr:description><gtr:id>D94572E1-79CD-42CA-A2DD-C4112FE34CF4</gtr:id><gtr:impact>Widely used in science and industry, the site started at UC San Diego in 1995 and moved to UCL with the PI in 2001.</gtr:impact><gtr:providedToOthers>true</gtr:providedToOthers><gtr:title>CVRL database</gtr:title><gtr:type>Database/Collection of data</gtr:type><gtr:url>http://www.cvrl.org</gtr:url><gtr:yearFirstProvided>2006</gtr:yearFirstProvided></gtr:researchDatabaseAndModelOutput></gtr:researchDatabaseAndModelOutputs><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/C4543154-19E9-49FB-84EF-222B8A98157C"><gtr:id>C4543154-19E9-49FB-84EF-222B8A98157C</gtr:id><gtr:title>Long-term effect of gene therapy on Leber's congenital amaurosis.</gtr:title><gtr:parentPublicationTitle>The New England journal of medicine</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/302e5d4c10875c411f1549c6c495119d"><gtr:id>302e5d4c10875c411f1549c6c495119d</gtr:id><gtr:otherNames>Bainbridge JW</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>0028-4793</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/89A45A88-F0F7-4A7D-B6E9-2621CF0929A1"><gtr:id>89A45A88-F0F7-4A7D-B6E9-2621CF0929A1</gtr:id><gtr:title>Handbook of Color Psychology</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:isbn>9781107337930</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/D768D72E-E5C4-4826-B73C-193244DC1027"><gtr:id>D768D72E-E5C4-4826-B73C-193244DC1027</gtr:id><gtr:title>Spectral sensitivity measurements reveal partial success in restoring missing rod function with gene therapy.</gtr:title><gtr:parentPublicationTitle>Journal of vision</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/eac5db3178ad0308d8f39daf63bce9b0"><gtr:id>eac5db3178ad0308d8f39daf63bce9b0</gtr:id><gtr:otherNames>Ripamonti C</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:issn>1534-7362</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/3B027F59-32E7-4B57-97BD-05426B81BCC6"><gtr:id>3B027F59-32E7-4B57-97BD-05426B81BCC6</gtr:id><gtr:title>The Pattern of Retinal Ganglion Cell Loss in OPA1-Related Autosomal Dominant Optic Atrophy Inferred From Temporal, Spatial, and Chromatic Sensitivity Losses.</gtr:title><gtr:parentPublicationTitle>Investigative ophthalmology &amp; visual science</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/b59fc60f985bd8aacf9bde6a7f490cf9"><gtr:id>b59fc60f985bd8aacf9bde6a7f490cf9</gtr:id><gtr:otherNames>Majander A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2017-01-01</gtr:date><gtr:issn>0146-0404</gtr:issn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/664FA7CB-77AE-47F3-8505-D875CE3B8655"><gtr:id>664FA7CB-77AE-47F3-8505-D875CE3B8655</gtr:id><gtr:title>Encyclopedia of Color Science and Technology</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:isbn>978-1-4419-8071-7</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/6F98593E-8CE7-45F6-BEFA-B263CA30B7F6"><gtr:id>6F98593E-8CE7-45F6-BEFA-B263CA30B7F6</gtr:id><gtr:title>Encyclopedia of Color Science and Technology</gtr:title><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/ade2a965521f256e08450689ee63883b"><gtr:id>ade2a965521f256e08450689ee63883b</gtr:id><gtr:otherNames>Stockman A</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2015-01-01</gtr:date><gtr:isbn>978-1-4419-8071-7</gtr:isbn></gtr:publication><gtr:publication url="http://gtr.rcuk.ac.uk:80/publication/3C598584-F80D-49AB-A2E0-B14C9B0183CB"><gtr:id>3C598584-F80D-49AB-A2E0-B14C9B0183CB</gtr:id><gtr:title>Psychophysical measures of visual function and everyday perceptual experience in a case of congenital stationary night blindness.</gtr:title><gtr:parentPublicationTitle>Clinical ophthalmology (Auckland, N.Z.)</gtr:parentPublicationTitle><gtr:authors><gtr:author url="http://gtr.rcuk.ac.uk:80/person/29ad15c8fce8d6684ccdd0eac53b1e63"><gtr:id>29ad15c8fce8d6684ccdd0eac53b1e63</gtr:id><gtr:otherNames>Cammack J</gtr:otherNames></gtr:author></gtr:authors><gtr:date>2016-01-01</gtr:date><gtr:issn>1177-5467</gtr:issn></gtr:publication></gtr:publications><gtr:identifiers><gtr:identifier type="RCUK">BB/M00211X/1</gtr:identifier></gtr:identifiers><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects><gtr:researchSubject><gtr:id>48D25546-6ADF-479A-8877-478CCDB1DC1F</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal Science</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>EB5F16BB-2772-4DDE-BD6C-3B7A6914B64C</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Info. &amp; commun. Technol.</gtr:text></gtr:researchSubject><gtr:researchSubject><gtr:id>5858EC49-4786-4440-8352-1AB0B6DC5F23</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Psychology</gtr:text></gtr:researchSubject></gtr:researchSubjects><gtr:researchTopics><gtr:researchTopic><gtr:id>790AD28C-6380-4025-83C2-6881B93C4602</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Animal behaviour</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>E1AC33C6-9927-41AC-B23B-2EED8F593588</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Experimental Psychology</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>F439A20B-A9B0-4A68-B703-7F6AE7570E39</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Systems neuroscience</gtr:text></gtr:researchTopic><gtr:researchTopic><gtr:id>541CA340-B127-4309-84C6-51C40A48B4DA</gtr:id><gtr:percentage>0</gtr:percentage><gtr:text>Vision &amp; Senses - ICT appl.</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>