<?xml version="1.0" encoding="UTF-8"?>
<gtr:projectOverview xmlns:gtr="http://gtr.rcuk.ac.uk/api"><gtr:projectComposition><gtr:collaborations/><gtr:leadResearchOrganisation url="http://gtr.rcuk.ac.uk:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:department>Design Engineering</gtr:department><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:typeInd>RO</gtr:typeInd></gtr:leadResearchOrganisation><gtr:organisationRoles><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/46387D84-F71E-4B7D-8C7D-9C288F113510"><gtr:id>46387D84-F71E-4B7D-8C7D-9C288F113510</gtr:id><gtr:name>Imperial College London</gtr:name><gtr:address><gtr:line1>South Kensington Campus</gtr:line1><gtr:line2>Exhibition Road</gtr:line2><gtr:line4>London</gtr:line4><gtr:postCode>SW7 2AZ</gtr:postCode><gtr:region>London</gtr:region><gtr:country>United Kingdom</gtr:country></gtr:address><gtr:roles><gtr:role><gtr:name>LEAD_RO</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/89EAEA11-6AF3-4412-AC88-C879A28B7C97"><gtr:id>89EAEA11-6AF3-4412-AC88-C879A28B7C97</gtr:id><gtr:name>Shadow Robot Company Ltd</gtr:name><gtr:address><gtr:line1>251 Liverpool Road</gtr:line1><gtr:postCode>N1 1LX</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/9B151DB9-8DD4-4190-824A-1254D7A7E4B2"><gtr:id>9B151DB9-8DD4-4190-824A-1254D7A7E4B2</gtr:id><gtr:name>Active8 Robots</gtr:name><gtr:address><gtr:line1>10b New Rock Industrial Estate</gtr:line1><gtr:line2>Chilcompton</gtr:line2><gtr:line3>Radstock</gtr:line3><gtr:postCode>BA3 4JE</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole><gtr:organisationRole url="http://gtr.rcuk.ac.uk:80/organisation/D1EC1C10-8151-45FC-AB57-101E207EDB37"><gtr:id>D1EC1C10-8151-45FC-AB57-101E207EDB37</gtr:id><gtr:name>Southern Scientific</gtr:name><gtr:address><gtr:line1>Scientific House, The Henfield Business</gtr:line1><gtr:line2>Shoreham Road</gtr:line2><gtr:postCode>BN5 9SL</gtr:postCode><gtr:region>Unknown</gtr:region></gtr:address><gtr:roles><gtr:role><gtr:name>PROJECT_PARTNER</gtr:name></gtr:role></gtr:roles></gtr:organisationRole></gtr:organisationRoles><gtr:personRoles><gtr:personRole url="http://gtr.rcuk.ac.uk:80/person/E040FEDB-ACCB-4B09-AF0F-532F0E1A4550"><gtr:id>E040FEDB-ACCB-4B09-AF0F-532F0E1A4550</gtr:id><gtr:firstName>Thrishantha</gtr:firstName><gtr:surname>Nanayakkara</gtr:surname><gtr:roles><gtr:role><gtr:name>PRINCIPAL_INVESTIGATOR</gtr:name></gtr:role></gtr:roles></gtr:personRole></gtr:personRoles><gtr:project url="http://gtr.rcuk.ac.uk:80/projects?ref=EP%2FN03211X%2F2"><gtr:id>983EC2F8-A899-4E40-8B71-830E4B8667ED</gtr:id><gtr:title>Morphological computation of perception and action</gtr:title><gtr:status>Active</gtr:status><gtr:grantCategory>Research Grant</gtr:grantCategory><gtr:grantReference>EP/N03211X/2</gtr:grantReference><gtr:abstractText>Living beings share the same embodiment for sensing and action. For instance, the spindle sensors that provide the feeling of a joint angle and speed are embedded on the muscles that actuate this joint. The tendon sensors that provide the feeling of force too are directly involved in actuation of the joint. Do the function of these sensors change when the muscles are activated to take action? Does the co-activation of antagonistic muscles play a role not only in actuation, but also in perception? This project will investigate these questions through targeted experiments with human participants and controllable stiffness soft robots that provide greater access to internal variables. 

Recent experiments we have conducted on localising hard nodules in soft tissues using soft robotic probes have shown that tuning the stiffness of the probe can maximise information gain of perceiving the hard nodule. We have also noticed that human participants use distinct force-velocity modulation strategies in the same task of localising a hard nodule in a soft tissue using the index finger. This raises the question as to whether we can find quantitative criteria to control the internal impedance of a soft robotic probe to maximise the efficacy of manipulating a soft object to perceive its hidden properties like in physical examination of a patient's abdomen. 

In this project, we will thus use carefully designed probing tasks done by both human participants and a soft robotic probe with controllable stiffness to access various levels of measurable information such as muscle co-contraction, change of speed and force, to test several hypotheses about the role of internal impedance in perception and action. Finally, we will use a human-robot collaborative physical examination task to test the effectiveness of a new soft robotic probe with controllable stiffness together with its stiffness and behaviour control algorithms. We will design and fabricate the novel soft robotic probe so that we can control the stiffness of its soft tissue in which sensors will be embedded to obtain embodied haptic perception. We will also design and fabricate a novel soft abdomen phantom with controllable stiffness internal organs to conduct palpation experiments. The innovation process of the above two designs - the novel probe and the abdomen phantom - will be done in collaboration with three leading industrial partners in the respective areas. The new insights will make a paradigm shift in the way we design soft robots that can share the controllable stiffness embodiment for both perception and action in a number of applications like remote medical interventions, robotic proxies in shopping, disaster response, games, museums, security screening, and manufacturing.</gtr:abstractText><gtr:potentialImpactText>Academic impact: We will make academic impacts in three major areas in addition to extended impacts in groups of identified areas. First the findings in morphological computation (how the mechanical circuits of the embodiment contributes to the computation of perception and action, and their mapping from one to another) will shed new light on how the stiffness of a shared embodiment between perception and action can help to improve information gain in perception while improving the robustness of action. This will take research in soft robotics in a new path, because so far the attention has predominantly being on the role of embodiment in action. We will also contribute new technologies in soft grippers and probes that can regulate the stiffness of the embodiment to suit the task specific perception and action requirements. This project will also make new findings in human motor control related to the common mediation of muscle co-contraction in perception and action. So far there has been a heavy emphasis on the central nervous system as a direct mediator of perception and action, and the computational motor control community has given full credit of motor control to the brain. This project will challenge that norm with experiments done to find the role of indirect involvement of the central nervous system to regulate perception and action through joint impedance control.

Other scientific engagements: In addition to the main areas of scientific contributions, we will bring together a diverse group of scientists in biology and soft robotics to explore questions about the possible projections from neural based computational plasticity to regulate a common embodiment to improve perception and action on long-term morphological adaptation to reduce the burden on the central nervous system to perform repetitive computational tasks. Moreover, the engagement with the telecommunication research community will help us to make an impact on the future &amp;quot;haptic internet&amp;quot; where we will have efficient communication protocols to perform remote physical examinations with real-time haptic feedback with guarantees on safety.

Industrial and clinical impact: There is an increasing demand for soft robotic grippers and probes in surgery, agriculture, remote healthcare, museums, tele-shopping, games, and aviation. The scientific contributions to introduce new ways to improve perception and action through a shared controllable stiffness embodiments together with novel ways to design and fabricate soft grippers/probes for physical examination of soft tissue will make a disruptive shift in the practice of the soft robotics industry.

Social impact: The project will contribute to a broad social discussion on how soft robots can be used in our daily lives as well as to understand our own bodies through engaging students and robot enthusiasts in scientific exhibitions, information on our websites, and meetings in the London Robotics Network. 

Impact on students and RAs: The postgraduate students associated with this project and the directly employed RAs will have the opportunity to teach and conduct public engagement workshops. We have budgeted for their travel to major international conferences to promote their visibility and to facilitate networking. Following our previous experiences, we have planned to integrate technological innovations in this project to formal teaching practice of robotics, neuroscience, and general practitioner training.

Open access data: Following positive experiences of releasing open access data based on previous EPSRC funded projects, we will release anonymised physical examination behavioural data with proper guides to use them for research purposes. This will engage a broad academic community interested in related research areas.</gtr:potentialImpactText><gtr:fund><gtr:end>2019-07-10</gtr:end><gtr:funder url="http://gtr.rcuk.ac.uk:80/organisation/798CB33D-C79E-4578-83F2-72606407192C"><gtr:id>798CB33D-C79E-4578-83F2-72606407192C</gtr:id><gtr:name>EPSRC</gtr:name></gtr:funder><gtr:start>2017-02-01</gtr:start><gtr:type>INCOME_ACTUAL</gtr:type><gtr:valuePounds>263165</gtr:valuePounds></gtr:fund><gtr:output><gtr:artisticAndCreativeProductOutputs/><gtr:collaborationOutputs/><gtr:disseminationOutputs/><gtr:exploitationOutputs/><gtr:furtherFundingOutputs/><gtr:impactSummaryOutputs/><gtr:intellectualPropertyOutputs/><gtr:otherResearchOutputs/><gtr:policyInfluenceOutputs/><gtr:productOutputs/><gtr:researchDatabaseAndModelOutputs/><gtr:researchMaterialOutputs/><gtr:softwareAndTechnicalProductOutputs/><gtr:spinOutOutputs/></gtr:output><gtr:publications/><gtr:identifiers><gtr:identifier type="RCUK">EP/N03211X/2</gtr:identifier></gtr:identifiers><gtr:projectHierarchy><gtr:parents><gtr:parent><gtr:id>FBDAE9D9-EB6B-4B2D-B798-2601A5E2E775</gtr:id><gtr:grantRef>EP/N03211X/1</gtr:grantRef><gtr:amount>307919.36</gtr:amount><gtr:start>2016-07-11</gtr:start><gtr:end>2017-01-31</gtr:end><gtr:children><gtr:child rel="Transfer"><gtr:id>983EC2F8-A899-4E40-8B71-830E4B8667ED</gtr:id><gtr:grantRef>EP/N03211X/2</gtr:grantRef><gtr:amount>263165.89</gtr:amount><gtr:start>2017-02-01</gtr:start><gtr:end>2019-07-10</gtr:end><gtr:children/></gtr:child></gtr:children></gtr:parent></gtr:parents></gtr:projectHierarchy><gtr:healthCategories/><gtr:researchActivities/><gtr:researchSubjects/><gtr:researchTopics><gtr:researchTopic><gtr:id>D05BC2E0-0345-4A3F-8C3F-775BC42A0819</gtr:id><gtr:text>Unclassified</gtr:text></gtr:researchTopic></gtr:researchTopics><gtr:rcukProgrammes/></gtr:project></gtr:projectComposition></gtr:projectOverview>